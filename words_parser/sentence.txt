 Now we'llmove over to the T and again, that's the root of a three node heap that's heapordered except at the root.
compareTo(w) less than zero.
 So what do we do to get lookup CSV implemented? Well, first thing is toset up the input stream from the first argument, so that's our input file.
 And then there's resolution which is to figure out how to change thevelocities of the particles according to physical laws.
 Okay, X7 is a new value.
That's a complete implementation of Quicksort.
So, we start out i is at the left end and then the remaining, all the remainingentries to the right.
 So the heap order condition is satisfied everywhere except at this node.
 Many obvious out applications like or, organizing yourmusic library or displaying your search results or listening feeds in your in yourweb browsers.
 It's going to be recursive,it's going to be based on the points, the way in which wedivide into halfplanes.
 Stacks are familiar.
Delete code is a bit more complicated but it's on the book side and in the book.
 Order doesn'tmatter so all we want to do is add an item maybe you want to know the size and wewant to iterate through all the items in the bag.
 That way, we leave a of zero empty.
 You can see it's got the first half sorted, now it's working on the secondhalf.
So we move to the left and compare H against the root of the left subtree.
 And plus it goes on the operator stack.
 The client really can'tknow how big the stack is.
 So that'sour parameter M - that's the number we can afford to store but the total number ofitems we couldn't possibly afford to store them.
 Now increment i, stop at the l which isgreater than k decrement j stop at the e which is less than k and now at this pointthe partitioning process is complete, coomplete cause the pointers have crossedand we have looked at everything in the array.
 Now there's a couple ofconventions around null.
 That's the most recently added item.
 So, at that point the right point ofa horizontal line segment we just remove it because we've processed that linecompletely.
 And what's worse is, the recursive natureof the sort definitely means that there's going to be lots ofsubarrays to be sorted.
 So, with that one copied at this code, it's almost trivial and it's a method in our standard random class.
 This is not a course on discretemathematics.
 And the reason is that you only createa new array every time it doubles.
If you look at this visual trace you can see how it works.
 That's what we needed for the Graham scan algorithm forthe convex hull.
 Sothat's the key is to be able to have client code that is so compact foriterating through items in the data structure so we're going to provideiteration for all our basic data structures and it's not too hard to dodefinitely worthwhile the effort.
 And then we do the same thing on theright, and eventually we have two eights that wemerge together to get the final result.
 People buying tickets toa rock concert and I'm going to sort by location what we'd hope is that it wouldkeep the sort by time but this is a non-stable sort that doesn't do bad sothen out in the location they're going to have to resort it if they use one ofthese.
 It's called divide and conquer.
 There's lots of importantapplications for this.
 It says thatindex one has got 0.
 It's not our fault that we had to do that, wehad to do that cuz of your requirement about not allowing us to declare genericarrays.
 And then, the next phasewould be to take that heap ordered array and get, get it to be a sorted result in,in place.
 Quicksort not stable.
 There's a, alarge amount of data.
 And now this one's not heap ordered, so we have toexchange over the largest of its two children.
 We have two different stacks.
 And that's one of our main themes in thiscourse.
 So we have to be sure we've gotthe method that we want for checking whether two keys are equal.
 Okay? Yup.
 In this case, the maximumdistance from the top to the bottom is sixteen the average is only nine and thebest you could in a perfectly balanced tree it would be seven.
 That's first = new Node.
 This is an example of a mathematical model where the problem is,is very well articulated.
 You have extra space for the links to implement the link lists butthe rest of the table is not much extra space.
But the other test is not in our implementation.
 But when N is large, 40 N is a very closeestimate to the amount of space needed.
 These types of things ariseoften in practical applications.
 Rankoperation, that is essentially what binary search provides.
 This is the Quick-findalgorithm.
 So, then we have to go through all the particlesand change their positions on a straight line trajectory, where would they'll beafter that much time? Then we have to take the two particles that collide and changetheir velocity.
 And the way we are going to that, is tomaintain a priority queue and that priority queue is going to have all thepossible collisions that could happen in the future and they're going to beprioritized by time.
 Now, our, our original paper on red black treeswas the way the paper was laid out, it turned out that the delete implementationhappened to be placed after all the references.
 So let's look at the beginning, we don't do anything, we just swap it with itself.
 And where we don't need ordered iteration or any of theordered symbol table operations because it has really fast access to the symboltable.
 But for certain applications we can get close to constant time for one or the other operations and that will be useful in different implementations.
 So the goal is socalled three way partitioning.
 A binary search tree, each node has a key and everynodes key is larger than all the keys in its left subtree and smaller than all thekeys in its right subtree.
That's going to be a constant extra cost.
 So we're done with 4, and we come to 3.
 There can't be a systemsort out there that's going to cover all possible combinations of attributes.
And so the end result is that a search or an insertion in a B-tree in a order m,that's where we're putting M keys per page, requires between log base M - 1N andlog.
 And you're familiar with this.
 And how close it could get to full withoutsacrificing performance.
If it happens to hit the left of the wall then you reflect the x-coordinate in theright wall, you reflect the x-coordinate bottom to top, you do the same for they-coordinate.
 The floor of K is in the right subtree, ifthere is any key smaller than K in the right subtree.
 That, if that assumption doesn't hold and you getbad performance you're going to have disastrous consequences.
 So to insert N items,it's about three array accesses.
 Now, here's an example where we want to use theory as a guide.
And if it's not a CCW turn, it pops and then continues going.
 So, suppose you have a deck of cards, one of the things that you might want to try to do is to simply rearrange those cards into random order, that's called shuffling.
 So the clustering in the data is going tomake the implementation inefficient.
 Now the 9th point well it's to the leftof 8, above 2 to the left of 8 and then corresponds toa horizontal partitioning.
 It's always refers tosomething that's nearby something else that I just referred to.
 And then the last thing we need to do isjust return the item that we saved away.
 That's aninsidious bug.
 In this case, we'll have the word, the file list.
 It's just complicated code to understand.
You could think of a vacant site as being a conductor and, and a block site as beinginsulated.
 The red black tree tracks every simplepath from a node to a descendant leaf that has the same number of black nodes.
It's in place we don't use any auxiliary array it's not stable, but its worst-caseguaranteed time is proportional to N lg N as well as the average and, and the bestthis is not a result but that's also the case so it's N lg N guarantee N place, butit's not stable, and we still have the hope that someday somebody will develop asimple in-place stable worst case N lg N algorithm but we're not quite there yet.
 B and this b treewould go down the left link.
 And if it does, print the value associated with the key.
 We'regoing to test whether it's valid.
 The property of a complete tree is at the height of a complete tree with N nodes is the biggest integer less than log base 2 of N.
 And at the end,E is associated with the value of 12, the place where it most recently appeared.
 But more important, there's code, there's exercises, tere's agreat deal of information there.
Now let's look at constructing a 2-3 tree from an initially empty tree.
 It's a well-known phenomenon knownas clustering that says that the points aren't going to be evenlydistributed all over the whole thing.
 So, for example if we insert h in to this treehere, it comes off as the left link of R so that gives us a temporary four nodethat's not balanced so we need to rotate the link from S to the right and thatgives us now temporary four node that is balanced and again, these are all localtransformation it's not changing the rest of the tree.
 So here'sa summary of linear probing, hashing.
 So these are our consequences, so it's the contains implementation is the samefor all our symbol type implementations.
 Like using anotherhatch function rather than looking at the next entry.
 The thing is remember represented in array one two three and so forth.
You could make it so that the hash table itself grows once it gets really huge andsuch hybrid methods are easy to implement.
 Make sure that both first andlast are always what we want them to be.
 Now that heap is a seven node heap that's all heap ordered, and then the lastthing is to do the root of the whole thing and again, now the two sub trees are heapordered, that's what we mean by bottom up, we took care of the heep ordering from thebottom up.
 The array representation, all we do is we put, we start with indices at 1.
 So, one thing is we're usinga different key interface.
 So, let's look at the proof of that.
 Then, asusual we'll connect, the entry corresponding to both five and six tozero.
 You might have anew computer that's ten times as fast but you could address a problem that's tentimes as big.
 So first we exchange it with the 10,it's still not in place, so we exchange it with the 7.
 Sothis is just another typical example where we've got things sorted by time, and thenwhat we want to do is maybe these are important events.
 So I don't want to do that.
 Even though we know we're not using it,the Java system doesn't know that.
 And so we search to the left sub-tree andwe check if it contains point 5 and it does, that's the one that we return.
 The first one is the size of the subarray and this loop getsexecuted on a log N times because each time we double the size of the subarray untilwe get to N.
 And all we want to count isthe first time we access a page, because the main cost is trying to find where thepage is.
 So, for example, this is a external, this is M = six.
 And then we set its instance variables.
 So this is a simple test client thatwe can use to test our implementations.
 The first part is data typesorting and searching.
 It seems like a lot of baggage tocarry around and the reason that we do it, why do we go to the trouble doing it isthat we can, if we have a data structure that's iterable we can use a very compactand elegant client code in Java, the so called for-each statement.
 Those areall at the level of exercises in the context of the kinds of algorithms thatwe've seen.
So, one thing we can do is just run it for a 100 balls in random position at randomvelocity.
 Probability that a site is vacantis low as on the left, two examples on the left in this diagram, it's not going topercolate.
 And the algorithm that he usedis based on 3d-trees with the N particles as nodes, and storing the centerof the mass in the subtree in each node.
 What's that threshold value but, nobody knows thesolution to that mathematical problem.
 So,without any extra special code we insert a node into an empty tree.
 We just put a test in the recursiveMergesort for that, through this one line of code, to checkwhether we're done.
 So that now, we have our set ofexceptional words.
 [COUGH] so the merge implementation then,the first thing it does is copy everything over to theauxiliary array.
 And so what the test client'sgoing to do is going to just go in the loop as long asstandard in is not empty.
And then we do the comparisons as, as before and that, and that's all fine.
 And the right link points to all, 2-3 treecontaining all the keys that are larger than the larger of the two keys in the3-node.
Alright.
 If we have a 10,000 by 10,000 matrix we can get it donenearly instantly linear time versus 10,000^2.
 A little bit of high school Physics and alittle bit of basic Computer Science.
 And, I might add, the algorithms that process them.
 So we move that one up and increment j andk.
 And you can think about the implications of that.
 And we'll continue to do a few more so you'llget an idea of how it works.
 So there's various technical reasons for that and you canread, read extensive debates about this on the web that's going to go beyond ourscope.
 So let's take a look at howit works with the demo its more complicated than standard Quicksortpartitioning.
 Start with the API.
 And so now we're only going tolook in parts of the tree that could give us a point that'scloser to our query point than 3.
 This is called intervalsearch.
 We're assuming that people who take this course know how to program,and know the basics of loops, arrays, functions.
 We can discover mistakes in typed mismatches at compile-time instead of atrun-time.
 And the other reason is that we cansupport a broader set of simple table operations that are veryconvenient for many clients.
 Then delete themaximum.
 And manages to get the sorting job done with guaranteed analogs and compares.
 So thesearches is definitely more complicated and kind of mysterious, but let's look atthe rules for search in an interval search tree.
Suppose we're inserting K.
 And thisis a big difference between the binary search implementation where the keys arekept in order in an array, in the sequential search implementation, whenthey're all in a link list.
 Now instead of the initialization always takes timeproportional to N.
 And then, here's the move method.
 Typical implementations ofred-black trees that do not use this recursive strategy wind u p having lots ofcases depending on whether left or right or double rotate to the left or doublerotate to the right can be critical of this code because my own was this way forthe first three editions of the book.
 Value, put in the value stack.
 But they're all in that long list and you're going to have a sloweralgorithm if it's based on this.
 And now 2123 does intersect 1622, so wereturn and intersection.
 So, a lot of people didn't seethe delete implementation.
 So, that's an answer to the question for people t hat have beenasking.
 So now it's alittle bit tricky the way that we implement it since we're using we use arecursive implementation.
 So, here's what the implementation of a sparsevector might look like.
 There's a method that all Javaclasses inherit for equals, but the default implementation is simply totest whether the references are equal.
 Very instructive to study this trace to really understand what this recursivealgorithm is doing.
 So that's three different clients, three completelydifferent types of data.
 So insert() just puts it at the end, and sinceits unordered delete maximum has to go through the entire array to try to findthe maximum when it refines it and the changes that we're the one at the end andthen removes it the same way that we do within the stack.
1 and 1.
 And then what thismethod will do is go through and merge those little subarrays of size onetogether in pairs to get subarrays of size two.
 The white is the unoccupied part.
 And if you don't have order in the keys at all then you need the compareto, to implement balance search trees.
So complexity's going to tell us that it's a quadratic algorithm if that's what itsworst case is.
 And we're, we're going to look at a more general model forexternal storage.
 And in this case it's H, and we put that node in T spot and then delete the minimum.
We think that one is bad news, we don't use it can lead to insidious debug, bugdebugging problems.
 So this is when the itemscome in in reverse order.
It takes it, boolean condition.
 Forexample, if you have a billion operations and a billion objects I said before itmight take thirty years.
 In this example what it tells us, what theorytells us is don't try to design a sorting algorithm that guarantees to usesubstantially for your compares than merge sort.
 But even if you take the absolute value.
 Any interval thatintersects this query interval 23 25.
left is red and h.
 If they are connected it'll ignore.
 But we have to use a little extra time andspace to deal with the links.
 They're in their own connected component.
 Just put them in anarray, and then, well, insertion is, is fast.
 And the other thing I have referred to butnot talked about in detail is the presence of equal keys.
 So, with just two exchanges we insert that new element into the heap in this case.
 And so, this client readsstrings from standard input.
 Links can be null.
 There's a 2-node, there's room for the X.
 That is, we need that extra auxiliaryarray for the last merge.
 Otherwise if themax is less than low we go right.
 So if the points are randomly distributed,then this is ideal.
 That's the sort problem.
 It could be that,if one of the fields is an object, then you use that object's equalswhich applies the rule recursively.
 Then our value stack is doubled so that's the same stack code but withgenerics, we're using, using two different types of data.
 For insert, we have a method calledpush that take a string as argument and for remove, we have a method, pop, thatreturns the string most recently added.
 But it won't work well unless we havean efficient symbol table operation, and we'll use this client to comparedifferent symbol table implementations.
 And there's a relatively easy wayto do that.
 At leastthat some indication that you understand the performance characteristics.
 In fact, some were discovered by undergraduates in a course,course like this.
 For files with large numbers of equal keys and that wasactually found by applications user and, and that's the standard Quicksort that wasin all the textbooks almost all the textbooks if you did not stop thepartitioning on equal keys it would run in quadratic time.
 So that's very straightforward implementationof the get operation for symbol tables with a binary search tree representation.
 To merge an array, put the result back inthe first one.
 So, that value stays the same.
 And the right rotationimplements this and again that's going to maintain a, a symmetric order in perfectblack balance we change the way the red goes but we didn't change anything aboutthe black.
 But for typical data, it's very efficient.
 And three, four, eight, and nine all have entry eight.
 Doublehashing is the variant of layer probing where you just skip a variable amount, notone each time.
 [cough] Alright, so now, there's a couple of elementary operationsthat we have to perform on red-black trees, called rotations.
 And in on the right we have to do a, a little bit of tricky codeto make sure that we return the floor on the right subtree, if there's some treethere.
 So, this one we used all three ofour operations, rotate left rotate right and flip the colors.
And in fact, in many real applications, they're not very random.
3 of the book, or in our introduction to programming andJava book.
 So that's our two primary operations.
 And it turns out to be very close to a generic algorithmic design techniquethat we will be looking at in many, many different applications.
 So you have to use hashing if you don't havethe comparison.
 Andfor example, the largest of all the keys is at the root.
 So, how are we going to do better? Our first attempt is analternative called, Quick-union.
 And so[COUGH] this statement builds a new symbol table with string keys and integer values.
 If they key's not there,it puts a new entry in.
 Selection sort is going to use quadratic time because it always has to gothrough the whole thing to look for the minimum.
 Essentially terminate the length of the [inaudible]list that we have to search through when we're doing a insertion.
 And if everything's random, then on average you only have to lookhalfway through for a successful search.
 This does not include the space for the strings themselves,which are owned by the client.
 If you do the, actuallyit doesn't cut it in half at exactly each time only on average so you need a fulleranalysis like the one we did for Quicksort and the bottom line of that analysis givesthe number of comparisons required as a function of n and of k in terms of thisformula here and if you plug in k = n/2, you get the result that the number ofcompares required to fine the median that's the highest value this formula cantake is two + two natural log of two.
 This paper was veryinfluential and, and that basic method is widely used.
 The other thing is that the seed is just the number of milliseconds since midnight and that cuts down the number of shuffles even more.
 Find implementation is identical to for quick union, you're justchecking whether the roots are equal.
 Andthat's a very useful thing because otherwise, we might try to define such analgorithm.
 Well no, the maximum,end point in the left node is eight.
 We figure out which of the children is larger.
 It's a complex dynamic situation that is better understoodthrough computer simulation.
Simulations in the real world, usually, we wind up doing huge amounts of data and wecannot have a quadratic algorithm.
 It's not onthe convex hull so, and what about the angle from 1 to 2 to 4? That's notcounterclockwise either.
 Now, the algorithms that we're looking at today are not goingto actually give the path connecting the two objects.
 But as it getsfull.
 And the idea is just a version of Quicksort in away.
 Okay, here's the complete Java implementation of a priority queue, we're using the binary heap data structure.
 And then, theresolution.
 Particularly, think aboutthe rectangle being small, it's going to be not that different thana regular search in a binary search tree.
 Sotypically for ordered simple tables, when keys are comparable will provide a muchwider interface it's very useful for many clients.
 So, we're going to keep trackof y coordinates in a binary search tree.
 So now what about solving a problem likethis, range search problem for a 2d tree.
 When we insert a new node all we want to do is create a newnode with the, I've given, associating the given value with a given key, as beforebut now we just make that node red.
 When does all the bins fill up? That's called the couponcollector problem.
 So, this has got the same amount of information.
 And that's the basis for a general method for deleting nodes from BSTs known as Hibbard deletion.
 For detailed information ona performance, eval grievance.
 And then use that index to get the valuethat's associated with that key, that's stored in a parallel array.
 And thensome advanced algorithms that make use of the basic algorithms that we developedearlier in the course.
 And now build asimple table that associates strings with strings.
 Suppose we want to test if an array is sorted.
 Tukey is a statistician and hehad this particular method for order statistics that has some interestingproperties and use that for the partitioning element.
 All have entries eight.
 As a warm up, let's suppose that wehave a string, a collection of stings.
 [COUGH] All right, so this is the code for the get operation andthis rank which is binary search.
 Now, which shouldthe output of such a program, such a method be? Well, in order to be able towork with the result, it should be a sequence of vertices that gives us thatpolygon if we follow it.
 And there's plenty of other algorithms waiting to be discoveredby students like you.
 And this one just uses equals, so the keysdon't have to be comparable for this.
 We encapsulate them in basicdata types like these.
 And the question is, can we do better? Can we have a faster way to shuffle? Do we really need to pay the cost of a full sort? The answer to that question is, no.
 We're not gonna try to find them all we'llget back to that in a minute.
 So to begin, we will talk about stacks.
 Well then, maybe somebody in this class will invent that but untilsomething like that is discovered use the quick select based on Quicksortpartitioning you can get linear time selection when you don't need a full sort.
 And we'll always go towardsthe query point first.
 So it's in three space,we use a plane and do above and below, andthen simply cycle through the dimensions.
 There's only a few instructions foreach one of the operations.
 So now we have a second item b.
right is black and so forth.
 And withthat 1D range search, implementation, we get an efficient N log N, 2D orthogonal,orthogonal line segment, intersection.
 That is easy for some types of data but it can get complicated formore complicated types of data.
 And to implement a stack when we do a push operation, we insert a new node atthe beginning of the linked list.
 There's do this prediction for every one of the particles.
 Because it would have N^2,calls to find, to check whether they're connected.
 Atthe beginning, 0->1 is a line that's on the convex hull.
 And here's the implementation there's very little to itgiven the symbol table API that we've articulated and the implementations thatwe have.
 As far as the algorithms go, as far asthe rules go, you can always return 17.
 So howare we going to implement stacks and queues for that types of data.
 So let's look at search first.
 You can, limit the depth of recursion byalways doing the smaller sub-array before the larger sub-array.
 Mm-hm.
 So here's the review of where we were withsingle tables.
 So like deleting R in this tree, it only has one child.
 Maybe the value in a parallel array.
 So, inserting the first N itemswould take time proportional, if the stack's of size N-1,it's going to take time N, N-2, time N-1.
 Pull it off the heap and then that's our example.
 And Bentley found this way toprocess it efficiently that's been widely used ever since.
 One of the most useful onesis to have comparable keys just as in sorting algorithms.
You can use your own programming environment if your comfortable with oneor you download ours.
Not the deletion algorithm that's guaranteed to keep the constant blackheight all the time.
 The key point is that the sort implementation has nodependence on the type of data that's handled by the Comparable interface and adifferent Comparable array will be sorted in the same way though eventually, becauseof the interface mechanism, they call back to the actual compareTo() code that goeswith a type of object being sorted.
 So, from these observations it's clear that what we, whatwe'd like is a selection algorithm that takes linear time.
 So,ours will have mass, so there will be some big heavy ones that make things moreinteresting.
 That's building a symbol table associatingkeys with sets of files.
 Now, if you're going to be using methods that depend on randomness in real applications, you do have to be careful.
 And that's difficult for Kenny to think about and difficult todrive that information from the implementation so program is just tooslow.
 We just during the insertion, make sure that we, we [cough] maintain theproperties the balance properties and by doing that, we wind up with balance treesand we make all the operations quick and we don't have to re-implement, we don'thave to change it at all.
 And then once we have the idea that D of N equals N lg N, we can plug back into theoriginal formula.
 So this recipe works prettywell in practice and it's used in several Java's libraries.
 Then, the whole array consistsof sorted subarrays to size two, and then we make another pass through to getsize four, and then size eight, and so forth.
If you know that v is less that w, w is less than v, you don't knowthat v is less than or equal to v.
 So the search is a natural generalizationof the search in, binary search trees.
 So a stable sort is asort that preserves the relative order of items with equal keys.
 In this case, as we'll see, ultimately we haveways to guarantee that all the operations can be formed efficiently.
 Andthat's definitely something to worry about.
 We create the array and then set eachelement to be it's own root.
 And, and in many applications evensetting M = 100 or 1,000 is going to be very effective.
" And many programmers live by that kind of preset.
 Our proposition says that insertion sort,to sort randomly ordered array with distinct keys, it'll use aboutone quarter N squared compares, and about the same number, one quarterN squared exchanges, on the average.
 Now for most of these,the intent is very clear.
 But also taking care of specialcases when the queue is empty.
 But now we're going to use that forintersecting rectangles rather than using range search as our basic operation, we'regoing to use interval search.
 Many of theseproblems are the basis for geometric processing of huge amounts of data that wesee all over the web.
 For example Java publishesits hash function.
1 through 1.
Another property of these 2-3 trees is that we are going to have perfect balance,That is every path from the route to a null link is going to have the same linkin the 2-3 tree.
 That's Hibbard deletion.
 That's the swim operation to eliminate violation when a key value increases.
 Our pointer still scansfrom left to right, but now the elements to the leftof the pointer, including it, are in order, but the elements tothe right have not yet been seen at all.
 This gives exactly what happens duringeach of the calls to merge.
 And similarly for the number of arrayaccesses, if you count up the number of times you're accessing an array for amerge you could be at most six in.
 And this is just adding the Heapsort line to the table.
 When we're using inShellsort of course, we find the largest increment less than our file size and thendo the sorts for decreasing values of that increment.
 Sosweeping from left to right means we consider each x coordinate as an event.
 If it is the case that you happen to betesting two objects that are the same object for equality, you might as welloptimize everything and just test that.
Now, what's interesting about binary search trees is that there are manydifferent binary search trees that correspond to the same set of keys.
Mergesort is not only efficient, it's also.
 Then once we've exchangedit, again, we preserved our invariant.
 And that's pretty close to the best thatwe could do in theory and is very important and useful, practicalimplementation and data structure.
 If you need that kind of order,maybe in an internet switch where packets are coming through at a great rate, youwouldn't want to be in a situation where you're missing some data becausesomething got slow all of a sudden.
Also staying in bounds.
 And we'll look at moreadvanced versions of these problems when we want to study hashing.
 So the idea is we're going to use a bottom upmethod.
 Butinexperienced programmers often have trouble with it.
 If it'sgreater we go to the right.
 Or actually Java implementsthat in its arrays library.
 And then we'll connectthem together.
 So if you just calculate the costof inserting the first N items, you're going to have instead of the sumof the integers from to 1 to N, you're going to have the sum ofthe powers of 2 from 1 to N.
 We're gonna start with an overviewdiscussion of why you might want to study algorithms and a little bit of discussionabout the resources that you need to take this course.
 You just take stackand remove the pop, or queue and remove the dequeue [cough] and you have fineimplementation of a useful data structure.
 So that's a few callsto Union but that's easy to implement.
 I drew all the cases and, and, there's a,whether you're splitting into the middle of a 4-node or the right of a 2-node,there's just a lot of cases.
 That's a lower bound on the complexity of sorting.
 Again, exactly as what would happen in a2-3 tree.
 Remember in the first computers, each bit was a physicalthing, a magnetic core that somebody had to string a wire through, so.
 For Java, because of the desireto check types at compile time, the use of specific method called an interface andthen, we'll look at the details of how to implement callbacks with the Javainterfaces now.
 There is that compareare the two children bigger, then compare.
 Now, mathematicians and computer scientists have researchedthis problem in a lot of detail.
 So the one on the left array goes to k'sposition.
 So we've got M bins, that's ourcorrespondence to our hash table.
 Nine and four, So now four is the root of the tree containing four is eight.
 But for a lot of applications that disadvantage is not viewed to be significant compared to the advantages.
 So then we're done, andwe found that the nearest neighbor is 5.
 The average case, which is extremelylikely for any practical application, is going to be about 1.
 So let's look ata demo of how it looks.
 We use this same idea on our initialrecurrences for comparison array accesses to show thatthe running, the number of comparison array accesses isproportional to N log N for Mergesort.
 So there's no reference to the old itemleft there and then the garbage collector can reclaim the memory sincethere's no outstanding references.
 But then,when we're doing selection, what we'll do is just go in one sub array or the otherdepending on where j is.
 Now, experts have worked to come up with improvements on this and there are slight improvements possible.
 Now, we want to talk about deletion andthen range search and range count.
 To push an item,we use N to index into the array, put the item there and then increment N.
 So this is a trace of whatwould happen for our trace.
 And the CSproblem is how and when to we exactly do these computations for each of the balls.
 And you put at the end of the code whatyou think it's going to do, again in the formof an assertion.
 So, just following those threecases, I see t hat this correspondence is going to work.
 About half a million distinct ones andin that [COUGH] corpus, the word government appearsabout 25,000 times.
 Problem with that is, that would be a brute forcealgorithm.
So it's twice the sum of from C0 to CN - one.
 In fact, this correspondencewith Quicksort partitioning tells us we can take that proof and prove that if youinsert in distinct keys into a BST, in random order, then the expected number ofcompares for a search and an insert is two natural log N.
 Differentlanguages have different mechanisms.
 And that's called Horner's Rule.
 But fortunately, we can get through prettymuch everything that we're going to do in this course just knowing about this one oflay cast.
 And so if you're trying to provide a service over the web.
 So a blacklist clientwould print out all the words in our source file, tinyTale.
 And a good way to think of a symboltable is as shown in the right here.
 That's kind of an amazing fact that this rough standard is reallyheld for 50 or 60 years.
 Now the first, and really one of the mostcritical observations, is that search in a red-black BST is exactly the same as foran elementary BST, we just ignore the color.
 What about nine and four? So, now we have to change the, to connect nine andfour, we have to change, 9's entry to be the same as 4's.
 NiklausWirth, another pioneer in computer science, wrote a famous book calledAlgorithms + Data Structures = Programs.
The idea is to arbitrarily choose the first element to be the partitioningelement.
 Alright, so, let's take a look at what happens.
And how can we do it efficiently that is in, in log N time versus quadratic time.
 Give me the minimum key, give me the largest key, andthen I can get the value associated with that using that.
 Say,university has student records and for every student there is a certain amount ofinformation.
 Where we could get guaranteedlogarithmic performance for a broad range of symbol table operations.
 So now,how do we implement rank? Well, it's a little like floor.
 Mergesort provides, provides an upper bound, that's an algorithm that'sguaranteed to get the sort done in time proportional to N log N.
 We're going to talk about insertion andsearch.
 And Dijkstra's algorithm is very simple toexpress.
 In the instance, methods won't change them and the client can't change them.
 Where we initialize the whole grid to be block edall black and then we randomly fill in open sites.
 For the union implementation, we're going tomodify the code to check the sizes.
 So we have to do a few extra passes to dothe higher sorts but the each element moves only a little bit on each path andthat's how Shellsort gains its efficiency.
 And all it does is just go through the array from the one to the length ofthe array and test if each item is less than the one before.
 And in all of these cases where we're on a node that alreadyexisted, we just want to return the link to that node.
 We'll start with the 1, 4, 13, 40, 121, 364 like thatand that's good because it's easy to compute.
 That's still a BST.
 But just a fewyears ago for this course I found a much simpler implementation of red-black treesand this is just the a case study showing that there are simple algorithms still outthere waiting to be discovered and this is one of them that we're going to talkabout.
Now, we'll go up again to just flatten the tree out.
 And we'll see some examples of this in this course.
 They convert to 64-bit, and x or the most significant 32-bits withthe least significant 32-bits.
Even on your PC you can sort huge array of a million items in less then a second anda million items in only a few minutes.
 We just return.
 And the, the bottom lineis that if you randomize the order and use three-way partitioning then there's lot ofapplications where your sort routine is going to be linear not N log N so it willbe much more faster than Mergesort and you know, the methods for really a broad classof applications.
 String.
 And that's a legal red-black BST.
 And that's fine in typical applications when the matrix is small, orwhen there's lots of entries in the matrix.
 The southern is still smaller, so T after it's exchanged up here will be bigger than both its children.
 Let's look at the Java implementation and then we'll look in moredetail at, at that quantitative information.
 We're going to do our partitioning so that we get entry a(j) in place of thearray.
 Maybe the way yourcomputer's memory is organized make a difference.
 So if it's in the tree, it would have tobe on the middle link.
 But if we ask is eight connected to nine? We are goingto say yes, even no we don't have a direct connection between eight and nine.
 And so, there are plenty ofapplications where we want to just be able to implement, this really simple API.
 That's restoring the heap border along a path from the place where it's violated to the root.
 But once unlocked, they cast a brilliant new light on some aspect ofcomputing.
 And don't forget to check that we're going off the end of the heap.
 So now, this is a recurrence thattelescopes.
 S o this shows the process ofbuilding a large B-tree.
 You really have to takethe absolute value.
 When it hits the wall is, is just going to change the velocity.
 And then again there's all, allkinds of difficulties in implementing convex hull in real world situationsbecause of various degeneracies.
 If I want that guarantee, if I want to besure that every operation's going to be fast, I'll use a linked list.
 And if it is in the symbol table,we'll just override the old value, which is st.
Again root of a three node heap may or may not be heap ordered, we do have to do thesync operation.
 So, it's just binary treeinsertion, but then after the insertion on the way up, we go ahead and, check, if themaximum that we have is bigger than the maximum there and update it if necessary.
Then we go ahead and then we could check if there's a collision, if the two balls,pieces of the two balls are occupying the same space.
 And so, it's larger than, it's bothchildren, and the larger of the two children is T, so we promote the T.
 And so that's really are thekey to thinking about what are symbol table and symbol tables in general.
 And all it does is divides by 2 again andthen throws out another 1.
 With a very simple modification,we can take a 2D tree and create a data structure known as a Kdtree, which even works for K dimensions.
 In fact, that's what lead to [unknown] analyze the situation then comeup with a left-leaning variant.
 So when we start putting the keys in the nodes, we're going to impose one more condition that's called heap ordering.
 In many cases, the first algorithm we come up with would befast enough and maybe it fits in memory and, we'll go ahead and use it, and be offand running.
 So in this case, the rank of e is twoand h is three and so forth.
 We might want to use the natural alphabetic order or we mightwant to make it case insensitive or maybe there is just different languages thathave different rules of the ordering.
 Here's the implementation.
 So again this time, sort of timing is whyQuicksort is so widely used.
 If there was perfect balance before,there's perfect balance after, because we didn't change the heights of anything elsein the tree.
 So, in this case we have a redlink connecting E and C.
 Littlebit scary for some systems designers.
 And this one, by definition,doesn't provide that.
 And it's actually a prototype foralgorithm design that we'll see come up again and again.
 And if M is prime,it gives us some comfort that we have some possibility of each table positionappearing with equal likelihood.
 And, and that willgive us now three rectangles on our sweep line.
 This implementation directly implements thelink list.
 So, what is this course? It'san intermediate level survey course on algorithms.
 That's thecode that we'll look at next.
 So Java is just an assert statement.
 And then a series of pairs of object names.
 So figuring outthe value of dt that would really work is a huge problem for the time drivensimulation.
 Go to 8, nope.
 The other thing is, ifyou take the point with the lowest y coordinate.
 And for linear probing hashing, really, theimplementation needs to include array resizing, whenever the hash table gets toofull.
 The key is, when it comes to removingan item, which item do we remove? The two fundamental classic datastructures for this, the stack and the queue, differ in the way in whichthe item to be removed is chosen.
 And then another thing that you mightwant to do is iterate through all the keys in the table.
 And also the associative arrayabstraction is the put() method will overwrite an oldvalue with a new value.
 And so that idea of getting closer andcloser to the query point is going to cut out different parts ofthe tree as we process.
 He worked with Doug McIlroy and they wrote a,a, a paper that outline this problem and talk about some of these things and theyhad a three-way partitioning method that was somewhat like the Dijkstra method thatwe showed but a bit more complicated.
 The partitioning elements in between themand they're in the wrong order.
 And if you're familiar with it, fine.
 Butalso, since it's the compare-to interface, and since it's a binary treerepresentation all the other comparable operations extended operations for orderedsymbol tables are going to be implemented and take time proportional to the log N.
 And what assert will do is it will throwan exception unless that condition is true.
 If it does have a right child and we do this, find the minimum on the right, deleteMin on the right and then fix the links, and then update our count that covers all cases.
 If the probability is high and there is a lot of open sides, itdefinitely is going to percolate.
 So, that's our starting point in terms of the code.
 So, let's look at a double split likethat.
Insert R into that, it goes to the right of E.
 But now,maybe a year and a half later, you have a computer that's two times faster but youalso want to build a bigger computer so you have twice as many rectangles tocheck.
 Actually less code thanfor Quick Find, no fore loops.
 If it goes on the right, then we attach a new node with thered link on the right but we have to rotate it to the left to make a legalthree node.
 Somehow we're going to want the valuebe any generic type at all but the key type we have to make somenatural assumptions about them.
 Once it's read in we get to read all of the page for free pretty much.
 And again, it's quite straightforward using the index arithmetic to move around in the heap, and that's called the sink operation because we're going down in the heap.
 So in this case,tinyTale.
 And then that's a time in the futureand we'll put that event on the priority queue with that time as the key.
right andnot is red h.
 We do some mathematical proofs in, in thiscourse when they're critical such as this one.
And okay, that's fine and you're going to see that when you do compiles using codelike these.
 And now we increment i and k.
Plus what happens next depends on what the partitioning element was.
 The idea is that in many applications,we have collections of objects that we want to maintain andthe operations are very simple.
 Balance trees, that allow for this.
 So in this case, we have an example where T, the node T here its value changes and it becomes larger than its parent key, P.
 Mid's the midpoint that divides the first part from the second, so our conditionsare that from lo to mid is sorted, and frommid plus 1 to hi is sorted.
 Now we have four pages andnow this time the first one fills up and splits and so forth.
It's less, so we go left.
 So, this three has to have at least N factorial leaves and ifthe three of height h, it has utmost two^h leaves.
 If they're connected by open sites.
 But there's plenty of applicationswhere the extra speed for search and insert that we canget this way is worthwhile.
 So now that's one step in the sort, we got the largest element off.
 We're going to have to look at both,as far as we know now.
 So the hash function willmap any key.
 Take it off the heap.
 It reduces to this case.
 So that's the cut off point for, selling,seven tickets that's the cut off point.
 Let's look at it when it's in reverseorder again it gets the first half done now it'sworking on the second half once it gets the second half done then it goesahead and merges together the whole thing it's just as fast in reverse order as asin auditory order.
That's kind of a magical operation and believe me, it's easier to get done in theimplementation than the graphics.
 Suppose you have a robot that wants to get from s to t andthere's an obstacle that's defined by some polygon.
 So, this value loop just builds thesymbol table from the file.
 You know, with reference to what weknow about 2-3 trees.
 And it's definitelyan instructive exercise to check that you believe that, that method works.
 If we're not done we're supposed to return true and the next() is supposed togive the next item in the iteration.
 But in general, we have to check whether the heap condition is violated and exchange it with its parent as long as it's smaller.
Elements that are all by themselves in just, in their own connected component,point to themselves, so one points to itself but also nine points to itself.
 So, rock, paper, scissors is intransitive.
 Now if we're going to implement our owntype then we have to go ahead and implement the Comparable interfaceaccording to these rules.
 So what power do you have toraise 500 to get bigger than N? In practice that's going to be like four orfive.
 So, we start with this sort example and then 7-sortingit - just involves doing insertion sort but just reaching back7 each time.
 Why? Well, we can start with a heap, by inserting all the elements and then deleting the maximum and getting a sort done and that would be linear time if we had this kind of variation, If we had Constantine's operations for both uncertain delMax.
 Now the one pointed to my i, the G is smallest so move that and increment iand k.
 And that has profound impact on theperformance of this algorithm.
 And we point that outbecause that helps with the mathematical analysis.
 Moving current to the next place.
 What about deleting the minimum? Well actually, that's maybe not too difficult.
 That's the a Quicksort like implementationsolving the selection problem.
 We'll populate its fields andthen that old link will change that from null toa pointer to the new node.
 So, for this example at right we have insert a numberof keys and, and we're just showing them in sorted order.
 It's very likely to be very near thisvalue is then as large.
 So, that's the way we representcolors by putting the, a color bit in the node for the color of the length thatpoints to it.
 So and a range search.
 Alright, so now let's look at the code for implementing Quick-union.
 Sometimes during theinsertion, we might wind up with a node that's got two red links coming out of it.
 So, because there's all these applications most programmingsystems have a fast sort as an important part of their infrastructure and Java isno exemption.
 So, if they're going to be comparable,we might as well take advantage of it, both to get more efficient algorithms and to be able to take advantage ofa broader set of operations.
 And so now, the question is when wehit a, a new rectangle, we want to do an interval search to, if we're at the leftto check which ones intersect and the interval search tree algorithm is going totell us which intersections there are right away.
 But if we shuffled randomly, it'sextremely unlikely to happen.
 That's a fine implementation for deleteMin and it also works for deleteMax.
left? So, that means H is h.
 In the third case now,when i is at the third entry in the array, now we start a index j, andwe move that starting at i to the left.
 So now with the iterator we have control over which order we gothrough the items and so that's going to go along with the semantics and the datastructure so probably in a stack you want to get the things in stack order like theorder that come out of the stack so that's reverse order in the array so in this casethen next() is just decrement and return the next one and our instance variable is anindex in the array.
 So if a big blockof things comes into memory, there's no more extra costs, whereas Heapsort isgoing to look far away from the current place as it goes down the tree and thatmakes it slower in a lot of situations.
 And there's plenty of natural total ordersin the types of data that we normally want to consider for sort keys.
 And one of the themesthat we'll go through over and over in this course is that quadratic time is muchto slow.
 So what about immutability? So, everything in Java is implemented as a data type, a set of values and operations on those values.
 There's no loops.
 Otherwise we go left.
 In this case, it's easy to see that every operationtakes constant time in the worst case.
 But otherwise, that's a fine method for merging.
 [MUSIC] Wow.
 So, more generally, here's the goal.
 So, let's just take a look at what happens with a real heap with the demo when we do these things.
 That the references tomemory are all over the place when it's a huge array, so it's not a good algorithmfor a situation where there's caching which is almost everywhere nowadays.
There's plenty of time by the memory model.
 So for example, here's somedata which is cities in the US.
 Then wehave a for loop that goes through every element in the array, we keep a variablemin in that is the index of the going to be the index of the smallest element tothe right of pointer i.
This bottom-up version that has no recursion, it's also quite simple tounderstand and to code up.
 And to pop, we decrement the index and then use it to returnthe item in the array.
 So this is a dynamic data structure that kind offollows the same rule as binary search.
That is, we allow for the possibility of something called a 3-node that can holdtwo keys, But then it has to have three children.
 So, we want to simulate the motion of N moving particlesthat might collide with the priority.
 So we just find that minimum node.
 In thiscase, if c is less than b and a is less than c then those three compares show thatthe order has to be a, c, b and if c is less than a, then it's going to be c, a,b, those three compares that c is less than a, c less than b and a is less thanb.
 So let's look at the analysis ofMergesort, that's a bit of math but very instructive because this really shows thepower of the divide and conquer method.
 That is, every object's connected to itself, it'ssymmetric.
 Thegive me the seventh key we just go and look there, they are in order.
 We have ourcarefully crafted code that does array resizing and so forth and we're going tocopy that code and change the data type string to the data type van or int toeverywhere.
 Say, for this fictionalclass Student, that's got two instance variables - name and section.
 Then the heap order condition is satisfied at that node because the parent was smaller, so that one's smaller.
 So, why should one study algorithms? Well, their input,impact is very broad and far-reaching.
 Or if theslope is infinity.
 In our hash function is pull out the system hash code, make it positive byending off the sign bit and then mark with M to get a number of, zero and -one.
 In this case we, wefind H as the left sub tree of R in [cough] that's a search hit and then forthe get operation, we can return the value that's stored in that node along with thekey H.
 It'samazing fact that was eventually proved by Friedman and Sachs, that there is nolinear time algorithm for the union find problem.
592746.
 But for many practical applications, they're easy to implement and worth using.
 We took a look at the last time at thebinary search tree, Which if things are well modeled by randomexertions, have a great performance.
 And it's quite straight forward simple code as simple as binary searchreally.
 It uses actually both quicksort and mergesort.
 And usually that's fairly straightforward.
 To put it in sorted order, we have to movefrom right to left, exchanging it with every larger elements to its left, andthat's what the code at the bottom does.
 It's closer, sowe update 3 to be our new champion.
 Like, forexample, what's the earliest time? That's the min or what's the latest time? That'sthe max.
 The idea behind Shellsort is that we'll move entries severalpositions at a time and the way we're going to do it, it's called h-sorting thearray.
 Alright, so let's just look at each of thealgorithms that we've considered so far.
 So easy to prove by correspondence with 2-3 treesthat t he height is guaranteed to be less than two log base two N.
 Actuallyfairly easy to understand why it works.
 And we'll see how that looks in just a second.
 So, that means that you could touch everything in the main memory inabout a second.
 And actually that's on the road to developing a compiler or a way totranslate a, a program from a programming language to a computation, soDijkstra's algorithm that uses stack is one way for entering and understanding ofthe basis of computation.
 Let's look at, Well it's a demo.
 So if wefind our key, that's the floor.
 And continue in that way, swap.
 And I mentioned that a lot of us would get uswrong.
And as this graphic integrates, it just does it by saving the information on astack.
 So again, the geometric interpretationis the keys are points in the plane.
 So now three and eight.
 Whatever the size,bottom of Mergesort gets the job done in log N passes.
 And it's a little different kind oftoo slow then for Quick Find, there's times when it could be fast, but there'salso times when it could be too slow.
 So, now we canlook finally at the main event driven simulation loop.
 We have less wasted space and probablyfaster implementation of each operation.
 Now, that part of thearray to the left of i is in it's final order and we simply continue.
 All those zeros have to getchanged to ones.
 They're either connectedor not then that will take quadratic time in squared time.
 Then on another pass through, we can takethe E, M and the G, R and merge them together to make EGMR, and the E, S and theO, R merge those together to make EORS, and so forth.
 And then, the implementation is just Insertion Sort.
 And that's also call the FIFO discipline,first in, first out.
So, there are number of implementation challenges for the Graham Scan and we'renot going to go into detail on this because this is a lecture on sortingalgorithms not computational geometry but it is indicative of how, even if we have agood sort, we might have to do some extra work to actually solve our problem in anapplication.
 If we're going to search for say L L's hatch value is six so it's notthere.
 Another right parenthesis, take the top two values off.
 First thing we do is the public sortmethod that takes the array of comparable items as its argument.
 So if xis null, we want to create a new node and return the link to that node.
 Well so, we arelooking for the largest key that's less than G.
 But most algorithms that we consider, were discovered inrecent decades.
 We'lllook at different methods that take advantage of such properties.
 Now in this case the second subarray to be sorted is smallerbut the merge routine doesn't really care about that so much.
 So we can,implement these, efficiently and they are, convenient and useful for the clients.
 But in the middle, when it's medium, it's questionable whether itpercolates or not.
 Now, built in to Java is the so-called the Comparableinterface and all the Comparable interface is the specification that a type, datatype that implements Comparable will have a compareTo() method.
 So, it goes down to the middle, and windsup needing to be inserted in the, 3-node in the middle.
 So take linear time forlarge number of keys.
 And there's many other thingsthat you can do with this basic collision system.
 So after this operation, we're firstpointing to the beginning of the list.
 So, a binary search treein Java is just going to be referenced to a root node.
So in a typical thing, say, maybe the matrix dimension would be 10,000, andmaybe there would only be ten non-zero entries per row.
 If D of N is 2D of N over 2 plus N with D of1 equals 0, then D of N equals N log N.
And to cope with that we need to do both.
 Wewill provide much more detail information on that as we get into the assignments.
 And the code for this is the same as forbinary search trees.
 So, from this datastructure we can associate with each item a root, which is representative, say, ofit's connected component.
 And there's plenty of other applications where people want to be ableto compute the convex hull.
 You wouldn't work to use Shellsortas the basis for h-sorting because that always takes quadratic time no matter whatorder there is in the array.
 So, forsorting, let's look at what each of these are.
 So wepick that number, I and then we just go to that list and this is the standard codefor diversing a link list start at the first node as long as it is not null go x= x dot x.
 There's many other reasons that people use immutable data types.
 And so that's the st ory of red-black BST's guaranteedlogarithmic performance for all symbol table operations.
 When we get our second A, we stopthe sort as long as we're not less.
 So details but any way you can use thiscode as a model to implement equals for any data type that you might windup using as a simple table key.
 Sopoint 2 can't be on the convex hull either.
 And every node's got fourfields, a key and a value, and references to the left subtree, that contains thesmaller keys, and the right subtree that contains the larger keys.
 Now we have, what about the pop, we haveto think about how to shrink the array.
Perform the operation.
 And then, we talked aboutrandomized queue or bag where we might remove a random or an arbitrary item.
So we're going to convert that into a 4-node.
 How do we, we do not implementing the API? The API says we should justbe able to create a stack and it should be able to grow andshrink to any size.
 What about insertion? Well, to insert a new key, allwe do is follow the same steps as we did for search.
In a regular BST node, the 2-node, we have one link for the keys that are less thanthe key in the node, and one link for the keys that are greater.
 So the basic rule is that if you'recomputing your own try to use the whole key but consult an expert if you'reseeing some performance problems.
 And then what we can do, is just return that node's right link, then that old node, nobody's pointing to it, so it's available for garbage collection.
 So we'll, we'll come back to dealing withthat worse case in the next lecture.
 Like stability, that'sa fairly sophisticated attribute that you really have to think about, you maybe notbe aware of.
39 log N and that's probabilistic ifthey are in random order, its extremely likely to be there.
 It would have beenvery exciting.
 If they're equal, it returnstrue.
 And, for everynode that we encounter, it could be that, our right endpoint of our interval, isbigger than what was there.
 It's optimal with respect to both space and time.
 We've talked about six different sorting algorithms.
 Anoth er thing they did was rather thanshuffling the array.
 So, that's definitely a way to get a deck shuffled quite easily, easy to implement.
 That's the shortcut in manyprogramming languages nowadays for use the index and then increment it.
 But this isunattractive because for large numbers of keys, in order to count the keys that fallwithin a given range, you have to go through all the keys and test whetherthey're in the range or not and to return them the same way.
All right so QuickFind is too slow forhuge problems.
 And that way the client code doesn't docasting.
 To remove a key, and maybereturn the number of keys in the set, and also have an iterator to iterate throughkeys in the set.
 Now we're going to look at a technique forresolving that problem.
 Now it's easy to develop on mathematical model for the costof selection sort and here's the proposition that describes that.
 In the binary search tree, we have a node at the root and we haveeverybody smaller to the left, and everybody larger to the right.
 Now, there's a lot ofissues in doing this.
 [cough]They're, they're going to be extreme points on the convex hull.
 And without something like priority queues, you couldn't do thisfor a large number of particles because it would require quadratic time and simplycan't be afforded for a huge number of particles.
 Four on, star.
 The first thing to check is find out which one is bigger, it's either 2k or 2k plus one and so set J accordingly.
 If we allow delete, in fact everything degenerates to square root of n.
 Alright, so with that mergeimplementation, then the sort implementation is a quite simple,recursive procedure shown here.
 And then,and then lg N more time.
 Do we need guaranteedperformance? Are we happy with random performance? Do we know, is the arrayrandomly ordered? You can think of a matrix shown in the right here where welist out all the possible attributes and then there's algorithms that worked wellfor different combinations of attributes.
 The idea though is that this example illustrates that good sortingalgorithm gives us a good convex hull algorithm.
 So, here's a clientthat calls our insertion sort method and all it does is read numbers from standardinput than into an array a then calls insertion sort and then prints them out.
 The question is what isthat value.
 Instead, what we want to do is called an event driven simulation.
 Whereas what we can hope for and what weactually will achieve is to get log N time for all operations, time proportion to log Nfor all operations.
 If we havea left parenthesis, do nothing.
 And you can see at the beginning,it doubles from one to two to four, but once it gets to four, it stays, once itgets to eight, it stays at that size for awhile even thoughthere's some operations.
 It seems strange to be ignoring parenthesis and we'll getback to that in a second.
 We have two requirements, andone is that we have to be able to compute the thing efficiently ina reasonable amount of time.
 Any particular value happens withprobability one over n, and if it's k, then the left subfile has k - one items init, and the right subfile has n - k items in it.
 Very little code toimplement the convex hull given that you have a sort and that's our main point forthis lecture - there is many natural applications of sorting but also will beable to develop new algorithms that use sort that gain efficiency because of theefficiency of sorting.
 And so we have twophases, we have prediction and resolution.
 And then we rotate thetop link right and then, we flip the colors.
 In all possible ways, andyou can get two to the N strings, for any N of length to N that all hash to the samevalue.
So [cough] this is if we implement a point data type for computational geometry, youcan have a method ccw() that just with this little math calculation (b.
 And generally programmers, Javaprogrammers know that it's a good idea to try to do these assertions.
 And then the last one changesthe value at E, again, 12.
 So, the priority queue operations is the insert in delMax that we just showed in the previous slides.
And making that, 4-node into two 2-nodes and adjusting the lengths appropriately.
 If it's in thetree, it's gotta be according to the left or right, according to whether it'ssmaller or larger than the key at the route.
 They give sufficient implementation of both searchand insert.
 Idon't want to spend a lot of time with this cuz I think this is a unsatisfactorysolution.
 And we start the k Pointer at thebeginning lo.
That's it's even going to merge with another big cluster.
 If you want, again, if you think that thethings we're studying are easy, think about the idea of actuallydoing an in-place merge.
 If get returns in non null value, then there's a value correspondingto that key in the table.
 And that will reset our instance variable, which is our stack,to this new, bigger array.
 But wewant to have at least M over two.
 So, say, four is supposed to be unio n with three.
 So we have less than M.
 Check if P and Q have the same ID.
 The constructor has to create the array and then go through andset the value corresponding to each index I to I.
 That's exactly log base 2 of N, so thegrand total of all the costs for the merge, which iswhere the compares are, is log N times N, N log N.
 And it's possible to prove that that produces a uniformly random permutation of the input if there's no duplicate values, assuming that you have real numbers that are generated uniformly at random.
 So,that's a, a really 1d range count is a very easy computation to perform in, inlog time with a binary search tree.
 The Java also allows remove().
 Insertion Sort is stable.
 As long as we're not at the root and k's parent, k over 2 is less than a of k then we just exchange it with its parent and move up.
 It implements the compare method that takes two points as argument and withjust a little bit of calculation is able to do the compare.
 For example we can say that the number of comparison and theworst case is O(N3/2) for the 3x + 1 increments.
 All we're going to do islook in the table and try to see if the key that's there isequal to the key we're looking for.
 The maximum end-point in the left is 22, and we're looking for 23, andwe're not gonna find anything there, so we just wanna go right.
 And that merge code is a good example ofthis.
 So, the weighted algorithm always makes sure that the smaller tree goesbelow.
 That's the one we just did.
 It's a little bit of programming language detailed but it's,it's really worthwhile because it allows us to use the sorts that we developed forany type of data in a type safe manner.
 For whatever reason a parent becomes the key and decreases, it might become smaller than one or both of its children's.
 [cough] And that's an example of building ared-black BST from our standard set of keys.
 This isthe average path in a tree, this is the, the worst of all the keys.
 To support comparators in our sort implementations we'll pass an arrayof objects and instead of an array of comparable and then, there's a secondargument passed a comparator.
 And we have four subarrays ofsize four.
 One myse alpha is forthe hit, one myse alpha for the squared for the insert.
 And again, to keep the code simplewe're going to assume that all the coordinates are distinct.
 We're goingto be able to sort the same things in different way sometimes and this exampleis a fine motivation of that.
 And the other is that itshould be the case that every table index is equally likely foreach key.
 So, here's an example that shows theeffect of doing the weighted quick union where we always put the smaller tree downbelow for the same set of union commands.
 And so, I'll just use thatone and pick an index at random and delete and that program took quadratic time andpoor Kenny, when trying to run his program for the huge instance that we asked foundout that it wasn't finishing.
And now, lg N is kind of a funny function.
 So this is, we'll start withone dimension as before and right away you can see that it's a more complicatedproblem than we've been dealing with.
 5's root isfive.
 So, if you have the keys in random order the binary searchtree gives efficient search and insert.
 The idea is that you create acomparator object and then pass that as a second argument to Java's sort routine andwe can do the same thing for our sorts.
 In the case of the grid implementation,they might all fall in the same square.
 And then we did a right rotate on the top node, and that transformed to thecase where our temporary four node is balanced.
It's not that much code.
 Just check for anintersection, if we find it ret urn if left is no we go right.
 Wehave constant time access to every element, but the space is proportional toN.
 On the other hand, maybe there is an algorithm that uses N log N comparesand also uses optimal space.
And again, when there's a lot of equal keys then there's going to be place whereone of those is chosen, it's partitioning element then a big chunk of the array getshandled just in a partitioning process.
 Well, just looking at one example you can see almost immediatelywhat to do to find the minimum, we move left from the root until we find a nullkey, that's where the smallest key in the data structure is.
 And the full pageabout to split then right below there's two pages.
 We have that's the, our first item in the list and we're goingto maintain an instance variable current inside this iterator which is the currentthing that we're iterating.
 Your music librarymaybe I, at one point, you sort it by the artist's name.
 Now, if the array is partiallysorted, it doesn't matter to selection sort.
 So, that's why we make a bunch of them and then we have a, a while loopwhich is just every 50 milliseconds clear the, the whole drawing and then move theballs a little bit and then draw them in their current position.
 So they felt that they got betterpartitioning than a random shuffling and it was also less costly and thengenerating random numbers including this change of state problem.
 And it'll probably be faster for simple keys to use hashing.
 So,our partitioning is complete.
 So,now the invariant might be violated so we have to fix it.
 Example at the right, a to b to c is not counterclockwise.
Stop here at t cuz that's bigger.
 Now, in this case, we have the 8, andwe only have to exchange one, and now it's got the 7 to its left andeverything is in order.
Operator, we put on to the operator stack.
 And that's to distinguish thoselinks from the other links in the binary tree so that we can tell when we'reinserting things which nodes belong to tree nodes and which ones don't.
 They're going to have a set of N objects.
 So you'd have to be a little carefulthat somebody is in there doing that.
 And so the first way we'll look at is called Separate Chainingand it's a very diagonal idea back1953, and the idea is just build a link list foreach of the table positions.
So let's start with the constructor, well we have a, a private integer array.
 So that's our problem, intermixunion, commands and connected queries and we need to be able to officially supportthose commands for a large number of objects.
 To maintain the sorted array in dynamic fashion is going to takelinear time you have to go through the whole thing.
 If the array happens to be already sorted,all insertion sort does is really validate that each elementhas got smaller elements to its left.
 And again, you could do this with a linked list or withthe resizing array but then, with array, you'd have to move all the larger ones overone position to fit the new item in.
 So, in, in fact, often, the purpose of a sort isto bring items with equal keys together for like the example that I gave where wehad cities and time.
 There is abook site and text book as well.
 In particular if you just haveN union commands on N objects which is not unreasonable.
 At the even levels, we think ofa vertical line, and the left sub-tree is all the points to the left and the rightsub-tree is all the points to the right.
 So, how do we find the point with the smallest y coordinate? Well youcould, you could sort, you could define an order and compare the points by ycoordinate so essentially sorting is the [cough] answer to that question.
 So, the basicselection sort method is to, in the ith iteration, find the smallest remainingentry and to the right of i or bigger index than i and then swap that with i.
 Well,if you think about it for just a minute, you see that what you need to do is justremove all references to value from any of the symbol table implementations that we'dlook at.
 And then, what we're looking for is to find or count the pointsin a given interval in one dimension.
 And we can move all those over.
 And then once it gets the second halfsorted, then it's going to go ahead and merge themright together to get the sorted result.
 And the first rule of the game that we have to thinkabout is, how can we make it so that we can implement one sort program that can beused by these three different clients to implement three different types of data.
 Seventeen, nineteen is at the root, so everybody with a le ft end pointless than seventeen is to the left, the left end point greater than seventeen isto the right and so forth.
 So, what we want to do is have an easy way to dealwith collisions.
 Going from a to b you turn left to get to c in the first case and you goright to get to c in the second case and we want to do a computation thatdistinguishes this.
 Andso, I think most students have had high school Physics and will be able to do, dothis Math or at least be convinced that the code that does this Math is correct.
But it's, easy to see from demo and from the diagrams that those are going to beconstant, guaranteed logarithmic performance for all operations, which iscertainly what we want in a symbol table implementation Now what about theimplementation? Well, we're actually not going to talkabout a direct implementation of 2-3 trees, because it's kind of complicated.
 So atthe beginning we're going to be fine.
 So in this case, we'll change the, connect three and four means that weneed to change the four to a three.
 You get long clusters and they're likely to getlonger.
And the exact number they use is not too, critical.
 Thereis a path from eight to three to four to nine.
 So, the one we're going totalk about now is called percolation.
 And that one generalizes to help us insert into a two node at thebottom.
 This things exist but they're not sowidely applied at in practice.
 But here's the situation that we're left with.
 And this code is straight forward way to implement comparators that you canuse as a model.
 P is less than R, so we look to the left.
 A way of evaluating a polynomial ora number.
Just a constant number of operations and that's why, this operation, is, ingeneral, efficient.
 It just uses equals.
 This is so called lazy approach to algorithmdesign where we try to avoid doing work until we have to.
Whenever we get a new one, then we throw away the smallest one that's there.
 So we have to look at the code that'sgoing to maintain that invariant as the pointer increments.
Because if we have a computational process that takes quadratic time, then it's notgoing to scale, we're not going to be able to do large number of particles.
 So, our cost model is the numbercompares.
 Sothe, search is, you know, just the same as we've been doing, just generalized.
Welcome back.
 Quicksortactually, they're up until the 1990s the most widely used implementation tookquadratic time.
 You might want to make sure that if you're advertising that you're doing a random shuffle, then you go ahead and do so.
 Sothat, that means you'd have, if you did exactly and [inaudible] + n/2 + n/4 and soforth which adds up to about two N compare so linear cross.
 So, that's inserting to a tree with the one node and make it a tree withtwo nodes.
 Each pass using about Ncompares for a total cost of about N log N.
 That.
 So now,let's look at the main loop for the event driven simulation.
 And so all that says is thatall the objects are independent.
 Is there a simple algorithm that is linear? And people, looked for along time for that, and actually it works out to be the case that we can prove thatthere is no such algorithm.
 But then we have anotherstudent who had some Java before coming to us and considered himself an expert andsaid, well, I'm going to use linked list because I could use Java's library and Idon't have to worry about downloading your stupid code.
 Lying in this table some pages getting anew key and eventually one of them fills up and splits.
 So, then your key would be a word or a string.
 We call that the swim operation.
 Use parallel arrays [inaudible] and thevalue array with the same index.
 And the other thing that we could dois we can use null and some situations are temporary situations to implementa lazy version of the delete() operation.
 In such a waythat, it's hard for someone else to find another key that collides with that.
 It's not agood idea to have lots and lots of, you know, operations in the same API.
 And then find the index associatedwith the key that we're searching for using binary search.
 And thenthe sort code can just use that compareTo() method, invoked in a sense of theobject like an entry in the array and as argument and another instance in theobject like another entry in the array to test whether the first is less than thesecond as in this example.
 X's color is stillgoing to be h's color.
 So let's, one way to understand the way that an algorithm works is tothink about invariants .
 So, now it'sless than the partitioning element.
 And you mightwanna ask, which points are inside the rectangle or how many points are insidethe rectangle? Or maybe what you are processing is rectangles.
 If you've got a large tree and a small treeto combine together what you want to try to do is avoid putting the large treelower, that's going to lead to long tall trees.
 Actually it usually crashes because it's recursive andit crashes the system stack.
 Supposed to search the right subtreeat 1 next, but we can prune that.
 There's not enough open site for there to be a connection from the topto the bottom.
 So lets look at it if there is no intersection in theleft, since we went to the left and then we have got, low less than max.
 But, in linear probing, to insert what we do is when we put it inposition I if that's free, if not we just look at I plus one, and I plus two, andwrap around to the beginning if we reach the end.
 But actually in practice it'smuch less than that.
 And here's the code that does it.
 We just moved things around locally withinnodes.
 And later on, we'll get it back to theleft again.
So we can just exchange J with our partitioning element.
 Actually not that much code is complicated, but not particularly more complicated than other code we've seen like rank, and floor, and ceiling, and that implements Hibbard deletion.
 And you can see that for a large arraythat's randomly ordered, the element that we put into place is going to goabout halfway back on the average.
 And what are we supposed to do then? Well, to maintain thevariant there we just need to increment i.
 But now you can see that, that localtransformation on the 2-3 tree completes the insertion.
Now, L is the middle key of that one, So we're going to split that 4-node into,two 2-nodes and move L to the parent.
 So, E is a key candidate.
 But we don't have the client to know whetherwe're using an array or link list or whatever internal representation we mighthave in mind.
 How to sort the points by polar angle?Well again we need to define what we mean when we're comparing points.
 And then proceeding inthat way, moving bottom up or moving from right to left, the next thing we do is butthen worry about a three node heap that's heap ordered and we're fine.
 It's going to be less than lg N and compares and it's got support for allthose ordered ST operations, and compared to and is pretty easy and natural functionto implement.
 Sothat's entropy-optimal and what that means is whatever the distribution of equal keysin there, this thing is going to use a number of compares that's proportional tothe best that you could possibly do.
 It's a traditional, text bookthat extensively covers the topics in the course, in fact many more topics than wecan present in lecture.
 In particular,all Java classes inherit a method called hash code which is returnsa 32-bit int value.
 It uses an arithmetic.
 Binary search trees is our first example.
 If we have a stack of size N,we have about 40 N bytes.
 Any uses of the resizing array,so many of the principles that we consider does also a, a link list interface.
 It's a little bit of anextension of the ordered symbol table API that we gave before and we're going tohave operations range-search and range-count.
 So, we implemented stack of strings but in applications wehave all different types of data that we might want to implement like stack of intsay or URLs or cars or vans or whatever data that we might be processing.
 Iwant to be able to create an empty set, we've got methods to add a key to the set,and to check whether a given key is in the set or not.
 So, this tree has got eight nodes in it.
 So this isa static method that is supposed to return true if the array is sorted and false if it'snot.
 so how are we going to fix it? So in the end researchers showed that after a sufficiently long sequence of random inserts and the deletes, the height of the tree becomes square root of n, not log n's, spurred event is hugely bigger than a log n, it might make the difference between acceptable and unacceptable performance in real applications.
 And now the integer that we'regoing to associate with each word is the frequency of occurrence ofthat word in the symbol table.
 So, since we're making array ofnodes, a node would have generics if we use to key in value.
 And that's called Heapsort.
 The construction, actually,it turns out although it's a little more complicated to prove, that it always usesjust a linear number of comparison exchanges.
 Then it'll put be on the top ofthe stack and then pop the top item on the stack which is now be, andthen pop the item most recently added.
 And what we need to do is just exchangethe 5 with every element to its left that's greater.
 Notice already that will meanwhen we get back to 0.
 People have come up with methods forgetting this done.
 So, there's alot of geometric properties of the convex hull that we can take advantage of todevelop an algorithm.
 And if it's array of objects,you can see that testing for equals can actually involvea lot of code and a lot of cost.
 Whereas on the other hand, sometimes the whole purpose of a data type is to maintain a changing value.
 If you have the convex hull, this computation is easy.
 And it'sessentially based on the idea of computing the slopes of the lines between a and b,between a and c and comparing them to decide whether you're turning counterclockwise or clockwise.
 But then, you might say,well, how many keys are there that are between g and k? In this case, there'sjust two.
 Alright, so now about, how do we do a, a search.
 So, what we are going to do is use internalleft-leaning links to glue the three nodes together.
 Doesn't seem like we're doing much except putting stuff on stacksand now, when we come to our right parenthesis and that's when it getsinteresting.
 Theidea of the lower bound generalizes this argument to figure out a number ofcompares that you need for a minimum to determine the ordering among N items.
 Slightly reduces the number of compares.
 That doesn't work i, t still becomes square root of n.
 So in order to look at every place in the table where L could be, we have tokeep looking til we found an empty table position, or we find L itself.
 That's the idea for solving any problem.
 Now we canpair H against the root of the right subtree of E, and that's R and it's lessso we have to go left cuz everybody to the right of R is bigger and H is smaller.
 So, that's a model for many systems.
 And then we can use, that property of the trees, in theanalysis to, show that, it's not going to be very many probes to get to any key.
 So here's abinary search tree let's do a demo of what different searches will look like in thistree.
 Hashing really at its core isa classic space-time tradeoff.
 We may need to fix it with the sync operation.
And then the height of the tree grows by one.
 Try to find any interval that intersects our queryinterval.
 Mcilroy, himself,actually found this problem that you could while the sort is running figuring out aninp ut that would make it crash.
So NCN - N - one, CN - one then the N, N + one - N - one N is just 2N.
 So it's not quite as goodperformance as we might like.
So this gives a feeling for the.
 Here's the 31x plus y ruleto combine all the fields.
 There's an easy way to do this based on CCW that is described here inthis text.
 And it doesn't take muchcode.
 A binary search tree is asimple and extremely effective data structure that can support all of theseoperations in a quickly, much better than binary search in an ordered array which isnot dynamic and slow for insertion.
get(word) + 1.
 And what about Mergesort? Mergesort is stable well,it's stable as long as the merge operation is stable and that operation is going tobe stable depending on how we code it.
 So here's just whathappens to the array for our small client example.
 So say we have this simplified dateimplementation that we talk about before.
 And it's a good exercise in object-oriented programmingshowing how just one implementation then we can use that same implementation tosimulate a number of instances.
 So left subtreeis [inaudible] right, okay? Otherwise, we have to check whether the max endpoint inthe left subtree is less than, the low point in our interval.
 So, now suppose we were supposed to add S.
 So first before we get to the code for insertion, we haveto look at the representation.
 And also in all different typesof scientific data processing, these things are extremely important.
 People often ask aboutprerequisites.
 So let's look at just inserting A into this B tree.
 So that's the second case.
 because there could be nopoint on the right subtree, on the right of this splitting line,that's closer to the query point than 3.
 We had one line of code to flatten the tree, amazingly.
 And we want to be able to find orcount the points in a given rectangle.
 Let's look at the meaning of those words.
 So, we knewthat the upper bound was N log, proportional to N log N and we just provedthat the lower bound is proportional to N log N and that means that mergesort is anoptimal algorithm.
 And this is very,very typical in geometric data, particularly in higher dimensional data,as we'll see in a minute.
 Now, what about when we get one that's greaterthan the partitioning elements? So, in that case, we exchange greater the oneover at the right with i and decrement gt.
 Take one of our symbol table implementationsand get rid of the code that refers to values.
 No entryto the right of the arrow is smaller than any entry to the left of it.
 So let's look at how itlooks now.
 But then we want these operations range-search and range-count.
 A search key and get all the associatedinformation.
And so bee trees are a generalization of.
 So it's a total of N log N.
 And that immediately gives this code forinsertion sort, which is similar to our code forselection sort and just as simple.
 Every path from the rootdown to a null link has the same number of black links that just follows directlyfrom the corresponding property for 2-3 trees.
 If we get to the bottom and our current nodeis null and that's falling off the bottom of the tree we return null and that'sequivalent to saying our buyer convention that, that key is not in our datastructure, or not in our symbol table.
 So, that's a sketch of a proof that the depthof any node x is at most log base two of N.
 This method was invented in 1961 by TonyHore, who won the Turing Award in 1980 for this and other work.
 We can use a two-dimensional arrayto directly index relevant squares.
 You can get to any one with onlyfive or six probes.
 Now it's true whencomputers only have a few thousand words of memory and it's true now that they havebillions or more.
 So now, we're gonna go back up the tree.
 Insert P, that goes to the right of M that makes M atemporary four node that happens to be balanced, so flip the colors.
So the transformation that splits that b, c, d, node and inserts the C into the3-node at the root, just involves, making that 3-node into a temporary 4-node.
 We have only one link and we can get rid of the node, but we have only one link pointing to it, but we have two links pointing down from it.
If you're interested in implementing this, you can come back to the slide.
 In this case wehit the right endpoint of line segment two.
 All right, so let's go back toour full implementation and this is just taking care of collectingthe code from the previous slides.
 Let's look at a demo of insertion sort.
sort() method again.
 And that approximation gives us, it'sabout two M+1 natural log N comparisons for Quicksort.
 We just use that dimension ofthe point to do the comparison.
 Delete the minimum key, delete the largest key.
Now the last element in the left sub array is the one that's going to get moved next.
 If we're sorting N items then let C of Ndenote the number of compares that we need tosort the N items.
 So, delete the maximum we have to do two things.
 So those are the basic operationsthat we're going to want to implement to get the associative arrayabstraction and then there's many, many possibilities for clients andwe'll look at some later on.
 So, here's a bunch of reasons that I justwent through for studying algorithms.
 So the invariant of that is thatthe array is always between 25% and 100% full, number one.
 And it's interesting to note we've looked atimportant and classic algorithms that are widely deployed but we don't have a, auseful, practical algorithms that are widely used that's got all of thesecharacteristics that's in place and stable worst case N log N.
 As far as we know, that one could be on the convex hull.
 Now, this illustrates something that youwant to do if you have a lot of bits, you want to try to involve allthe bits somehow into hash function.
 Duplicate keys, we may notneed N log N compares, we're going to look at the method that I guess that down inlinear time and a lot of situations.
 We justchanged the way we get to them.
 And that's, going to be a lot of work, and take N lg Ntime.
 This is more complicated to prove.
 Then let's do the search.
 Every 3-node has three links and two keys.
Now with this code, we're also introducing the idea of makingassertions just to make it easier to debug our code and to haveconfidence that it's correct.
 So that's the closestpoint that we know about.
 So, [cough] in this case, for example, forselection sort, when we do that first exchange oops, [cough] where we found theminimum A and B is in position zero.
 And they're all quite natural and intuitive.
 Here's a quote from one of Javas architect Josh Block, "Classes should be immutable unless there's a very good reason to make the mutable.
 That's a legal left-leaning red-blacktree.
 Ourproblem we were treating partitioning, equal of partitioning element as one valueless than as another and greater than as another.
 That's another proof by expansion.
 It's called a color flip.
 Now we're going to do the O.
 And they rebuild the whole treeand, and then because of the way they did this deletion, well, the end of the storywas that they had extended the client had extended outage because the implementerdidn't use the full algorithm.
 And so, symbol tables provide us with a way to provide a moreefficient implementation of, of this process when we have lots of zero entries.
 So we have to check, all the way up the path, themaximum in each node on the path.
 So, we have an assignment whereyou need to generate a random open sites in a percolation system.
 This is historically, an extremely, important problem.
 And we have some number of balls,however many keys we have.
So the easy case is if the key winds up in a 2-node at the bottom, like this one.
 It's gotone too many.
 So, we're goingto use a method less() that takes two Comparable objects as arguments and itjust returns, v.
 A bit more complicated because there's more to do.
In the, all during the partitioning process, the code is maintaining thisinvariant.
 And then we left out, left out the code where you print out the nine words thatyou want.
 The other thing is return the maximum.
 But still,this is a very efficient algorithm.
 So the black is theoccupied part of the page.
 It was proved actually a long time ago even before computer implementations that if you do that, you get a uniformly random permutation and it only takes linear time.
sort is a method that takes anarray a as its parameter and it, it's the first argument and it rearranges thestrings in that array to be in sorted order.
 All right, now the way we're going to use a complete binary trees to implement priority queues is to first of all associate information with each node.
Convert into a 3-node, Now insert C into that.
 And fiveand zero have different entries.
 And then after those two things are done,the whole thing is sorted.
 The problem, the real problem is that when youdo that you can't know much about the performance or you can't assume much aboutthe performance.
 But now, we start with the array in order, and actually it doesn't matter how we start the array.
 So with thesestraightforward changes at the comparator as argument to the sort and to less andmake array to be sorted array of objects, it's easy to convert any of ourimplementations to support comparators.
Again, studying this, a, a trace like this, gives a, a good feeling for exactlywhat's going on in the recursive program.
 So that's an animation forrandomly ordered items.
 And these methods are all widely used throughout ourcomputational infrastructure.
Now it's working on the left part of the right.
 And our data structure then will be a root thatpoints to a node in the tree and then that node will point to subtrees and that willbe the data structure that we use for symbol tables.
 And now we've added it to the heap by just incrementing in and putting it in there.
 And the way that it works is we are always reducingone case to another.
 And it's very typical for keys to comefrom an ordered set, for example, in the dictionary application.
 And then wecome off a null link, and all that says is that there's no place in this tree where Gcould be so G is not there.
 And that method is the basis for the Graham Scan.
 We might have to use resizing to make the array grow.
 That's what binary search provides for us.
 So here's just simple example onhashing in java.
 But still again, using theory as a guide maybe there's a way to decrease costs a little bit from binary heaps.
 The basic plan is tothink of the symbol table as really try to reduce the problemto being like an array.
 Alright so now we're gonna look tosee if we have an intersection what a.
 So the first point that's the closestwe found so far to the query point, so we'll save our number 1 as the distance.
 And again, that's a little harder to do withsomething like a red black tree where we have performance guarantees.
 Now, the problem with binary search is,well, not necessarily the problem, but the situation is that whenit's time to insert a new element, we have to move everything larger over oneposition, just like an insertion sort.
 And then we're going to maintain an Ipointer that moves from left to right, and a J pointer that moves from right to left.
 And it's also, used in the, Linux kernel,and in many other systems.
 So here's a visualization of what the practical Mergesort might looklike, and this is with big cutoff to small subfiles.
If this object is greater than the object given as argument.
 So what you want to do, is given a word, find all occurrences of that word alongwith immediate contexts.
 And then,also we're going to put as the first thing that happened always a, an event that saysredraw everything.
 That's quite amazing.
 Now, it's important to not create theauxiliary array in the re in the recursive routine because that couldlead to extensive cost of extra array creation.
 So, our client is going to called fileindex.
 Eventually, you're going to get an overload of memory and you're going to have to rebuild the thing, or clean out the tombstones in some way.
 Resizing-array implementation.
 So symbol tables are ST is the type,symbol table, they're generic in key and value.
 The only possibility is c, a, b.
Now, we'll look at Shellsort which is abit elementary on the face of it but it's not at all elementary as you'll see.
 And then we move one more to the left, now we're looking at the R.
 What we do is put a bit, a color bit in each in the nodeclass.
 So, we start bycreating an empty set of strings, and again since we don't have associatedvalues, we just have the one generic for strings, and then create a new inputstream from, from the first argument so that's the name of the file that containsthe exceptional words and so this just reads the strings while the input stringis not empty and then adds the m to the set.
 R is fourteen,empty, put it there.
 So we need to remove this cheat andwe will, but the code is nearly trivialif we have the capacity.
 Do the same thing in the vals array.
 And that has to do with whenthe array is partially sorted.
 And then, if we want to look up theIP address associated with a given URL we can just type in URLs and the client willreturn the IP address, it'll do the look up.
 Notice again that it depends on the randomshuffle at the beginning that's going to be important for performance.
 Otherwise, if it's a string that'snot equal to the hyphen character, it'll just push it onto the stack.
 And all of these things allow us to makebetter use of memory, allows the table to become nearly full.
 Its a probabilistic guaranteed fast algorithm.
 So this is, and actually the versionthat we're going to, looking at is called left-leaning red-black BSTs.
 Two and one, that's an easy one.
 Now, it's key that the uniform random number be between zero and i minus one.
 We're only counting the number oftimes we access the pages.
 But actually, in most cases, you want tofind the way to use all the data.
 So in the first case, it's much, much faster than selection sort,linear instead of quadratic.
 So in this case, we have to search both, there might possibly be a closerpoint than 1 over in the right.
 And the idea behind that is to think aboutjust associating one value with each key.
 And if it's unsuccessful, you can use that rank to figureout where to insert the new key.
The value that arithmetic expression is 101.
 So, we'll build a new array of keys and we have to use an ugly cast because of generic arrays in Java, and that's where it's comparable and we need one more than the capacity to handle this thing where we don't use position zero.
 Now, ifthe priority queue has more than M items because we inserted that one, then we wantto delete the smallest one there and that way, we're keeping track of the largest M.
 And that's useful for a couple ofpurposes.
 If you have a hugenumber of operations and every one of them is proportionalto the symbol table size, then you're just not going to be ableto support huge numbers of keys.
 And also by convention, itreturns a negative integer for its less zero if it's equal positive its greater.
 So we could have,billions of objects, and hope to do billions of union commands on them.
 And that willfill in the fields and then, we put that transaction on the priority queue.
 In this case it's the S.
 And the idea is to use three simple rules, you get something very close tothis complex flocking behavior.
 And then, it's easy to seethat what you should choose is M to be about square root of N.
 It comesinto the node on the left.
 So that's something that isa convention that's built into Java and that enables the hash code to be used forhashing.
 And for insert, you just take (x,y),figure out which square it belongs to.
 The only instance variable is a link to the rootnode called root.
 So, here's the basic idea for proving a lower bound forsorting.
That 3-node gets converted into a 4-node.
 So we'll maintain two pointers,the first item in the queue and the tail, which is the position forthe next item to appear.
 Anadversary can learn your hash function and just send you data that causes hugeperformance problem by just making all that data hash to one particular item.
 And why is it true that the depth ofany node x is, at most, log base two of N? Well, the key to understanding that is to,take a look at exactly when does the depth of any node increase? When does it go downfurther in the tree? Well.
 We get to move things around for free.
 What, what are going to be the cost of all of these things.
Actually, some implementations of Quick Sort out in the wild don't have thisproperty, and they suffer a little bit in performance.
 So, that's the setup.
 We start with therandomly ordered input and you can see that it gets more and more in order oneach time that we h-sort for the decreasing values of h.
 And then the actual sort is takes just theone argument of the array creates the auxiliary arrayand then uses that.
 So, those local transformations,converting a 2-node to a 3-node or converting a three to a four, and thensplitting and passing a node up.
 Well, let's look at a simpler problem.
 Look in the middle of the right half.
 21 thru 23 to seventeen, nineteen.
 Sofirst thing is if we hit a horizontal line segment.
 And with the Swiss knife implementation with so many operationsit's hard to know whether or not the particular set of operations that yourclient needs is efficiently implemented.
 So that's the root of three is nine, going up that root.
 The first.
That's still not empty.
 In fact there's a file out there in your book site and get it that willactually break the Java system sort.
 Now,usually it's going to be good enough but it's definitely worth while to understandwhat's going on with different sorting algorithms in order to even find improvedperformance over the system sort.
 But in another situation, you might want to sort it by song names tolook through it by song names.
 So we want to support the followingoperations.
And we have everybody to the left.
 So that's a short demo of linear probing hashing.
 And it's a very interesting extension ofthe ideas that we've looked at for symbol tables for all sorts of familiarapplications.
 And its thefastest and most useful in practice particularly if you make improvements todeal with duplicate keys.
 We say that our generic type Key extendsComparable of Key.
 And again as with priority qs the bestpractice is to use immutable types.
 While, they're both the same, soi t goes with the left one.
 When you have two particles there's definitely moremath.
And that completes our treatment of sorting algorithms with the Heapsortalgorithm.
 There's a lot of different ways toimplement callbacks and that's programming language specific.
 All of which are private as usual.
 If you got one bigparticle like a pollen grain and lots of little particles like atoms molecules andbouncing against it the big one is going to move about randomly.
That random shuffle at the beginning is important and needed for guaranteeingperformance.
 So, what they did in this implementation was theyjust put in regular Hibbard deletion in the binary search in the red-black BST.
 Number of items that have to be touchedduring quick sort.
 So we don't need so much any more generalprograms for manipulating linked-lists.
 So, That's a, quick sketch of the proof of this proposition.
 We use the Java language, but we don'tdwell on details of Java, we mostly use it as an expository language.
 And if you give it toby section comparator, it will them in order by the second field very convenientfor all kinds of data processing applications.
 The amount used is between 8N and 32N, depending on how full the array is and just a quick analysis of the amountof space that arrays take in Java.
 Now with i equals two, i pointing to the second card, we generate a random integer between zero and i.
 And eventually we get down to smallsubfiles, actually our code doesn't do anything at all for subarrays of size one,so we just leave those in gray, and then it does the right subfile, and so forth.
 First, it puts all the ones to theleft on the queue.
 7 can't be on the convex hull.
18 and soforth.
 And then we just declare that that's part of a heap and that node, well if it's less than its parent, we're fine.
Eight and nine are already connected.
 So that also is a foreliner toimplement the stack push operation.
 Here's a way to get shuffling done using a sort, it seems like the opposite.
 Nowthe next largest element in the array is now at the root of the heap.
 Maybe there's a class number, there is a grade, there's a phone numbermaybe an address so we refer to an item and it has a record or the informationthat we're going to sort.
x) and we see that calculation here gives youimmediately whether it's counter clockwise, clockwise or co-linear.
 So if we're going to union six and one,then we have to change entries zero, five, and six.
 And we'lllook at the next lecture of what it means the divine ordering among objects, littlemore general than what we do for sorting.
So you got a visual feeling of how this sort getsthe job done.
 So thissimple thing just tests is a node red.
 But now, let's look at the computerscience code.
 This gets to the intellectual challenge of developingalgorithms.
 Could, could hardly be simpler.
 Continue until we find P.
 We have hundreds of different implementations.
 Will create a new set for that word andput that in the symbol table, and then, we simply get the set associated with the key and add the newword to that set, the new file name to that set.
 But still, we're guaranteed thatthe amount of the memory that we are use is always only a constant multiple ofthe number of items actually on the stack.
 So, that's one importantreason to study algorithms, their impact is broad and far-reaching.
 As we sawwhen doing the implementation, both the initialized and union operations involvedthe for-loop that go through the entire array.
 So everything to the left of i is inascending order, everything to the right, we haven't seen it all yet.
 You can sort from that heap and that's significance be,significant because it's the first sorting algorithm that we've seen that is both inplace.
 It's certainly worth adding them.
 But selection sort is not stable.
 And so we'll do a sync on the S and bring it into a heap ordering, sothat's with just a few exchanges we got that whole array heap order, and now whatwe want to do is take advantage of the heap ordering in the array to do a sort.
 We start our I pointer at the left hearton the left half.
 Probably should do that.
 Now, we have athree node, but the red link is leaning right so we have to rotate.
 So first we search the leftsub-tree that's the one below.
 One thing is, that you can traverse the convex hull by making only counterclockwise turns or left turns if you're looking at the screen here.
 And we aregoing to change things when something happens.
And by the way, if we find a key that's in the tree already, then we just want toreset the value.
 Except that it compute a skip that wouldmean that, that only look at about every eight key and they wouldn't have to doquite so much work performing the hash function.
 So the way we'll set that up is tothink about having a list of files a list of words in a file that are exceptional insome way.
 Seven and two seven goes to be a child of 2's root which is one.
So this is the implementation of the ball class.
 And it might have occurred to you while we are looking at thesealgorithms.
 We have a constructor tocreate an empty stack.
 Down at the bottom, andit's optional for this course, we have a text book.
 Well, you can see from this structure that we'reall set to do that all we need to do actually is not change any links, justchange all the colors.
 And again it 's pointing to one that'sequal of partitioning element increment i.
 In Java, there's an implicit mechanism that says that any such array ofobject is going to have the compareTo() method, then the sort function calls backthe compareTo() method associated with the objects in the array when it ever needs,whenever it needs to compare two items.
 It was named as one of the most importantalgorithms of the twentieth century and it's widely used for system sorts and manyother applications.
 It could be that there aresome increment sequence out there that make Shellsort more efficient than anyother method, any of the sorting method that we know for pratical file size, noone can deny that.
 So when we have these types ofdata structures and data types that are precisely defined, like stacksand queues and so forth, what we want to do is completely separate the detailsof the implementation from the client.
txt except was, it,be, and of.
 It's possible to implement symboltables that allow multiple values with the same key and so forth.
 Sixis occupied.
 Otherwise, we increment i.
 So nowwhat happens here, now i is pointing to a bigger one so we're going to exchange itwith the one at gt and decrement gt again.
 So standard implementation of this is quite easy.
 And so if there's a conductor from top to bottom then the thing conductselectricity.
 Still has to go through, even ifit's totally sorted, still has to go through to the side where that minimumelement is.
 So now we have three,four, eight, and nine.
 And it doesn't shrink back to four untilafter there's only two items in there, and then it shrinks, and so forth.
 So, again, considering it forthis simple case will pay off later on.
 Then thesecond pass again that's only a two liner, we exchange the first element with the oneat the end and then decrement the size of the heap and then do a sync operations.
 So again, go towards the query point, so I'll go to the top first,and that takes us to 6.
 So the end result would be likethat, with, no keys in the heap, but all the keys in the array in sorted order.
 In well, this is, the very special casethat you're very familiar with.
Now, if that parent were a 3-node, it would become a temporary 4-node and wouldcontinue the process moving up the tree.
 All of these operations are very useful forclients and we'll see plenty of examples later on.
 Really often what we're doing is just inserting items into a collectionand then, later on, iterating through the items that we have.
 I, the current entry in the left half, j,the current entry on the right half and k, the current entry in the sorted result.
 So that's the standard recipe.
 Or, you could think of it as, as water flowing through a poroussubstance of some kind.
 It generalizes thestack and the queue and gives us a data structure that we can use to effectivelydesign algorithm of all sorts.
 For, and for array,it's even simpler.
Next we'll look at separate chaining, acollision red solution strategy that makes use of elementary link list.
 And we will skip the details.
 Ituses two quick sort for primitive types of data and a two mergesort for objects.
 But with a geometric algorithm likea 3d-tree you could get the time to n log n that enabled all sortsof new scientific investigation in this example of the use ofalgorithms to enable new research.
Arrays and then all you need todo is invoke Arrays.
But the advantage of that might be that removing the maximum is easy.
 So, we'll talk more about that in a minute.
 So, in this case, we aregoing to write a client called Lookup CSV that [cough] is going to take threearguments.
 So our challenge is to look formethods that give us more efficient implementations forthese search and insert operations.
9 which is 0.
If the parent was a 2-node then the transformation is a local transformationand if you look at where the links are, then it's easy to see by induction that ifthere was perfect balance before there's perfect balance afterward,Because we didn't change anything about the perfect balance in any of thosesubtrees.
 We dothe standard BST insert, color the new link red, and we do the rotations that weneed, either one or two rotations to balance the temporary four node, and thenwe flip colors to pass the red link up one level and then remind me to rotate to thatto make that one lean left.
 This is a very concise code thatotherwise we'd have various cases about saving which link we went down in order toreset that later on.
 Here's maybe a more familiar sort client that sort strings.
Those are remarkably small numbers, so we're going to have guaranteedperformance, even for huge databases, We're going to be able to guarantee thatwe can get search and insert them with just eighteen to 30 operations and it'squite remarkable, really.
 And by Stirling'sapproximation, we know that log base two(N) factorial is proportional to N logbased 2N.
 Left tree can be null and right treecan be null or both.
 That's theway that we set it up.
 So, with the priority queue abstraction that'snot too difficult to do.
 We use to implementlinked list in all linked data structures throughout the course, weuse what's called an inner class in Java.
 There's a lot of detailed data and the time and maybe thewhole goal of the sort is to group them by cities so we can ship out the data foreach city, to each city and there's plenty of other examples like that in dataprocessing where we find maybe remove duplicates from a mailing list or all thejob applicants that we get, we might want to sort them by the college attendant.
So split into two 2-node and pass the middle key to the parent.
And the concept is very simple.
 And now, we've gotta find BST.
 When it'shigh, it is going to percolate.
 We assume that the array consist of Ndistinct values there's a position created that describes the performance of anyalgorithm to compare sequence done by any algorithm to determine the N factorialdifferent orderings.
 It's guaranteed that the longest path which is alternating red andblack can be no more than twice as long as the shortest path which is all blacks.
 So H now, the hash valueof H is four.
 And that's really important, because itmeans you can put them into your code to check whiledeveloping.
Now we'll look at our first implementationof an algorithm for solving the dynamic connectivity problem, called Quick-find.
 Computational complexity isvery useful way to help us understand properties of algorithm and help guide ourdesign decisions.
 And those statements can be borne out in practice,because the hash functions approximate random, the math assumes random and theformulas predict what actually happened in practice.
 And again, as we know,such an algorithm is not going to be practical, for huge numbers of linesegments.
We apply for n - one we get one less here and we can throw out a lot two over n.
 So, how are we going to dobetter? That's what we'll look at next.
 Let's look at an animation of selection sort in operation.
 We have a good amortized time, so totalaveraged over the whole process is good.
 It's in place.
 So we're not going to allow null values.
 The operandstack the operator stack is string, it could be characters which is just ouroperator.
 Then it computes the value of the midpointsame way as we did for a binary search.
 So for linked lists, every operationtakes constant time in the worst case, that's a guarantee.
 So we can do about twice as many itemsin the trace in the same amount of time.
 You run Quick Sort and you count compares.
 So, that's all the code for doing the bouncing ball simulation.
 A fundamental andextremely important data type that have led to all kinds offascinating implementations and we're going to look at severalof them in this course.
 So, what we are going to do with thisclient is specify with integers which field is the key, and which is the value.
>> Does that help you with the ladies? >> So not only is there some excitement inthat dialogue but it's also technically correct which you don't often find withmath in popular culture of computer science.
 Consider it as aevery time it hits some line segment as an event where we have to do something.
 It's extremely easy to codeup as you can see from this code.
 We pull out the current item and then advance the current reference andreturn item.
 The datastructure that we're going to use to support the algorithm is simply an integerarray indexed by object.
 And another natural way to implementa stack is to use an array to store the items on a stack, solet's take a look at that.
 They have to be in the same class and well there's a couple of differentways to check about the same class and that's another religiousdebate that we'll ignore.
 And itreally forms the basis for what we're going to do.
 There's going to have -2 to the 31st.
 And there's many, many other applications including scientificapplications where say, in genomics people use symboltables to keep track of finding markers in a genome andagain many other applications.
 Because if you're looking for thesmallest, you can just go through the array and find the small or the smallestin one pass through or if you're two, you'll find it and two passes through.
 The math doesn't quite work out right.
 Another reasonmany people study algorithms and I suspect many of you, is it's necessary tounderstand good algorithms, efficient algorithms, a good data structures inorder to be a proficient programmer.
 Okay then,it's one of the detail that Java takes care of and that's what about primitivetypes [cough] so the generic type that we're using is for objects and you know,we're casting down from array of objects.
 So, that's the node that's going to be the new root of thethree nodes so to speak.
 We want to fill up the memory with stuffto sort and then sort it.
 Usually, we provide two implementations: one that's max oriented, one that's min oriented so that nobody gets confused and they're the same except less and greater switch.
 And, in order, it's just a simple recursive method.
 And we'll leave that as an exercise.
 Alright.
 There's algorithms in physics for understanding physical phenomenon thatwe'll look at an example and many others on this list.
 This animation does the whole h-sort for each subarray.
 And same for deleting.
So that's more compares than Mergesort uses.
 If you want an in depth review, we have a full text book called, AnIntroduction to Programming in Java: An Interdisciplinary Approach.
 And then put the value associated with C.
 And that's easyto convince ourselves of that just from, from what we did in the demo.
 It starts j at i, and decrements j, exchanging j withthe elements to its left, a of j with the element to its left,a of j-1, as long as a of j is less than a of j-1 orj is bigger than 0.
Now we'll look at insertion sort, which is another elementary methodthat interestingly has quite different performancecharacteristics than selection sort.
 For that is C of N over 2, ceiling of Nover 2 for the left and ceiling of, floor of Nover 2 for the right.
 And an experienced programmers know thisand it's not difficult to arrange for the natural types of data that peopleare going to use for symbol table keys.
 In this case, we use single letter keys.
 But this general purpose implementationstops the pointers on keys equal to the partitioning items key and we'll take alook at why that's important in a minute.
 And we do that by juts by notputting too many keys in to the table.
Now it's working on the left.
 And there's also a variable called count, which is the number ofcollisions of particles have been involved in.
 Well in his original paper in 1961 Hoare gave a solution to the selectionproblem based on partitioning.
 And we just say, we're going to update everything every dt seconds.
 And somehow algorithms take advantageof the ability to use null in this way.
 If you're goingto implement it compared to students by section, then it'll return just thedifference of the sections which is my minus if less zero if equal then plus ifgreater.
Now, Quicksort itself then is going to be a recursive program that uses thatpartitioning method.
 If it's greater we move the element i overin increment i.
 So in this case our query point isover here in green and our algorithm's going to want to return point 5,that's the closest one to the query point.
 Wedidn't, that's the whole poin t was, we don't represent zeroes.
 If you want a new string, you have to create a new string using concatenation or some other operation.
Now, the constant depends on the implementation, exactly what kind ofmanipulations we need to do to convert, 3-nodes to 4-nodes and so forth.
 It's a little bit asymmetric.
 So let's start by just looking at vectors.
 And if it is, we move the element of jover in increment j.
 So, here's what our table, will look like,when we finish the implementation of 2-3 trees.
 In this one of many different algorithmsthat have been studied for this.
 That is everything,every type of data in Java has to support an equals operation, that meanswe have to test whether they're equal.
 First one says that if v is less than or equal to w and w is less thanor equal to v then the only way for that to be true is if they're equal and thenthere's transitivity.
 So, the simulation has to be careful to take thatinto account.
 And then fromthat, you can figure out how many keys there are or return them all between theindex, the lowest one in the range, index the highest one in the range.
 That's the Quick-unionalgorithm.
 And that's an association that'swell known to biologist and then you can use this lookup CSV client to quickly getthe name associated with any given codon.
 And then that key is going to have all those keys in order by induction.
 So now 5 comes in, that's to the left of 4because it was partitioned at a vertical and 5's going to partitionin a horizontal.
 On the other hand, balanced searchtrees have a much stronger performance guarantee.
 You can't associate null with any key.
 Now, that element which went from the bottom to the top is most likely going to violate the heap order, it's going to be smaller than one or its both of its children, so we do a sink.
 Those are some basic data structuresand implementations and it seem quite elementary and simple but actually rightaway we can get to some very sophisticated applications of these basic concepts andthat's what we're going to consider next.
 They the expected number of comparisons isconcentrated around this value.
 But we're gonna store the, largest endpoint inthe subtree rooted at that node.
 Element in the heap in the largestposition in the array which brings that element into its final position in thesorted array.
 So now we're going to have tolook at can this code be effective for large problems? Well unfortunatelyQuick-union is faster but it's also too slow.
 You could wind up with a long skinny tree.
 And in yourexceptional list would be words that are in the dictionary.
 So here's an implementation of that.
 So the Javalanguage for that is in the class header.
 So here's the corresponding API forQueueOfStrings.
 So, given a BST with someof the links colored red that has those properties that's going to correspond to a2-3 tree.
 So insert, find,delete, and find any interval that intersects.
 In to.
 Now,the height of the tree, as I just mentioned, is the worst case number ofcompares.
 Now those two particles'velocities have changed , essentially that invalidates the future collisionsinvolving those.
If there's a two, a 3-node, it takes more compares than a 2-node,So, it's complicated to analyze.
 So we just throw a point 3 out.
 Now, there's another scenario where a key becomes smaller.
 But it's only going to be fast, ifthe, table size is set appropriately.
 In this case it's not because one of the children is larger, sothat's where things are going to start.
 So we, to add it at the end, so first thing we need to do is save a link,the last node.
 So, the analysis now says thatthe average running time per operation forwhatever the sequence of operations is, the average running time is going tobe proportional to a constant.
 And in your list, might be kind of short, which would be thestolen cards that you know about, and you'd want to run a, a white list filterfor those cards and print out in your long list of transactions which evertransactions have that stolen cards, So, that's just a couple of examples ofexception filters.
 Take it off theheap.
 So, you can imagine a creditcard company looking for fraud - it's going to care about keeping track of the largesttransactions.
 That's our first collision resolution method, hashing with separatechaining.
 Also you could just not do anything forsmall arrays, and then do the insertion sorting in one pass at the end.
 Algorithms play an extremely important role in thisprocess.
It's a few arithmetic operations to do the hash versus lg N and compares for thebalance tree.
 Many of you probably implemented stacks inan introductory programming course, but we'll do a thorough introductionto implementations right now.
 One of the practices that will follow often inthis course is to check our API design before getting too far into dealing withthe problem, by building a client that is going to use the data type that wedevelop.
 Increment i, generate a random integer, this time it's going to be the first one again, swap them.
 Much too slow.
 And there's some better system support in Java for strings thatcache hash code means that you don't even have to compute the hash if your, yoursimple table for strings is in an inner loop.
 Now, let's just talk roughly about what I mean bythat.
 Butactually this situation is where it could be red.
 So lets look at how we implement those,first using linked list and then arrays.
 And so,suppose we have a large number of such line segments and what we want to be ableto do is to find all places where they intersect.
 Be, becausesince there's no intersections in the left sub tree high has gotta be less than C.
 Quadratic time worstcase but that's unlikely to occur if you do the random shuffling.
 And so you can kind of immediately arrive at that performanceeven for simple clients.
 What about the analysis of insertion sort? It's more complicated.
 After about natural log M tosses,every bin has at least one ball.
 And the algorithm that we're going to look at, called the Grahamscan is based on those two facts.
But one of the big advantages of Quicksort over Mergesort is that it doesn't take anyextra space.
 And this assumption, again, it would work.
 In fact, maybe ten times what's in the book,including a summary of the content.
 Let's take a demoof how Heapsort works in our example.
 So in the example down below here, if we have this file called tobe.
 So we pick some othersmall prime number and for each field we multiply by 31.
 So the way that it's convenient to set up a symbol table is to implement theso-called Associative array abstraction.
 And implementing that in code is really easy.
 And we flip the colors and we have a single fournode.
 Plugging in N log N we get the desiredresult.
And so, for example, what this table shows, if you were to tryto use a insertion sort for a huge file, say a file with a billion elements,on your PC it'd take a few centuries tofinish.
 So let's see how that looks in a demo.
 And the quicksummary is that every one of those operations, while ordered iteration isoptimal, it just gets them in linear time.
 Try some technique to discover one and try to saysomething about the average-case performance of Shellsort.
 So, it will get added to, as the right link of A and every time weadd a node we just create a red link to its parents and so, that's changing thetwo node into a three node.
 And since stack is used inthe inner loop of some algorithms, it's important to think abouteven faster implementations.
 So how we're going ti implement that? Wellthis is the basic problem that is very similar to our symbol table problem.
297and so forth.
 Where for each digit, you just multiply.
 So that's our skeletonimplementation, let's look at the keys.
 If we're going to implement our own typesand then use those types as keys and symbol tables you have toexercise a little bit of care and we'll talk about that briefly.
 We have the swim and sink functions that we showed earlier.
 And that's why so manysystem programs refuse that.
You have to be a little bit careful of that and even if everything is randomizedif there's lots of duplicates and the implementation is not done quite right thequick sort might take quadratic time.
 And this is a very common operation, say, in databases.
Now, all collisions are, might not happen so we might have two particles that are ona collision course that and we're going to predict that point for both of thoseparticles, you know, even right at the beginning.
 Now, if the, the keys are inserted inrandom order, we know that height by analysis, is going to be proportional tolog N.
 We have an inter-for loop that for j, if it finds asmaller one, resets min and then once we've looked at all the elements to theright of i we exchange the smallest one with i.
 We'll see later Kruskal's minimum spanning treealgorithm, which is a graph processing algorithm which uses Union-find as asubroutine.
 When we insert, we're going to add the item at the endof the list instead of at the beginning.
 And then draw, it's just using standard draw.
 In this case, it's the one to the left and we swap those.
 And then, this is just for simplicity to get this done andjust part of a lecture.
 So, the code isn't quite as simple as you might come up within thefirst instance that you try.
 Sonow R exchanges with M.
 So three and eight now so to connect three and eightnow three and four have to be connected to eight.
 Nowhow we are going implement or solve this problem or you can think of lots of waysto go ahead and solve this problem of finding the largest M items in the streamof N items.
 So, there's a lot of theory that goes behind thealgorithms that we use.
 It depends on the arraybeing randomly ordered.
 We can do search in worst case, in averagecase, in time proportional to log N.
 You can kind of switch the role of theinput and the auxiliary array every time youmake a recursive call.
 And then in that case, when all the keys are equal,it's going to divide at exactly in the middle.
 And the way to prove this proposition isto from examining the code, to write down what'scalled a recurrence relation.
 Sowe just rotate left H.
 So we're going to have nodes in the linkedlist that have key value pairs.
 That's, that's really adesirable way to look at it and let's take a look at that option.
 So that's a tradeoffthat the client can make.
 The cost of computing the hash function can mean that something like redblack trees will even outperform hashing even for just searching and insert.
 Say, one-half N log N compares.
And then it calls the recursive method that takes as arguments the limits of thesubarray that's gonna be sorted.
 And when we remove, we'll do the same,we'll take it off at the front.
 If neither one exhausts, we need exactly Ncompares.
 And then in that case you get an Nlog N compares.
 And that allows us to model the situationwith a so-called Bins and Balls model that directly relates the study of hashfunctions to classical probability theory.
 Essentially if you have M entries in the hash table and Mkeys the link of list you're going to look at is about N over M cuz they're evenlydistributed.
 So how about implementing a hash code forour own type of data? And so our transaction type might have a couple of instance variables,a string, a date, and a double.
 And is to the left, so we're going to haveto search the left sub-tree of point 6 and that one is empty andnow we return and we're done.
 And that pretty much wipes out clustering but it, it is moredifficult to implement delete for that one.
 One is an, what'scalled an upper bound which is a cost guarantee that's provided by somealgorithm for solving the problem.
 We look at eight, and we put itthere.
 Every item is put in to it's final position with just oneexchange.
 Same way we did for sorting methods.
 So, it's an interesting question to think about forsure.
 Inthis implementation, the Date class has three instance variables.
 If that comparisoncomes out left, here's how we do the insert.
 On standard input.
 No intersection in the left means no intersections at all, sothose two cases is enough to show that this algebroid finds an intersection, ifthere is one.
Rearrange the terms, so we get n+1 cn-1 and then divided by n, n+1.
 You can figure out from the last index when you don't find yourelement that you're seeking.
 So what we have to do first is to rearrange the keys in the array to heaporder it.
 We need those procedures that implement those Physics rules for everyparticle.
 Now that parents of 4-node and that has tobe split, And we create a new root node.
Or, did we use comparators anywhere here? In, this Index will tell us no.
 Andthis was taking a look at the Qsort that a user found was broken and, and now, thismethod is incorporated into some plenty of system sorts.
 It's a very small number compared toN.
 The right goes to the value stack and nowwe got a lot of stuff on the stacks and we got through right parenthesis and that'sgoing to finish up the computation, take the top two items off the stack and thetop operator off the operator stack, perform the operation, put the resultback on the value stack.
 And then that makes that temporarily overful.
 For queue,we examine the item least recently added.
 So we need to look for a better way.
 But we mentioned this example to illustrate how even asimple algorithmah, can have interesting and complex analysis.
 So let's look.
 So, we take off the toptwo things, we do the operation and then we put the thing that we get onto the valuestack.
 But simply can'tsupport a huge dynamic connectivity problems.
Once we have it arranged in that way, then we recursively sort the two parts.
 So let's, we have 2N over 2s and then for each one of these we have divided into Nover 4s and each one of those 4N over 4s has anextra cross for the merge of N over 4.
 Findthe smallest, swap that with i, increment i.
 So, here's the idea.
 So it has the infrastructure that allows us tobe used for all types of data types and all types of ordering so it's got a methodthat implements comparable then its got methods easy compare order.
 And so but, but they still thought that it should be balancedand it shouldn't matter much.
 Now,that's not quite as good as totally flattening actually in practice that itactually is just about as good.
 So this well illustrates that youneed to use all of the data in the hash function and sometime we do a closeranalysis.
 Where, we work with continuous blocks of data that are big.
Stop her at I because that's less.
 So, then that tells uswhat time it's going to be next.
 Now, there's an important consideration that we have to bring up related to the programming language, and this is a more general consideration and usually we bring into focus in algorithms but it's worthwhile mentioning.
com has got this IP addressthat's shown if this line here in the table, and so forth.
 That's an example of a, anexception filter.
 And we define an array to bepartially sorted if its number of inversions is linear,if it's less than some constant times N.
 The same data on different sortkeys, different orders.
 So again we use the File class from Java and we use, we go anduse the listFiles() method from that class to get an array that contains all the filenames in the given directory.
 What we're going to do is we have our end keysand we'll have them in an array.
 But otherwise, usually it's a CCW call in this code which again Iwon't go through in detail as an implementation of a comparator for two Dpoints.
 And this seems to be a problem, we can't be supposedly having a dynamic situation that is going to allow support of lots of different inserts and leads and in the end, wind up with a less balanced treat.
 And another property is that youcan't sort moving less data because selection sort does just a linear numberof exchanges.
 All right, so there is equalities, now equality again we're going toget a programming language issue but still was important to be explicitabout what's going on with equality.
 Alright, here's the code corresponding to the process that we justdemo.
 And then range search is only findthe squares that intersect the query and process the points in that square.
 But what's nice about data driven code is now that the code's workingand again we, we're not saying that this is a trivial code to write but it'sdefinitely manageable.
 Down below.
 Now, it was very expensive.
Now we're going to look at binary heaps, which is an ingenious and very simple data structure that's going to help us implement all the priority queue operations quickly.
 They, most of theentries are zero.
 So, what we do is try to figure out why, find a way to addresswhatever's causing that problem, find a new algorithm and iterate until we'resatisfied.
 So the codeimplements the invariants.
 We have to work through other cases that can arise but there's nottoo many so we'll work through and we have the basic operations, left rotate, rightrotate, and flip colors.
 So, this is so when we have the GCD function, computing thegreatest common denominator, greatest common denominator p and q is greatestcommon denominator of q and p mod q and it just calls itself until q gets to be zero.
x - a.
 Now, in other situations,maybe they're not comparable and all we're allowed to use isto use the equals operations.
In fact.
 We'll just goahead and compute the increments that are less than n, n / 3 and then startingat that increment whatever it is and say, we started 364 then next time we need anincrement, we'll just divide it by 3, 364 integer divide by 3, 364 integer /3 it gets 121, 40 and so forth.
 And so now what's going to happen is thosetwo elements are out of place.
 A tree that's got three two-nodes and no red links sosame situation as before.
Now, from a theoretical standpoint that's a little unsatisfied and in, in 1973,there's a famous paper that found a compared base selection algorithm thatguarantees to solve the problem in linear time.
 And now, if we ask is zeroconnected to seven we're going to answer yes.
 So, the lesson isthat we can develop good algorithms or good implementations without much code butthere are some out there that are still waiting discovery.
 And then process all the points, and make a list of points thatare contained in each square.
 And so and that's true as long as N isbigger than 1.
 So in this case we'llgo right 22, 23 no inter sectional left, so we go right and now we do find anintersection 21, 24 does intersect with 23, 25 because 23 is in the middle there,so we find an intersection.
 And while the nearest neighbor can't be, we don't have to go down the right subtreeat 6 because you can't have a point in that rectangle that's closerto the query point than 3.
 So you can run a Mergesort on hugeproblems.
 If you have an itemthat's less than one before then it's not sorted you return false.
 So here's the basic plan.
 So, the API will look very similar to our stack or queue API with adifference that we want to have generic items that are comparable.
 That's the summary for hash functions.
 If a class cannot be made immutable, you should still limit its mutability as much as possible.
 In the1970s, when we switched to very large scale integration for computers, we wereswitching from a situation where we were wiring physical devices together, to asituation where we were essentially drawing the computer.
 Andthis is a very general concept that's useful in all kinds of context.
Selections or uses about N^2 / 2 compares and exactly n exchanges.
 And it's a requirement that if x and y are equal then theirhash code should be equal.
 If we have a full stack,which we know by testing N, which is the number of items inthe stack versus the array length, then we just resize the array into one of twicethe length before inserting the item.
 And then, it'll put an event onthe priority queue for that time, this particle with that particle.
 And so, people, to design new computers,would, make huge drawings that just showed the lines that corresponded to thematerials that had to be created to make the computer.
 So we haveto look through the whole list for search but you only have to look through one listout of all the lists.
 But now we have to bring the heap order back into condition and so now that key is larger than its parents.
 Lots of researchers havedone good work to show this.
 And then, when we want to know whetherthis system percolates, we just check whether the virtual top site is connectedto the virtual bottom site.
 We readthe line, build the transaction from the information on that line.
 It's an easy recursivealgorithm, but there are three cases.
 We needed tohave a comparison for points that orders them by the polar angle they make, makewith the given point p.
It's gonna to do a shuffle.
 And everytime we add an open site, we check to see if it makes the system percolate.
 And then if the ones on the right goin their natural order, and then, by induction, they're all in their naturalorder.
 So we have to again prove that property by induction.
 It's a class, the constructor doesn't haveto do anything, there's no constructor.
 So hashing's going to be preferred for short keys where the hashfunction's easy to compute.
 And [inaudible], and then we have delete, and then we haveintersects.
 If it's equal,then you found it and you return it and you keep going until you get to a pointwhere you have only one element.
 We look at seven, seven is occupied.
 But Java does provide a nicea solution to this called iteration.
 And in order to do thissensibly, we need what's called a model of computation.
 And, and, anybody taking highschool Physics will, be able to deal with these formulas and the rest of this mayhave to go to a reference book to get up to speed on them.
 So the worst case quick sort is quadratic.
For example, here's another CSV file that from biology that deals with, amino acidsand codons and names.
 We started with one dimensionalrange search and just used regular binary search tree to compute ranks to get theanswer.
 There is a disadvantage that you have to create a new object for every data type value.
 So that's a trace of implementing binarysearch to find the rank of a key in ordered array.
 So we have to do it again, exchange it with S.
 And there weremachines that would take drawings and, and return, [cough] and from those drawings,like this, make, physical things that implemented computers with differentlayers and different, physical materials interacting, in different ways.
 If we have a left parenthesis.
 Now again it's going to use, this is a method that's linear timeon the average.
 All it's supposed to do isimplement those operations.
 So, that's true in many programming environments.
 And the node that was deleted is available for garbage collections, nobody's pointing to it.
 But most people will accept thatand it's a fact and that's how Shellsort gains efficiency.
 It's got 13,000 points, but if you tryto use the grid implementation for this you find that halfthe squares would be empty and half the points are injust 10% of the squares.
 Shell's original idea is to try powers to two minus one andthat works okay.
 Get that set, and put the new index onthat set.
 Not only does it help detect bugs, but it also documents what the code is supposedto do.
 Here's a partially sorted array, and you can see that insertion sortquickly gets the job done.
 But we can also provide a lot of convenient functionalityfor the client that's what we are going to look at next.
 So, this h = h / 3 gets us to the nextincrement.
 So that seems as if it should work but that doesn't have all the characteristicswe need in the Java implementation.
 And we have the items onthe list in a decreasing order of when they were put onto the stack.
 That's a Monte Carlo simulation, a computational problemthat gives us a solution to this, scientifc problem where, mathematicalproblems nobody knows how to solve yet.
 That's the average number of comparisonstaken by Quicksort, and actually they for a random permutation of the elements whichis what we do with the shuffle.
 We're going to read every word in the fileif the symbol contains does not contain theword.
 And then that sets up for this four loop that accomplishes themerge.
 We're going to pull off the two particles and then we'regoing to all, we're going to move all particles by the amount of time that haselapsed since the last event.
 Otherwise, the year, years must be equalso we have to look at the months to do the compare and so forth down to do the days.
 And then here's the skeleton of what's going to happen withthe collision system which is the key thing is this prediction method that takesa particle as argument, and adds to the priority queue, all the possiblecollisions involving this particle.
 If that's true, then we attach the new node with thered link as always.
 The whole partitioning process forthree-way partitioning and the modern programming language like Java simplymaintains the invariances described in the demo.
 While we're doi ng that we might as wellmake each one of those just point to the root.
 Down atthe bottom is one of those important one is in image processing for understandinghow to label areas in images.
 Now next we'll look at thecode for implementating that.
 So in this case, that first callwill return a link and whatever link gets returned, that will be set to root.
 So this creates a new symbol table associating string keys with sets offiles.
And then move on.
 So one thing that we can do is sample theitems, and then take a median of the sample.
 There's N squared over2 below the diagonal, half of that is N squared over 4.
 We do somemath, but not advanced math.
Okay? And that's the legal of 2-3 trees, So we stop inserting A into that.
 And since sorting is an operation that'sused in so many situations, many of the standard Java types that you would expectto involve sorts will implement Comparable.
 So by default, insertions are disabled.
 And rememberwe took some pains to think about the recursive implementation where when we godown a link we replace that link by whatever the recursive routine gives usback and that strategy is going to pay off in giving us a really simple code.
 Now theseproperties are very intuitive.
 We change our left link which isright now it's null to whatever put returns.
 The 4-node had four links, and the two2-nodes have four lengths, so nothing has to be changed below.
 If we now run out of space, wemight run out of time.
 [cough] Let's look at thebasic Binary Search Tree data structure with Heaps we talk about implicitrepresentation of trees with an array.
 So, the 2-3 tree is a way to generalizeBSTs to provide the flexibility that we need to guarantee fast performance.
 It's in it's final position and you can see down at thebottom, the large elements in the array filling in, in their final position, inthe, the left part of the array is representing the heap.
 A would go to the left of E two lefts in a row so we have to rotate thatto right.
 It's often used in embedded systems or in hardware sort type systems becausethere's so little code involved to implement it.
 So we assume that is connectedto is an equivalence relation.
 So the goal is, you got an arithmetic expression this is justactually like a simple stand in for a program and we'll talk about that in asecond but let's say, arithmetic expressions.
 In the second case,it's slower than selection sort, because it uses about the same number ofcompares, but it uses many more exchanges.
 So there's a number ofthings that you might consider trying.
 Ifk is to the left of j, then, we just do the left sub-file which is set high to j -one.
 And then we just update that value.
It's kind of a graphical proof or a proof by picture that thatrecurrence has that solution.
Alright, so here's the code for merging, which is quitestraightforward from the demo.
 The x's depth will increase by one, when its tree, T1 inthis diagram, is merged into some other tree, T2 in this diagram.
 [COUGH] The method that we're going to use isbased on taking an auxiliary array to hold thedata.
 We did a long distance exchange and thatcatapulted that first item past any item that it might be equal putting them out oforder.
 They d on't need the colors,but they can all benefit from the fact that the trees are much better balanced.
You, you can't have [cough] lines that come too close to other lines, certaintypes of lines can't intersect.
 As I mentionedthey're widely used.
 So now we have a query like thisgreen rectangle and what we want to find is all of the points in the datastructure that fall within that rectangle.
 For example, there's the birthday problem.
 And what we want to do isprint out all the occurrences of our exceptional words in our given file.
 The idea is to completely separatethe interface and the implementation.
 We exchange the elementat the root with the last element.
 And sowhat's the largest key that's less than G in this, in this tree here.
 And, sothere was quite a bit of effort, devoted to figuring it out, how full we could getthe hash table, in linear probing.
 Now, but the thing is, foreach pair of particles, so if you have N particles and you have todo it for each pair, that's N squared.
 But the problem bycomparison with sorting is, we don't get to randomize the order the client isproviding the keys.
 And then, if we want to connect five and zero.
 Or if it's some application where the order of insertion of the keys is wellmodeled by random order and that's not unusual at all.
You might think it would be better to handle equal keys in some special way.
 I'm Bob Sedgewick, professor ofcomputer science at Princeton.
 And then there are many applications where randominputs are fine model.
 So there is going tobe situations that are going to require an understanding of what it takes to engineera, a sort method that's appropriate for your application.
 But one thing that we can do is make sure that our algorithms work as advertised.
 All the keys that are smaller on the left we are going to put them out,and then we put the key at the root and then we put all the keys on the right outin order.
 And the bottom line is that we can articulate anAPI for generic stacks that works for any type of data and we've got twoimplementations, link list and arrays that, that performed very well for [cough]any type of data using the, the resizing or link list as we've described.
 So, we want to avoid cast as much as possible because it,it, it really is declaring some kind of weakness in what we're doing.
 It gets the sort done in place.
 It moves keys pastother keys that could be equal and so its easy to construct examples showing thatSelection Sort is not stable.
 Stability is an important property in sorting algorithms.
And working from left to right, by dividing each sub-array in half as itgoes.
 Then there's, what's theseventh largest times, that's select that like a median, it generalizes min or max?Which key is that, happens second or seventh? So that's, order statistics, adynamic thing what happened, whats the closest time, thing that happened justbefore, five past nine.
 And this is simple and completely well defined partitioning of the plane corresponding to a binary tree.
 And that is going to be very effective forperformance and lots of applications.
 Then merge those two together to get thefirst four done.
 So, let's, one of the easy ones is, if our keyis equal to the, if were [cough] to the, the key at the current node then thenumber of keys less than our key is the size of the left subtree of that node.
 So, now if we ask our zero connected to seven, well one and zerowe can do that too.
And everybody to the right, there's nobody less.
 Now, insertion sort does dependon the initial order of the data.
 Sevenand two, two is in the bigger tree so seven goes below.
 And again, that's not, not difficult to see thatthat's a fact.
 Next we're going to talkabout Binary Search Trees, a classic data structures that'll enables us to provideefficient implementation of symbol table and out rhythms.
And this one is kind of upside down as compared to Mergesort.
 When we insert E and that's supposed to keepthem in order, we have to move over L, M, P, and P to get the E and then so forth.
 It might be violatedbecause you might have an element to the right of the pointer that is smaller than some, the element on the pointer.
 Soa little Java [cough] code to provide this iteration facility but actually withinthis framework not too much to do and you can see how to implement this for your owndata type and we'll use this paradigm for every basic data type that we, thatinvolves collections of objects that we'll encounter.
 So that's a simple example ofimplementing a hash code for our own type of data that might include severaldifferent types of instance variables.
 To add a note, or enqueue,add a new note to a linked-list.
 What about the [cough]starting at the root if we have the case where E is less than S.
 If this less or less than or equal, thenit wouldn't work.
 Usually way, the way to show that a sortis not stable and it's just to see if it has a long distance exchange that mightmove an item pass some equal item.
 So, that's a look at binary search treeimplementations of ordered operations when keys are comparable.
 There's the three cases that could happen and here's an, an a, an example.
 So rest assured these types ofalgorithms lie at the heart of any program you use that isinvolving a lot of geometric data.
 It can't maintain a dynamic table efficiently with binarysearch and that's going to be your focus in the next lecture.
 Given a 2-3 tree, we saw how to do it.
 And that's may not get fixed so that sort is not stable.
 We have a full scientific understanding ofthe properties of these algorithms, andthey've been developed as practical system sorts and applicationsorts that have been heavily used over the past 50years.
 What we're going to look at next time called the Red-Black Binary Search Tree will guarantee logarithmic performance for all operations.
 This is aboutfour natural log N.
 so, with the, more [COUGH] complex userinterface, this is, very much what the spotlight or find functionon your computer is doing.
 Sort the points by polar angle with p wherethat is we're just going to consider in that order.
 Now, because it's 7-sortedand a 3-sort elements are either already in placed or on a go back a fewstrides.
 That'sour ID array.
 In this case, if we're searchingfor G, it's gotta go left, because it's less than S.
 That data structure iscalled a bag and so let's look at what that API looks like.
 A binary tree in symmetric order that's the data structur ethat we're going to use to implement symbol table operations.
Implementation of Java 1.
There's the Convex Hull for that set of points.
 So that's a binary search tree built, from thoseintervals.
 And the very first thing that we actually do is just compare and exchange if necessary the first twoelements.
 And all that is, it's a mathematicalreflection of what's going on in the code.
 Whenthere's a function call the whole local environment is pushed and then along withthe return address and then the function returned is pop the return address in thelocal environment.
Only if they're all equal that we return zero.
 And as we'll see this extendsto a practical problem in a number of situations.
1, we won't search the right subtree.
 And so, then we'll use the quicksort.
 That's the nextcollision that's going to happen from all our calculations.
 So, so we're gonna go left.
 Andnow, for a search, we just do the same thing.
And now we've achieved the goal of partitioning the array.
So that A of J is in its position.
Shows the state of the array before partitioning.
 Okay, let's take a look at a demo ofsearching in a 2-3 tree.
 That really seems unsatisfactory.
And again, a good algorithm is much better than having a super computer.
 So that's the running time Mergesort isfast other thing that we usually want to knowis memory.
 And now we, supposed to search and return from there, we're now at 1.
And if you make M too small then they're too long, you have to search through themall.
 So now, we'regonna go left to right.
 And for when there's only two items to link it, itworks, works the same way as before.
 You wouldn't want it to all of a suddennot implement some operation quickly.
 And then thenext lecture again we'll look at ways to define different orderings among pointsand Graham scan is a perfect example.
 We'll look at couple of elementary priority queue implementationsthat are straightforward.
 Forexample in this small example here, there's three connected components.
 The way we do that is to takethe two primary operations, compares and exchangers that were that were, were usedto refer the data and encapsulate them just the static methods.
 If you want that you have to providethat as a specific operation but in the case of symbol tableswe're not going to do that, you'd have to remove it andput it back in.
 Our representation is an array of keys and a size, that's the number of items in the heap.
So this is a summary of the optimized Quicksort with cut off the small subfilesin median-of-three partitioning.
 So it's prettywell balanced which means that our search and insert cost in this case for 255 keysis only going to be sixteen quite a bit less.
 [cough] but once it'sreduced to code we can be, it might have some trouble debugging at first but atleast we can be convinced that it works.
 Some of them very mathematical, that extend thehigher dimensions.
 For example, if the node is at position k, index k in the array then its parent is at k over 2 and that's the integer divide.
 [cough] and, [cough].
 So let's look at the Implementation,a demo of that one in operation first.
 So, let's summarize the properties ofQuicksort.
 So if the word's not in the symbol table,we'll put it there with a frequency of occurrence of 1,that's the first time we saw the word.
 And if we can keep the array about half full then we getconstant time performance for search hit and search miss.
 So and this is just some test datawhere we've got all, all these transactions and so we are going to beable to take in data like this and again an unbounded stream of data.
 In web searches.
 Cuz it's simply just faster thanMergesort.
 So the first thing is if, if is red h.
 And his idea was that if some particle isway away from some cluster of particles, we can treat that cluster asa single aggregate particle.
 Alright, so basic Mergesort algorithm.
 And in this case, it's very easy to improve it much, much more.
 So, it's going to go through every particleand call the time to hit method for that particle.
Group of four key, continuous keys in a table space there is called a cluster andclearly we want to keep those clusters small.
 So, to move the pointer to the right, we increment i.
 And those are typical parameters.
 They'reblacklist, and we want to take them out of our source file.
 And specifically, the work we do is, weadd the key to a 3-node to create a temporary 4-node and then split up thatfour node and move it's middle key into the parent.
 Now on the other hand, let's say they were lookingfor 1214, so no intersection.
 But with the symbol table implementation we can ef ficientlyprocess huge sparse.
 And there's nointersection.
 Tells us where, which element is inposition, and then recursively sorts the last part that's loaded, J -one.
 It doesn't have this highly desirableattribute but everything would compile.
 Let's seea demo first.
 Here's an example.
 So, it means that we've divided the search cost which would be Nif we have a sequential search by a factor of M.
 So Integer with the capitalized rapid typefor int and so forth and many of you were probably familiar with that.
 So, in this case, there'sno key smaller than G in the right subtree.
 Suppose, we wanted to find the minimum key in a binary search tree,or the maximum key.
 It's actually not so different from the elementary implementations that we looked at in the last section.
get(word) withthe new value st.
 She rotate right, rotate left.
Now, we're not going to be able to really implement that in a computer program butit's surprising how well we can do.
 So that is, for every line segment,you check whether it intersects with every other line segment.
 But there's also a good case that actuallywe take advantage of in plenty of practical applications.
 So it treats it as a base 31 number.
 The thing is totallyunsorted, then it gets sorted until subarrays to size four, then eight,sixteen, and 32.
 And experts debate about that and people who are interested can lookon the web for that kind of date.
 The client can have many differentimplementations from which to choose, but the client code should onlyperform the basic operations.
 And E goes to zero, and A goes to zero.
So, that's a first improvement.
 That stays to be 24.
 There's all kinds of cases where we justhave a lot of information, maybe on our PC or all over the web, and we want to createan index that allows us to specify.
 So array resizing doesn'thappen that often, but it's a very effective way ofimplementing the stack API with an array where the client does not have toprovide the maximum capacity of the stack.
 If you take all the points in one square, in 0 and all the rest of them,your average is still N over M squared.
 What we'll do is we'll keep track of the number of objects in eachtree and then, we'll maintain balance by always making sure that we link the rootof the smaller tree to the root of the larger tree.
 These are the basic topicsthat we'll cover in part one and part two of the course.
 It's the smallest convex set that contain all the points,the smallest area of convex polygon enclosing the points.
 Well we invented this datastructure this way of looking at balance trees at, at Xerox PARC which was the homeof the personal computer and many other innovations that we live with todayentering graphic user interface and internet and object oriented programmingsand many other things.
 Part of the array is the heap.
 And there's anothersurprising situation that happens in today's world.
 So how are we'regoing to represent binary search trees in Java? Well, we're going to extend ourimplementations of linked list structures to have two references instead of justone.
 Like if they come in, inorder, that's the worst case.
 If that's true then it's less return -1 and if it's,the year is greater, return +1.
 And we keep going.
Insert P, That goes between E and R.
 Now, once that's done, what we'll want todo is copy back to the original array to get it insorted order.
 Really amazingly simple and efficient algorithm.
 Whichever sort arestable? That's an interesting question that we'll take a look at now.
 So insert L,That's between E and R.
This is a so called eager algorithm, for solving kind activity problem.
 It soonbecame clear that those mathematical models were difficult to solve.
 For insertion sort, what we'regoing to do is we'll move an index i from left to right as before,but now, in the i'th iteration, we're going to move a[i] into positionamong the elements to its left.
Now it's partitioning what's left.
 So you don't want to make M too big,it'd be too much space.
 The J pointer on the left part of theright half.
 So, the idea is that we are, are going to represent every two, three treeas a binary search tree.
 Increment that pointer j and alsoincrement k.
 And whichever one is taken, we incrementits pointer.
 At least reason for pause in using hashing.
 The basic idea is to think of the array as being a littleat the begining a set of little sorted sub arrays of size one.
 So called Horner's Method.
 If the string is equalto the hyphen character, it'll pop the string at the topof the stack and print it.
 This is a somewhat detailed mathematicalderivation, but it is worthwhile going through the steps, to really get a feelingfor why it is that, Quicksort is quick.
 And so the average list length is short, this islike what we encountered with hashing.
And in this case it reads the strings from a file using our readStrings() method inour In class that which takes a file as argument.
 And what that mans is that all we can use iscompare, that's the only way we can access the data.
 And if we wanna find all intervals we just have to run thealgorithm fur Each interval that's, until we come up against no intersection, soit'll take time proportional to R log N if there's R intervals that intersect.
 And the get operation wouldreturn null in that case.
 So if you have this recurrence [COUGH]which is similar to the ones that we're talkingabout.
 We can associate the keywith null internally then apply or know the differencewhether that's in there or not.
Substitute the previous equation telescope.
 So one thing to do is start outwith some small prime number and this kind of mimics Horner's method tojust add in more data as we get it.
 And the idea is that each of thesorts can be implemented with only a few exchanges given that the previous oneshappened.
 So, point 4can't be on the convex hull.
 So say we have this 2-3 tree here and wewant to search for whether or not H is one of the keys in the tree.
 Or in a browser you might want to mark your visited pages orblock sites and so forth.
 And that's what we do inorder to get the hash code to be a number between 0 and M-1.
 And if it's plus, add the resultof the two values at the top of the value stack and if it's a star, multiply the twovalues on the top of the stack and, and then push the result.
 And then the corresponding oneis, what's the first thing that happened after that time? That's call in to theradio show, I'm going to take that caller, the first call that comes at nine:30.
 So that's a search miss.
 And it's not equally likely that each phone number has the samefirst three digits.
 And so we can pick some numbers that we can store.
 And then, we have the idea of a connection between two objects.
 So in typical cases, the runningtime of nearest neighbor search in a 2D tree is going to beproportional to logarithmic.
 This kind of question plagued a lot ofpeople in this late 60's or early 70's as these types of problems emerge forcomputing applications.
 And actually, you can make some progress with this kind of method, leaving tombstones through out the tree.
 Right here, we have K in its position.
 6's route is zero 1's its own route, so zero becomes a child of one.
 And the implementation of put issimilar.
 But use the center of mass andyou get a very accurate [COUGH] approximation tothe N-body doing that.
 The word lamb appears both in Tom Sawyerand Aesop's Fables, and so forth.
 And insertionis not much more difficult if you do the same thing and if you find a node wherekey equal to key on the link list, reset the value and return.
 And again, with the same client login is key and getthe section as a value.
 And just a very, very huge number of transactions.
 With this fast algorithm we can get an accurate answer to the scientificquestion.
 So this isthe binary search tree that's built from those five intervals, six intervals in ourexample.
 Maintain a dynamic search symbol tablewith trillions of keys, so that you can get to any key just by looking five or sixplaces but that's what B-trees provide for us.
 Once we have the array partitioned in thatway, shown here in the middle.
with mergesort is a good opportunity totake a look at the intrinsic difficulty in the sorting problem, now that is calledcomplexiting and we'll look at that next.
 Nowin framing of the difficulty of problems were only two things.
 You might assume that once you have it sorted by name, then whenyou sorted by the second field then it should maintain the sort of by name forall that have equal keys in that second field.
 But we're only associatingone value with each index.
 First when we look at, seemseven simpler than the regular symbol tables, and that's about sets.
 So for example, let's supposethat our keys are phone numbers.
 All we do is exchange the key in the child with the key in the parent.
 At this point, that's X - it's right at the end, and P is right at the end.
Okay, next we'll briefly considerqueue implementations using the same basic underlying data structures.
 And, depending on the valueof the parameter, M, you have a space time trade-off.
 [COUGH] So, the idea andthe consequence of this is, if you insert N items into an array, intoa stack with this array representation, the time will be proportional to N,not N squared.
When keys are comparable and we can putthem in order.
 And correspondingly given a red-black BST then you can get the 2-3tree if you wanted it.
And then these terms, every size appears twice.
 So 3's entry is four and 4's entry is nine in the array.
 And that brings it down somewhat andallows us to keep the tables more full.
 So we'llmove it to the left of lt and increment both lt and i.
 [COUGH] For analysis for bigger problems, we'll use a client calleda frequency counter client.
So, any point that's inside that interval, is going to represent a horizontal linesegment that is an intersection.
 So at the root, the maximum endpoint orthe rightmost point covered by an interval, is 24.
 And then we want to know if two referencesrefer to objects that have the same value and we want to call that equal,now that's what equals is about.
 Now H is greater so that says we should go right.
 So for example, this gives us a way to insert a new element into a heap.
 So those are detailsthat are easy to check.
 And clearly, that's going tosupport a quick implementation of the find operation.
 Somethings are wires, and some things are switches that, are used to, implementmemory bits and computer logic.
 So, we want to be sure to analyzeit in the simple case for stacks to set the stage formore complicated applications later on.
 So, that creates a connection between five andzero.
 So, we have to go down the tree somewhere.
 Today we're going to talk aboutalgorithms and data structures for implementing some fundamental datatypes called bags, queues, and stacks.
 In different clients, you might want touse this data in different ways.
 There's a little extra for it first,but that's about N overhead for the whole stack.
 Instead ofusing space for the length in a length list.
 And then, and maybe it's all files on the computer, or maybe it's specified in, insome other way.
 But in time,much closer to N log N than to N squared.
 So it's dividing by N.
 So we split it into two nodes.
 Whereas binary search, you just iterate through, the things in order.
 So, H is a three node leaning the wrong way.
 So [cough] so, for example whatabout one-dimensional range counting? Well, what we're going to do is just keepthe keys in a binary search tree and we looked at the implementation of the rankfunction for binary search trees where for every key, we can compute how many keysare there that are strictly less than that key.
 This is just first indication of that of why ifyou want to do this simulation, you better know about some data structure likepriority queues.
 So we need to convert that 2-node into a 3-node.
 They bounce off one another.
You didn't want to have any bugs when you're making a chip.
 so, in this small example.
 Not an easyanalysis, but we actually could make precise accurate statements about theperformance of this algorithm.
 Now,there is a possibly that something else happened to t hem in between and we'lltalk about that change, too.
 And so we're just gonna go right.
 We just go throughstarting at h for i and when we do the insertion, the j loop, we decrement j by heach time, otherwise the code is exactly like Insertion Sort.
 And so that's a little extra code, and then you have to add the resizingcapability as well to implement the data structurethe same as for stack.
 This is areal landmark in the theoryof algorithms because for a long time, it's not known, we knew we could have theaverage case, the linear time but could we find a worst case? And this paper foundsuch a construction.
 And actually there is avalue as N gets large that if you're less than that value it almost certainly willnot percolate, if you're greater it almost certainly will.
 So that's moving the smaller key down.
 Here's the implementation of file indexusing our symbol file implimintation.
 Another importantreason is that if you know effect, how to effectively use algorithms and datastructures you're going to have a much better chance at interviewing for a job inthe technology industry then if you don't.
 Soit's a little exercise in abstraction.
 Notice that we didn't increment ibecause that element z that is over in the right, really hasn't been compared to thepartitioning element yet.
 Sorry a, a red black.
 So, themethod is not really used in practice.
 And,but the problem with that quick find algorithm is that, that would taketen^18th operations, or, say array axises or touching memory.
 And then simply print out the set ofstrings associated with that word which is a list of filenames.
 And it wasactually the case that the progress of faster and faster processors with more andmore components was slowed because people were using the naive quadratic algorithmto do this design rule checking.
 And cycle through the dimensionsof level i mod k.
 In the lower balancing, a coupon collector analysistell us that the collisions are going to be evenly distribute, distributed amongthe table, around the table.
 We'll put our keys in the nodes.
 We'll look at two classicalgorithms.
 And so, that is, we change the link from E to A and from E toS to be black.
 So let's look at our algorithms in that situation.
 Not much code involved.
 So that's the kind of performance that we want.
 Here's what it looks like for a bigger array.
 So we say that we're dealing withkeys that are comparable by simply adding this extents comparable key to ourdeclaration.
 We'll use get class andthat's something that's gotta work or you'll get an exceptionin this later code.
 But, but actually it's a problem that Edsger Dijkstra had proposedin the 70s as an example of, of programming problem.
 Traverse the left subtree enqueue the key, traverse theright subtree.
 So that kind of meets thesetwo requirements for Java.
 Whenever we're at a node, it represents apoint, so we're going to check that point and we'll compute the distance fromthat point to our query point.
C.
 If K is lessthan the key, it roots i n the left subtree.
 And so when we insert a new node L say in this tree we go down that path, wecreate a new node and then return the link to that node higher up.
 And so client programs andsystem programs on the Java system were having terrible performance on theirsymbol table because of the shortcut in hashing.
 In this case, we do allowthe client to insert null items.
 There is this test fornull that has to be there and if it's not there it can lead tonefarious bugs and unusual problems.
Algorithms are computational models, and algorithmic models are replacingmathematical models in scientific inquiry.
 So, an h-sorted array is h different inter leaves sortedsub-sequences so in this case with h=4 if we start at L and look at everyfourth element - M, P, T - then it's sorted.
 So whichalgorithm should we use to sort that's, that's really a key question.
 Pull off the first E,it's already heap ordered.
 So, now we can return from that, and now we have to look at the bottomsubtree associated with 3.
 First it says that, that it's going to take as argument anarray of type Comparable.
 It's basically that distancedivided by the by the velocity.
 Howcould we guarantee that all operations are fast? Binary research is pretty good butthat's a major flaw.
 And then supporting that textbook, is free onlinematerial that we call the book site.
 Most of the operations are simple ones likethis happening at the bottom.
 Well, it's like in a Javaarray of integers say, our keys in that case are indexes that arerestricted between zero and array size.
 So right away, we can see,let's suppose that we have an empty tree where root is null.
To finish up, we're going to look at therectangle intersection problem that's got important practical applications and, usesthe techniques that we've been studying so far.
 Well we're going to hit the leftendpoint first, and so what we'll do when we hit the left, endpoint is, insert, they coordinate of that line into a binary search tree.
 So, that's N^2 or quadraticrunning time.
And, and, so for, if N is a thousand, that's going to be ten, if N is a millionthat's twenty, if N is a billion that's 30.
 So, that's an example of animplementation of Comparable by implementing the compareTo() method to putdates in order as you might expect.
 So people have developed all differentkinds of methods for adapting in this way.
 But it's a different wayof accessing the data.
 First thing is the inner loop is longer than Quicksorts.
 And that shuffle is needed to make surethat we can guarantee that the performance is gonna be good.
 If it'sless than b, maybe the next compare is b against c.
 So, in this case, the first field is three letters from theDNA sequence which, represents a codon.
Another quote from Francis Sullivan, says, "The great algorithms are the poetry ofcomputation.
 So that's thedefinition of a binary tree.
 The first stepis to model the problem.
 Well, actually if it's going awayfrom a wall, it's not going to hit it so that would be infinity.
 And also, itwouldn't be reasonably efficient at all for large data sets.
 And that's going to happen in the casewhere the biggest element in the first half is less or equal to thesmallest item in the second half.
 But it definitely becomes inconvenient to manage large numbers of tombstones in highly dynamic situations with large numbers of keys and values.
 SoJava has general API for sequences of items and its got things like a, append atthe end, remove from the beginning, and so forth.
 And follow the link corresponding to theinterval that we know must contain the search key by definition of the tree andthen we recursively continue the search.
 With comparators, we can do that outside of thedata type even at some later time.
Or you could think of a social network where it's people connected and eitherthere's a c onnection between two people or not and these are a way not to get fromone group of people to another communicating through that social network.
 Associate an integer with adouble.
 Now, the property of this operation that's very important is itmaintains a symmetric order.
 One of the firstthings you might think of is let's try powers of two.
 Again, it's not too good to use the firstthree digits because they're associated with some geographic region andit's better to use the last three digits.
 Since we shuffled the array, that's ourrandom element from the array.
 So, people found deletion moredifficult.
 And partially sorted arraysappear often in practice.
 In fact we can analyze the running time mathematicallyand show that defined operation, it takes time proportional to how far down thetrees are in the node in the tree, the nodes are in the tree, but we can showthat it's guaranteed that the depth of any node in the tree is at most the logarithmto the base two of N.
 For example,if they're all arranged in a circle and your query point's in the center orsomething of that sort.
 The.
 So our, our challenge is let's say this is on the web we havebillions of transactions, you know, and they are streaming through our data warehouseor processor in some way.
 And then isEmpty is just testing whetherthe first note on the list is null.
The left link is for the keys that are, points to a 2-3 tree with the keys thatare smaller than the smaller of the two keys in the 3-node.
 Now but there is this problem that theactual worst case height if the keys come in, in order and reverse order and othernatural orders that the time could be proportional to n.
 For simplicity, we'll show the code where the client gives the capacity of the heap.
 In the standard built-in types ofthe Java language we're going to have those customized implementations andwe can rely on them doing what we expect.
 So let's look at how this works in a demo.
 This is a general method that people often use in all different types of implementations, but in modern systems it's rather unsatisfactory.
 So that's a key method t hat gets used in thesimulation for each of the two particles that are going to collide.
 Well, it'sleft leaning and the process is a little bit different and sometimes the left pathcan get long but not that long.
 That's our definition of what a priorityqueue is.
 So the Java system sort will have adifferent.
 So that's an implementation of the delete max operation for heap using a sink, where a key value decreases, goes down in the heap.
 And if you find a key that's equal to the key you're looking for,return the value and we have to cast it to value because of the generic recreationproblem in Java, otherwise return null.
 Okay, so now, let's look at a coupleof test clients before we look at any particular implementation.
It's about analog in.
 Now the thing about assertions in Java is that you can enable or disable them atruntime.
 And that's true in every case.
 Today, we're gonna take alook at a number of interesting applications of symbol tables and thebinary search tree data structure to address problems with processing geometricdata.
 Optimal representation of the data and only a little arithmetic with array indices.
So let's just look at a little bit of thecontext of hashing in practical applications.
 Now, it's constant time butthere's faster implementations of stack.
 And so, that's thesituation as the table fills up.
 So, it's a dot product that takestime proportional to the number of non-zero entries in the vector.
 And, there werevarious rules about what you can do on these drawings.
 We're equal, we're not less, we stop it so wenever move an equal item pass another one.
 If occupied you, youreinsert the displaced key into its alternative.
 So let's look at example of Shellsort with increment7, 3, and 1.
 So, what we want to find is so say, we're seeking the floorof G.
 And certain codons have names, that's theamino acids.
 And the other thing we can do with this is just use a red-black BSTto guarantee that we solved this in time proportional to log in.
 Most of the time all you need to do is do the CCW of the two points.
 And indeed if you just draw theline from 1 to 4, you can see the 2 inside so there is no way it could be inthe convex hull.
 So they have to touch in a constantproportional to n times after touching array entry.
sort.
 Seven and two creates a connection between seven and two.
 And even if it's not points in the plane,just databases.
 So from these rules you can see that the man of code required toimplement this intersecting inter role is extremely low.
 This, this kind of stimulation is enabledby priority queues.
 Now that we've seen efficientimplementations of algorithms that can solve the unifying problem for hugeproblem instances let's look to see how that might be applied.
 Move the M up and increment i and k.
 So there are two compares that get done atN lg N times.
 So here's theexample of typical data, which is a URL.
 Now, we have to look at the third case, which is, when it's, thenew node inserted this in between and comes out of this link here.
 Now we go to 10 and 11.
 And we're not going to test on itor even go through the details.
Finally, we talk about stability.
 And then the third kind ofevent is what happens when we hit a vertical line segment? Well, in that caseall we want, need to do is just do a range search, for the interval of y end points.
txt the first couple of words from "A Tale of Two Cities.
 So, there's degeneracies to deal with and floatingpoint precision but people, researchers in computational geometry have worked thisout and actually there's not that much code at all in the end involved.
And what about the analysis? Well, again this the [cough] standard probabilisticanalysis of the balls and bins problem tells us a lot of information of what goeson.
 Howdo we arrange to do something is natural as this in our Java sorts? Now, we use thefourth in order to be able to implement sorts that can sort any type of data, weuse Java's Comparable interface.
 No algorithm can do better.
 Today we're going to look at Mergesort,which is one of two classic sorting algorithms that arecritical components in the world's computationalinfrastructure.
 And if they're not connected, then it'll connect them andprint them out.
 And it's only in this edition that we figuredout how to make the code this simple.
 Any CSV file, you can pick any field as the key, any otherfield as the value.
 Get the hash code out, make itpositive and MOD M is the way to go.
 So, normally we have a bunch of dot java files when we're working on anapplication.
 Also in some applications,we would include the size as well.
left, and then when you're done with that, you fix the count.
 Then there's no intersection on the left.
 And all that means is that,that data type has an instance method that will implement the compareTo() method.
And that's what people do, and that's why people use it.
 They're alloriented horizontal or vertical.
 For sorting that's kind of straight forward,what we're going to do is have a cost model where we count the comparisons.
 This is a bigger trace that shows, again, about half the elements belowthe diagonal are involved in the sort.
 And the math bares that out.
 So just given that high level descriptionthen the implimintation is pretty direct.
 So, you have to take both velocities and divide theirdistance by those and, and so forth.
 What's the next smallest xcoordinate? In this case it's the line number one there, and we'll remember its ycoordinate in a binary search tree.
 So what are we going to do about that? There are a couple of thingsthat we didn't consider.
 So those are just two examples.
Nobody to the right is less.
 And then processing queries is the same asbefore, as long as standard in is not empty we take aquery.
Where, because they're sorted by left N point.
 And what's interesting about insertionsort is that it runs in linear time for partially sorted arrays.
 That does not contain point 3 butnow which sub-tree do we search? [COUGH]In this case, now the rectangle intersects our splitting line, so we have to searchboth sub-trees, both above and below.
 So, we, we avoid this firstsituation here where we put the larger tree lower.
 So all that means is we start with an array in arbitrary order and then we'regoing to work from the bottom up to make sure that it's heap order.
 Now, in geometric interpretation, we just thinkthat the keys as points on a line.
 Well, we just do a recursive search and tofind all the keys between low and high you look in the left subtree if any of themcould fall in the range.
 And we've already looked atan algorithm that can do this, and that's binary search.
 But we're also in the, each node of the tree, we'regonna store, not just the interval.
 Now paradoxically and you'll see why very soon it also turns out thatto get the insertion done properly we sometimes need to take a left-leaning redlink and temporarily make it lean right.
 And you'll have a good feeling for how this data structure works.
 And then the,range search, in the binary tree, for each, each one of the range searches.
 Asyou can see from this example, it's not clear whether or not there's such a path,we need a computer program to do it, in fact, we need an efficient algorithm to doit.
 Onevery smaller heap, now we continue just performing sync operations at the rootuntil we get a completely sorted array.
 And put all those new events on to the priority queue.
 And then we also look for a lower bound which is a limit on the costguarantee of all algorithms.
 Here's another application.
 So wehave them sorted by name and this is say, something that we do just before assigningfinal grades.
 And then they get initialized in some way, but the main computation is apair of nested four loops for each row in the matrix we have to go through eachentry in the column vector and compute a running sum of for that row in the matrix,that corresponding expanding entry with the entry in the column and them, keep therunning sum and then that's the result that we put in the result column factorfor every value of i.
 In this case, the value apposition two has changed to H for whatever reason, in that smaller, in this case then both its children.
 And he was able to show, and we'll talk just a little bitabout this, that if, there's, only half of the parking spaces are occupied, then, onaverage, half the people find, find it after one place and the other half have tolook one extra.
 But, the bottom line is, you should be able t oprogram, and the quick exercise to get ready is, to write a java program on yourcomputer perhaps using a programming model, as described on the book site.
 But otherwise, it's a simple modification ofrecursive tree search to find all the keys and it's easy to see the running time tothat is going to be proportional to the number of keys returned plus log N.
 What it says is to you have the top operator and the top two valuesand that's what you want to do.
 [cough] And actually, in typical applications with any kind ofrandomness or even if there is a lot of order its difficult to find situationsorders of keys that build the trace of height is bigger than actually one log Nin, in a real application, its very close to fully balanced all the time.
 And you'd want to printout all the words that are not in the dictionary.
 A three node heap.
 So, that means that the running time ofweighted quick union with path compression is going be linear in the real world andactually could be improved to even a more interesting function called the Ackermannfunction, which is even more slowly growing than lg<i>.
And finally, seven and three.
 Typically, these are set up so that, the, all the data is in the externalnodes.
Then, we've talked about a bunch of attributes.
 If we make id, i a child of j, then we have to increment thesize of j's tree by the size of i's tree.
 If wekeep it in order, we can find the maximum or delete it at constant time but it takes uslinear time to insert.
 Sql or Oracles database and others,are based on, some variant of B-trees because they're so, so effective.
 The find is going to have tocheck if two objects are in the same component and the union command is goingto have to replace components containing two objects with their union.
 Instead, what we do is create avirtual site on the top and on the bottom.
 And then we pass through picking out from low to low+size-1,and then the next part is low+size+size-1 until we run to the end of the arraywhere we might not have a full subarray of size sz.
 Could hardly besimpler.
 That's a bottom-up Mergesort.
 So it's all finesorted by name and but then in order to distribute it out to the people leading itto the sections, what we want to do is sort by the second fields, sort bysection.
 So X hashes to fifteen, that's empty so weput it there, M hashes to one, that's empty and we put it there.
 One other client might want touse the IP address' key, have an IP address give methe corresponding client.
 This is a straightforward modification to our sorts.
Kind of discover that everything to the right is greater.
 So a client mightcall us for a null tree or [cough] or an empty tree.
 That returns true if the ported is sortedand false if it's not.
 On the right is a generic implementation.
 Where's the closest thing? How am I going to findthe closest thing efficiently? What things are nearby and so forth.
 We compare that with seventeen andtherefore go left.
 So now again, sweep from left to right.
 And similarly, maybe we want to build a, abook index, maybe for a real book, or maybe foran ebook.
 And it can cause all sorts of problems.
 All we do is set theID of P's route to the ID of Q's route.
 Clearly, these things can be extended in many ways.
 Our regular search code doesn't examine the color of a linkand so we can just use it exactly as is.
 And kind of an explanation for how it getsthe sort done so quickly.
 And the iterable just returns allthe key to iterate.
 But it might be the case thatthere's a third particle that knocks one of those out before that thing happens andthat event would be invalidated.
 So, a very smallamount of code based on a symbol table implementation that gives us thedictionary functionality.
 Need spacing between certain types of wiresand, you wanted to, before you tried to make the physical circuit to do thischecking, which involved this orthogonal rectangle intersection sort.
 So, in this case, we put, with generics, we can have a type parameter onour class and that include, that's inside angle brackets in this code and then, wecan [cough] if we have a stack of apples and we tried to push an orange unto astack of apples then we're going to get a compile-time error because that's stackwas declared to only consist of, of apples.
That's the basic Mergesort algorithm that we're going to look at differentversions of in the next.
>> So red turning to black means what? >> Budget deficits, red ink, black ink.
 So now we're going to build a symboltable.
 Now we increment I, as long as it'spointing to an element that's less than the partitioning element.
 So there might be a few nodes on the bottom level and one level lower than the bottom level, but otherwise all the levels are full.
 Figuring out whether what we have is a counterclockwise turn that's a little exercise in geometry and we'll just talk about thatbriefly in the next couple of slides.
 And once we've done that, then we have everything tothe left by in ascending order.
 You can go to books, the book site to see thelecture slides.
 And the reason would be, noreason not to do that.
 It's going to be cre ated a new node and the link to that node will be returnedand that's the link that we'll put in the left.
 But that's not difficult to do.
 Now, we're cheating in thisimplementation to keep it simple, and we'll take care of thischeat in a little while, by requiring the client to providethe capacity of the stack.
 It's the same as the term on the left.
 Again, now when we go to one level below,we switch again to vertical.
 But theyallow us to have a much more efficient matrix multiplication method.
That's another variation on the team.
 So, maybe we can store millions or thousands of them.
 The value of M is maybe a power of two orsometimes we'd pick a prime because of the waythat we normally would get the big hash code value down to bea number between zero and M minus one.
 And again it involves allthe characters of the string in computing the hash function.
 For algorithm design where we tryto develop mathematical models that help us understand the properties of thealgorithms that we're developing.
 And that's diffidently one thingto consider when using hashing is that the cost of computing the hash function for acomplicated key might exceed the cost of searching and using a simpler structurelike a binary search tree.
 And so in the first call over here, we might use the loginname as the key and the first name as the value.
 Ifwe have a value that's not in the table like K, well hash and is in position five,no, six no, seven no, eight no and we find an empty position at that point we canconclude that K is not in the table.
We'll talk about that in a second.
 And, quicksort certainly plays a role in most systemsorts.
 It also has been shown actuallynot that long ago, that the expected height of the tree if they're inserted inrandom order, the height that's the worst case length of a path in the tree.
So say your geometric objects are points in the plane and you specify a rectanglethat's oriented with the horizontal/vertical axes.
So let's look at a demo of how Quicksort partitioning works.
 So what we do is, as we did for MergeSort, is write down a mathematical recurrence relation that corresponds towhat the program does.
 So this is data driven code.
 So, again, we start at the root,and what do we want to do? Well, we're going to check.
 You know, keep the items like we would in the stack andthen when we need to find the smallest or the largest look at, look at them all.
 Now we search the left sub-tree andwe want to check if it contains point 3.
 We know their position and velocities shown at the bottom here and wecan predict exactly the moment, which they'll collide assuming that somethingelse doesn't happen to them in between and then so they will put that predictedcollision time on the priority queue and later on, when that time comes to pass wewill be right at moment when they collide and we can figure out what to do.
Now, we'll take a look at how the sortingalgorithms that we talked about or expressed in the systems that we useeveryday.
 If the key's there, it just resets the value.
 Pull off that E.
 Again, we exchange as long as the cardimmediately to the left is greater.
 While we know the one that we want to return is the one at the root, so we'll save that value away to return to the client.
 And so, then there'll bemutual gravitational pull and this is what happens with a large numberof particles in a certain simulation.
 And then we just take the nodes in level order.
 And then we 3-sort.
 We looked to the push downstack where we removed the item that was most recently added, And the queue where weremove the item that was least recently added.
 And it's very flexible andvery useful in lots of applications.
 So let's see that in the animation.
 If it's a boolean, they pick out a coupleof particular values that they return, so hashing boolean type,there's only two different values, so it's hard to think about whatyou really might want there.
 And now to do the high ones pretty quicklyand now it's doing the 1-sort and again it steps through the array pretty quickly.
 That's a detail, but an important onethat we have to take care of in our implementations to make sure that we'regetting most efficient use of memory.
 And what the client does isit, it'll, first it'll read the integer from standard input, and create a, a UFobject.
 So this is just an exampleof an application that might try to associate keys with values.
 And that recursive [cough] method is going to return a node.
 In the easiest case is, that node has no children.
 So, the rank of Ein this whole tree is the same as the rank of E in the left subtree.
 And that idea that I didn't need totake time proportional to N squared.
 A good example as a counter or a stack.
 It's turning the wrong way and it's turning to the right.
 So, in, in summary.
 For the stack, we take out the itemthat was most recently added.
 So what we want to choose is this squaresize that would best balance these two needs.
So that's what were going to look at now is try to find an implementation that canguarantee to be fast for all the symbol table operations.
 So,why not just use those? Why use our own implementations? Well, the problem isoften in such library code is kind of designed by committee phenomenon that moreand more operations get added and the API becomes too broad or bloated.
 The next most difficult case is like the deleteMin case.
 So the scientific question, or the, mathematical questionfrom this model is, how do we know, whether it's going to percolate or not? Inthis problem and in many similar problems, there's what's called a phase transition.
 And then the union operation is simply find the two roots Iand then set the idea the first one could be the second one.
 And then hasNext() is okay as long as that thing is positive.
 T and P are out of order, and so forth.
 So now we have two sorted sub-arrays atsize four.
 The Physics problem is exactly what happenswhen two balls hit and they bounce off each other according to somewell-understood physical process, and that's the high school Physics.
 So now in the tree on the right there, all the points that fall to the left of thefirst plane are going to be on the left.
 First one is to makethe bottom link left-leaning and then the second one is to make the top linkright-leaning so that we can have the temporary four node balance.
 Now, there is a worst case, that is,at the point when the stack doubles, it takes time proportional to N.
 But we're kind of stuck.
 Use another hatch function todetermine the stride that we're going to use.
 He's widely accredited as being theinventor of Mergesort.
 Another reason nowadays to studyalgorithms is that, they have become a common language for understanding, nature.
 And that concept is that there's some naturalordering of the data that you'll want to use most of the time, that's what theComparable interface is all about.
 So if N is the number of items in the heap, defined to be in the heap, we're going to increment it, store our new key there and then perform the swim operation.
 So, so, that's a one way you couldimplement this with, with a linked list or with the resizing array.
 The computers get bigger but they get faster so to toucheverything in the memory is going to take a few seconds.
 Even Quicksort has more overhead than youwant for a tiny array, like one of size two or three or four.
 So thisone is, I've only got ten tickets to sell.
 Here's our summary of where weleft off with red black BSTs.
 We modeled theproblem to try to understand precisely what kinds of data structures andalgorithms we'd need to solve it.
 And the left subtree.
 So, we're going to take T and we're going to exchange it with the last element, and then declare that to be no longer part of the heap.
 So now we can animate and againMergesort's more efficient, so we can do more and moreitems.
 Perhaps you wouldn't want to usea resizing-array implementation at the moment that your plane's coming in fora landing.
And you'll find textbook implementations or implementations out on the web thatwind up running in quadratic time in certain situations.
 Another reason to studyalgorithms is for intellectual stimulation.
 For example, you might have a spellchecker where you want to identifymisspelled words.
 Those are elementary implementations.
 And so that one is going to reada sequence of strings from standard input and print out the one thatoccurs with highest frequency.
And it's definitely worthwhile taking implementing for a Quicksort.
 But if we have a situation wherethere are a lot of equal keys, that model is wrong.
 So, the insertion time might belinear, but then you can use binary search, to look for the two endpoints,that's only going to take time proportional to log in.
 We start with an array of size 1.
 We saw a few easy algorithms for solving theproblem, and quickly saw that they were inadequate for addressing huge problems.
 Simply divide both coordinates by M, andthen look in the two-dimensional array.
 But it's worthwhile to state them explicitly andmake sure that our algorithms maintain them.
 Now, we attach a new link at the left of the smallernode.
 And the idea is we want to study some property of thenatural world by simulating it.
 That's the associative array abstraction.
 And then it will have a clientthat uses the iterator going through all the keysin the symbol table.
 And then we use our usual trick of returning the link that we went down to update the other links after the recursive calls.
 And then simply performDijkstra's algorithm.
 So, this isn't just an example about software security, there's a lot of difficult and deep issues to worry about in software security, and we're not going to worry about all of them.
 In this casewe just make four as parent three.
That selection of simple problem like sorting that is well sound with Quicksortpartitioning.
 So, what happens is that you are on a one waystreet and you are looking for a parking place and, it's, the idea's you startlooking for a parking place at particular times and say "Okay, now I need a parkingplace", and what you're doing is linear probing hashing.
 And search and selection in shellsort arein place, they don't use any extra memory.
 Let's look at how that workson our example with cards.
 And that one actually gives constant worst case time for search.
 It means for each string in thestack - print it out.
 For symbol table implementations where wedon't need ordering.
 And on the right, we put the points whoseith coordinates are greater than p.
 But usually it's fine just to do that.
 So then your space is withina constant factor of N and your time is constant.
>> [inaudible] the large screen.
 So the next empty position in the array, there's a place to put a new node.
 So hashing is widely used forsystems programming and applications, so some conventions forhashing are built into Java.
 So shouldn't use it inconnection with inheritance.
 But that as the basis, we're able to solve the two dimensional line segmentintersection search using the sweep line algorithm.
Increases the number of exchanges paradoxically, cuz more exchanges arerequired when the partition is right in the middle.
 So, as you can see in this examplewe start out by merging the first two sub arrays of size one to make a array of sizetwo - E, M - that's sorted, and then do the same thing for the next two elements and thenext two and so forth until eventually instead of sixteen individual elements wehave eight sorted subarrays of size two.
 Or another way to look at thisis it implements the function, how many keys are therethat are less than K.
 And our simple client is totake some strings on standard input and some pop commands whichare indicated with hyphens.
 And, and this one might be, if there's a time cut off.
 So you wouldn't put those things on a priority queue because the value is changing, but the other ones you would.
 Andeventually if the key is in the tree, we're going to hit it.
 Otherwise it's the same.
 And, and the reason is, and theproblem is that quadratic algorithms don't scale with technology.
 First exampleis to just sort some random real numbers into ascending order.
 And then we read from standard input.
 But if the maxendpoint in the left sub-tree is less than low, that means every interval in the leftsub-tree has a max endpoint less than mah, low, and so therefore it can't intersect.
 So, now we start by initializingi at the first card, and we take the idea that everything from ito its left is going to be sorted, and everything from the right we'renot going to look at at all.
 So who was a string, sostring has a hash code method.
 And those are just examples ofclassic results from combinatorial analysis that help us understandwhat happens when we do this, which is what we're doing with hashing.
 But we do have to worry in Javaabout a problem called Loitering and that is the idea that we havereferences to an object in our array implementation in the stackarray when we're not really using it.
 The idea is to when implementing the quick union algorithmtake steps to avoid having tall trees.
And the idea is very simple, We allow one or two keys per node.
 And the reason is that the Java linked listimplementation takes a linear time to find an item with a given index.
 Could there be a node that's closer to our query point than 5 inthe right subtree of 4? We have to go above, sorry, to look atthe top subtree associated with 5 and we find that it's empty.
 Again simulation of the naturalworld is an increasingly important application of computing and needefficient data structures like priority queues to get it done.
 That's less than thepartitioning element so exchange with lt and increment them both.
K is less than L, so the search ends at the left link of L.
 But first,we want to look at some algorithms.
 And also, we have to update the count, something happened down below, and we use that code to update the counts in a consistent way.
 So that puts B at the root.
 For thenode at the root, it's not.
 So, you can't make Mtoo large, you have too much space and you'll have empty chains or short chains.
 And in the worst case if the randomshuffle winds up putting the items exactly in order, then partitioning doesn't,doesn't really do anything except find the smallest, peel off the smallest item.
 So first N items would takethe sum of the first N integers, which we know is about N squared over 2.
 That's the implementation of binary searchtrees for symbol tables.
 So and actually, since strings are immutable,what Java does is keep the hash value in an instancevariable so it only gets computed once.
Which on average will be at the middle.
 Do the sync operation onthe A.
 Now, it's indicated by a little redarrow in this representation.
 So, if your business does depend on shuffling, people have looked at all sorts of options, including using hardware random number generators, and there's various tests available to make sure that it's random.
 So, here's whatthe, [cough] code is based on.
 And the other point is we're going to return infinity if there'sno collision at all so that it's going to keep, keep that on the priority queue,that ran on the priority queue forever.
 Now that's essentially the proof that you have to have acounterclockwise turn.
 We flipped the colorsand now our temporary 4-node is up higher in the tree but it's not balanced so weare going to have to do two rotations to make that balanced.
 So that's easy.
 We're assuming that the client doesn't get to change the keys while they're on the priority queue.
 This is another example where we use theory as a guide.
 So, we're going to need a bunch of procedures which do the prediction andthe collision resolution.
 The worse that can happen is that it alternates redand black.
 We consider all null nodes to be black nulllinks to be black, we don't have red links dangling off, that would be incompletepre-nodes.
 If the client happens to dopush-pop-push-pop alternating when the array is full, then it's going tobe doubling, having, doubling, having, doubling, having.
 Again one path through the tree to determine anintersection.
 So that's certainly somethingto be aware of when using hashing in practice.
 There's a lot of particlesout in the universe and you can't do a quadratic calculation forlarge N.
 And then key partof the problem is find query or the connected query, which just asks, is therea path connecting the two objects.
 And then there's 2 referencesthat we built in our class node, 1 to a string and another 1 to a node andthose are each 8 bytes.
 And then given a key, we want tosearch for the corresponding value.
 And the idea is to build a tree that corresponds torecursively partitioning the plane.
 It's hard to beat binary search.
 We didn't put in code to throwan exception if the client pops from an empty stack.
 If Ngrows from a million to a billion, that cost goes from twenty to 30, which isquite not acceptable.
 Both of which are easy to implement.
 So, the system designer, Jon Bentley was one of the designers totake a look at these problems and that lead ultimately to the development of the3-way quick sort that were used today.
 Actually since we copied, we couldoptimize by avoiding these moves.
 All take time, guaranteed,proportional to log in.
 One more pass makes two subarrays of size eight, and the last passis just a sorted array.
 Union is more difficult in order to merge the components, containingtwo given objects.
 Now,years after, we have to deploy our software and be extremely difficult oneveryone.
 So thatE again is going to come down and now it only goes down one step in this case.
 This is different than for example for quicksort when we, our assumption was we're going to create randomness and we aregoing to depend on that randomness.
 And what we wanted to do with the temporary four node was to split it andpass the center node up to the root.
 It's quite remarkable, actually.
 So given a queryinterval, we want to find all intervals in the data structure that overlap thatinterval or find any interval we'll start with that simpler problem.
 We search for the node that contains the key.
 Every time you hit a power of 2, you takethat many array accesses, but in a sense, you've already paid forthem by putting those items on the stack.
 So, we'regoing to use a recursive method put.
 Here's an example of one that goes one, two, three, four levels at least.
 And there was an example not that long ago, where atelephone company contracted with a database provider to build a database thatcould store customer information and the provider implemented the database usingred-black BSTs for search and insert.
 There's many different ways that we mightwant to sort strings.
 They get search and insert on in timeproportion for log base two of N and they support ordered operations.
 Okay, so toimplement the operations, we have to find query and the union command.
 And now, if we insert C into this one, it goesless than E, greater than A it's a red link connecting A and C but it's leaningthe wrong way.
 Even though it emerged asa data structure relatively late in the game now that we see that there are manyalgorithms that are much easier to implement when we think about the prioritykey abstraction.
 The only, the, the tree that hasthe most leaves of height h is totally complete and that one has two^h leaves.
 For hashing an object just somememory address of an object.
 That's mid plus one.
 So if it's a reference type,you just use the hash code.
 That's an algorithm that's, that we know that hasthe best possible cost guarantee.
 So, for example, for Q,that's an unsuccessful search.
 And as you'll see, this is, a generalization of,two three trees.
 The one that it doesn'tmaybe meet is the idea that every table positionshould be equally likely.
 So that's a basic implementation of priority queues using the heap data structure represented as an array.
 Same kind of dynamic characteristicas selection sort, except, for every step, it's not just comparing, it's also exchanging,which makes it even slower in practice.
 So now, we have to bring the heap order back because it might be violated at the root.
.
 And the proof is, the number ofcomparisons and the number of exchanges is equal to the number of exchanges equalto the number of inversions, and there's an extra compare forevery element except the first.
 Also, of course,if they're not equal then you'd like it to be that they're hash code's are notequal but you can't always get.
 And really it doesn't makesense if you don't know about comparators which we just introduced.
 And then the only instance variableof a stack is a reference to the first node on the list andit starts out being null.
 Which is another approach toimplementing symbol tables that can also be very effectivein a practical applications.
 Or it's something about thedistribution of key values if there are a lot of equal keys we can get sorted, getit sorted faster than, N log N.
 There's this one wild loop that we have to worryabout a little bit.
 Every search inleft-leaning red black three is guaranteed to take less than two log base two of Ncuz every path gets the same number of black links so you never have two redlinks in a row.
 But anyway, those arereasonable goals.
count,which is the number of nodes in that, in that subtree by definition.
 So, that's our problem, to be ableto officially support these two commands for given set of objects.
 So, everyplace that we used string type on the left we used the word item on the right.
 We start out with a big problem to solvebut we divide it in half, then we divide that one in half, and thenwe divide that one in half.
 And this is, as we'll see, this is a bit of aproblem when we have a huge number of objects, because there's a lot of valuesthat can change.
 And the idea isthat during the construction of a tree, or during an insertion operation, sometimeswe wind up with red links that are leaning in the wrong direction.
sort and it's intended to be ageneral purpose sorting method for use by Java programmers.
 And then there is some that array index arithmetic.
 Now suppose we insert S back into the heap.
 All different types of problems mightoccur and with some difficulties, it's possible to prove thateven if the tree's balanced, you can get a worse caseproportional to square root of N.
 And, and then, x.
 We're going to use the numbers, zero through N tomodel our objects.
 So again, that's, fairly little code, to implement, a fastsymbol table and insert, search and insert.
 With the inductive hypothesis that D of Nequals N lg N, we want to show that D of 2N equals 2N lg 2N, using the recurrence D of2N equals 2D of N plus throw out the 2N.
 You might also want it to be iterable but we'll skip that for now.
 And [cough] otherwise if the color's red, we return true otherwisereturn false to test whether a node is red.
 And also it'llperform better for huge tables whereas caching is involved.
 Or fordatabases with large number of dimensions, you could do even muchhigher dimensional data and find nearest neighbors anddo range searching extremely efficiently.
 So we just essentially, using the hash funtion as anarray index.
 So, the put which is to store a value associated with an index i, is justput into that hash table, associate key i with value x.
 Now,when we get a union operation.
 In this case they're both empty,so we're done with that.
 Another kind of eventis that we hit the right endpoint of a horizontal line segment.
 And so what we want to do is, build andindex from that set of text files.
 And link the root of the smaller tree to theroot of the larger tree in each case.
 Two^h has to be greater than orequal to the number of leaves.
 In that way, many clients canreuse the same implementation.
 So this is a useful and non trivialclient that's enabled by symbol table.
 If they're not equal, it returns false.
 So to add it to the heap, that's got to go in the position at the end.
 A very effective improvement, it's calledweighting.
 Now, applications of these, these algorithmsinvolve objects of all types.
 To find the maximum, wemove right from the root, until we find a null key.
 And there's no other forces involved.
 So that, that, that'sour full summary of sorting algorithms to and completes our treatment of sortingalgorithms with Heapsort.
 And that array, it's got value stored in it, say it doubles and those can change but what immutable implementation would do would be to copy those values into the local data array instance variable and then those values are not going to change.
 So we don't need explicit links at all to represent these data structures, we can just use array indices.
 Weneed to just in terms of implementation details, our keys and values have to beobjects.
 That's going to be the overall architecture forstudying algorithms that we're going to use throughout the course.
 And then we 1-sortand again because of the fact that it's been 7-sorted and 3-sorted, thearrays are almost in order when it comes time to do the 1-sort and most of theitems only go back one or two positions.
 They do notintersect.
 So usually we'll do some more workto try to make that one happen.
 We can have a, a very large number, ofunion and connected, operations and our algorithms are going to have to beefficient, under those conditions.
 And that's just perform the swim operation.
 And those have to have ex, externallinks or tree links connecting them to some other node.
 So we have 40 bytes per stack note.
 And that's the way we split a temporary four node in aleft-linear red-black tree.
 Andwe'll give'em a name, from zero to N^2-1 as indicated here.
 And that and you can see the amount of black.
 Swap that with i, increment i.
 Their impact's broad and far-reaching,they have old roots and present new opportunities, they allow us to solveproblems that could not otherwise be addressed, you can use them forintellectual stimulation to become a proficient programmer.
 Then, the less method will take that comparator asan argument and this is the one that actually invokes the method compare twodifferent keys.
 So, all of the operations thatwe're going to look at for red-black trees can be understood in terms of thecorresponding operations on 2-3 trees.
 So, linear time to find the k-th largest forany value of k.
 If why is a reference that's pointingto the same object as this object, just return true,because if you're going to test the values they're going tohave the same values anyway.
 So, it's called the orthogonal line segment, segment intersection searchwhere the lines segments or constrained to be either horizontal or vertical.
 So, first thing it goes up the exchange with the S, it's still bigger than P so we exchange it with the P and now we're done because S is not bigger than T and the heap order condition is now satisfied everywhere in the heap.
So that's 2 and then the extra cost for the merge is N, but if we're going todo this twice then we have 2N over 2.
 Now, what's interesting aboutthis proposition about selection sort is that, it doesn't matter what order theinput is.
 That's a model of a file system that is pretty workable.
 Now, on the other hand, we could, fromthis same file, we could build a symbol table where we treat the IP address asthe, as the key and the URL as the value.
And at the top, the class declaration we declared an angle brackets that item isthe generic type that we're going to use.
 So that sort of operation isgoing to work in a big tree when we insert into a new three node at the bottom.
 This is a an ordered array implementation ofpriority queues and it's quite straight forward.
 And these things are studied inclassical combinatorial analysis.
 So, for examplestacks and queues you can find those words mentioned in the Java library so there's aJava collection library and the so-called List interface which is displayed here.
 So,that's one dimensional range search using binary search trees.
 That's a bit of a hack, but it cuts down on a lot ofcode.
So 2d tree again, it's going to be a datastructure based on a bunch of points that's going to facilitateefficient data processing at these points.
 And what if we have hundreds of different types of data that we'reprocessing.
So, in this example, it shows the general situation, when the 4-node to be split isthe middle length, But the same is true if it's a left orright.
 But in particular, there's a piece of a recordcalled a key and what we want to do is put the records into order according to thekey.
 And then,we're going to adopt the convention that the get() method returns null ifthe key is not present in the table.
 And again the string is the key and thesets of integers are going to be the places in the arraywhere the given work appears.
 So we use a simple scientific model calledthe hard disc model.
 In order to get that done, we're sortingthe left half and the right half and this notation ceiling of N over 2 andfloor of N over 2 that's the N over 2 round up and N over 2 round down, that'sthe size of the two sub-arrays, and we're going to call the same routine forthat size, so the number of compares you needto.
 But one of the things that was invented there, was thelaser printing and we were very excited to have nearby color laser printer that couldprint things out in color and out of the colors, the red looked the best.
Easy, easy to fix but, but we don't simplify the code.
 The type of the argument inthe equals must be object, you'd think it should be date.
 That's a very simple implementation of an iterator for these symbol table withcomparable keys.
 Now sixteen isbigger than fifteen so we go right.
 So your equals test you bettertest the client and give you null.
 Doing the left part of that.
 So that's not much code, and it's trivialcode at that for doing an efficient symbol table search using hashing.
 [cough] and that gives us immediately our code for the selectionsort implementation.
 It's an easy way to get things drawn.
Then the method calls the sort for the left subfile first, and then that's gonnabe partitioned on this e, and so forth.
 It's a good visual representation of how Mergesort gets its job done.
 As far as we know theycould be.
 The model of computation is what'scalled a decision tree, tree.
 Ifit's greater than the key at the root.
leftis red, the color of h.
 So here's just a particular client that will helpexplain the idea.
 There's a trivial lower bound which says you have tolook at all the data, that's N and we'll look at a better lower bound and see thatmergesort is optimal.
 In the next increment goesback to zero at the left end of the table and we just test for all the non nullkeys.
 The bottom line in this is sequence of passes through thewhole array and there's no recursion needed at all.
 So the idea is to keep a linked listwhich consists of nodes that have strings in them, and references,to the next item in the linked list.
 So wealready looked at the Get operation so we might want to know what city is associatedwith the event that happened at time nine o'clock, thirteenth and so that shouldreturn that value.
 So at every node, we're gonna store the maximumendpoint and subtree rooted at that node.
 If you don't look at everything, you might miss the one itemthat you're looking for.
 A exchange for the larger of its two children.
 So, it's clear that, we'll create an object corresponding to each site.
 And nowadays that means priority queues.
 So, in a binary search tree, those rank numbers goin an increasing order as we do in an ordered traversal and that's easy tocompute.
Next we're going to consider addressinganother fundamental defect in the implementations we've considered so farthat those implementations are only good for strings.
 So, for example, to provide order and iteration,you have to get them sorted.
 So the parents of say H and G are both N, H is at 10 G is at 11, N is at 5.
 So how are we going to grow andshrink the array? Well, first thing you might think of is,when the client pushes a new item onto the stack, increase the size ofthe array by 1, and when it pops, decrease the size of the array by 1.
 Now, the default implementation for hashing is the memoryaddress of the object.
 That's an array with file names in it and Insertion.
 And it's important for us to know that theory and that willhelp us decide how to choose which algorithms we're going to use in practice,and where to concentrate our effort in trying to find better algorithms.
 For convenience, we'll provide a constructor that takes the key and valueas argument and fills in the key and value instance variables then the left and rightlinks are initialized to null.
 That'sthe pretty much all the code for the simulation.
 And in the ith iteration, we go through the array to try to find thesmallest remaining entry, in this case, the 2 is the smallest from any entry.
That's how we h-sort an array.
 To.
 And then, we're going to test which of the fourtypes of events that it is.
 P hashes tofourteen, 14's occupied, 15's also occupied, now we run off the end of thetable, and look at zero, and that's empty so we put it there.
 You just find the root of P and the root of Q and if youcheck if they're equal.
 So, what we're going to do is we're going to rotatethe top link to the right.
 Now there's anotherproblem is what increment sequence should we use for Shellsort.
 Quicksort doesn't do that.
 The R goes off theheap, do the sync operation on the M, and now we have a heap ordered array.
 And if there's more items onthe stack than the capacity, we'll have to deal with that problem.
 If you have huge numbers ofparticles and you measure the number that hit the size and the frequency with whichthey hit they sides you can do experiments relating temperature and pressure and manyother things or do three-dimensional versions.
 And so a constructor for an immutable vector data type, it might take an array as its argument.
 Now what about inserting?Well, it's a similar type of strategy as with regular binary search trees, exceptthat we manipulate the two and 3-node to keep perfect balance in the tree.
The middle link points to a 2-3 tree that contains all the keys that are between thetwo keys.
 So that's a quick implementation of the insert operation.
 And in general, a CSVfile might have many fields separated by comma, comma.
 Maybe that one's minor but it also is picking a random card from the whole deck, and as we just pointed out, that's not uniform, it should be between one and i or between i plus one and 52.
 The distance from the root to the bottomis always the same.
 We don't actually have explicit representation oflinks or links in trees or just references to nodes.
 You get constant time expected and lg, lg N worst case.
 So we start again by picking K as thepartitioning element.
 So we'll start with a, a demo of how this works.
 Maybe your computer is parallel and the sort has to be paralleland we found that equal keys make a huge difference.
 We'll look at three proofs of that, justassuming that N is a power of 2.
 It'll map any key to aninteger between zero and four and then to [cough] do an insertion we'll just keep alink list at the table position corresponding to the hash value.
 Each node is its children so this is theright child of the root.
Why is it stable? Well, we never move equal items pass one another.
Like Mergesort there is more things to do in the inner loop.
 So just for example, let's take a look at the problemof computing the floor.
 Sothat, after the, at this point zero, five, and six are all in the same connectedcomponent, because they have the same array entry, zero.
 Then, how about space usage? That depends very much onthe implementation and the machine so this is a typical Java implementationthat we do the analysis for.
 And then there's two cases.
 And depending on the frequency of execution of the uncertain delMax operations, that might work out better.
 And this is going to be very efficientbecause as we get closer and closer to the query point, we're cuttingout all the sub queries that are away.
 The word majesty appears in three places,and there's, there's the context.
 But the advantage that weget is very fast pushes and pops, just access array and increment it,and very efficient for most operations.
 Now, it's essential that the array size is greaterthan the number of key value pairs N.
 If it's there, then we return the valuewith the same index and parallel array.
 And the idea is, that what we're going todo is associate.
 It's very useful in practicebecause it's pretty fast except for very huge arrays.
 Those are the, only operations we need toconsider to get balance in our search trees.
 And we'll skip that code and just take a look at the comparison betweenthis elementary implementation for symbol tables with the sequentialsearch in an unordered list.
 Or you could do it in a linkedlist, and then when it's time to find the, remove the maximum, you have to scanthrough everything to find the maximum.
 The two things that are critical is thatthe, in a, in a 2-3 tree, we always have symmetric order.
 The cartoon on the right showsthat not all orders are necessarily total orders.
 Today, we're going to lookat Priority Queues which is a variant of sorting that generalizes the idea toprovide more flexible data structure that we can use for all sorts of applications.
 So, that's shuffling our first non-trivial sorting application.
 So, that's a canonical example of a, a priority queue client that we need todesign a program that can do that.
Now that's looking like a much simpler equation.
 Find the smallest, the four.
 And so, that is where we look tocheck to see if that key is there.
 Anillustration of all the different operations that a client might want.
 Or you might tosay well let's try to keep things in order.
 On the red one is the onethat's finally put into place.
 So first thing is if At the root,we have an intersection, then we're done.
 You can think of for electricity.
 And as long as there aren't too many deletions, you can keep the search cost and deletion and insert cost to be logarithmic.
 But now, that's not a 2-3 tree, so we haveto split again.
The constructor is the same as the other one.
 And theneach side has 500.
 On the other hand,if the array is in descending order and has no duplicates,then every element goes all the way back.
 And the idea is we're going to use Insertion Sortbecause of two reasons based on our understanding of how Insertion Sort works.
Is to save a little bit of time you don't really haveto copy over into the auxiliary array.
 Our sub text today is allabout modular programming.
 In the case of Quick Sort, the number ofcomparisons taken to sort N items is N+1 for the partitioning.
 So, we're going to list of files that arespecified.
 So there's simple formulas to tell us what todo and we can also figure out the formulas for what we do o nce they do collide.
 And then, the index in the array is going tobuild the fields that we're going to use.
 And the idea is to keep the arrayof keys in sorted order.
 Now, this algorithm people discovered rather earlyon after figuring out the weighting and it turns out to be fascinating to analyzequite beyond our scope.
 Another one that's the boundary between the keysthat are equal of partitioning elements and the one that is greater.
 That will maintain in the unionoperation.
 So it's got five keys.
 Or more generally, people want to oftenprocess, preprocess text to, maybe a huge amount oftext, to support, so called, concordancequeries.
 Now this was studied in detail by Knauf, DonKnauf, in the 1960's and actually this problem, Knauf says, was the origin of theorigin of analysis of algorithms.
 So, those are independent symbol table objects.
 So what we're going to do is look at how tomake our stack, and queue, and other data structures that we consider later onimplement the so-called Iterable interface and it will work for client code no matterwhich implementation we used so let's take a look at the details of that.
 So, how are we going to be able to determinethese intersections efficiently? Now, the natural algorithm, or the naivebrute-force algorithm, is quadratic in time.
 So let's take a look at aninsertion into an interval search tree with a demo.
 So and then whenyou're done then simply print out the value on the stack and that's a fine andelegant implementation using stacks for any arithmetic expression.
 So instead of using the standardmatrix representation, where every row of a matrix is an array, that's what a twodimensional array is and the space is proportional to N^2.
 And then that allows us to processqueries, where we take a query, and then get the set of indicesassociated with that query.
 So, for the selection sort, we have a pointer that wasour variable i, that scans from left to right.
 Let's make P's tree point to Q.
 It's actually going to be quadratic in the worst case but again, thechance of that it will happen with a random shuffle is less than the chancethat we'll be struck by lightning.
 So, what we want to do is to allow the client to iteratethrough the items in the collection.
 Ifthey key's not in the tree then we add a new node at the bottom.
 And the idea is that the parent's key is going to be no smaller than its children's key, and that's true for every node in the tree.
 And we keep doing that until we get down to D of 1 which is 0.
 So, initially, we set upthe ID array, with each entry, equal to its index.
 That's a summary of Quicksort, our bestsorting algorithm that we've seen to date.
 In the bottom, for the weighted algorithm all the nodes arewithin distance four from the root.
 Now it's heap ordered.
Actually to make a one liner code, we use a, a simple variant where we make everyother node in the path point to its grandparent on the way up the tree.
 Let's look at ananimation, an animation with Heapsort is interesting to watch so the constructionof the heap happens in a blink and now it's pulling off the largest elements,moving from right to left.
 Creating new arrays on every operation.
 Then we looked at range searchand other operations using KD trees.
 So here's an, here's an example right from Java.
sort()takes that array as its first argument and again sorts them and then wego ahead and use as, go through them one by one and print them and they come out inorder of file name.
 So, we use less() and exchange() to be sure that we can testthat our, our methods work with the method like this.
 Unreasonable to expectthe implementation to work well if the client can change the valuesof keys that are in the table.
 We can just test if the arrayis one quarter full, if it is, we resize it to half full.
 So thislittle example if we insert P, Q, and E then when we do remove max, we want to getthe Q out and for later, we insert X, A, and M and then we removed max.
 It's identical to the code forpop for a stack.
 Now, the code for partitioning is straightforward to implement.
 We can make the heap d way rather than just two way.
 You want it to be between 0 and M- 1.
 You're both testing that these conditions hold, and also telling someone reading thecode, what you're trying to do with it.
 So now, do we go left or right? Again ten is less than our left endpoint21.
 And we also want to make use ofthe hash code implementations for the types of data that we're using.
 It gets the sorting job donewith just N minus 1 compares.
 So that's, in array accesses forthe copy, there's two array accesses.
 Now this isn't exactly precisely wh at would happen in the real worldmainly because we didn't put in the simulation what happens when threeparticles are touching or there's two touching in another one hits them.
 [cough].
 And then we get a final sorted array.
 But we don't to look at the leftsubtree of e because all of those are less than e and therefore are less than f.
 And this is absolutely a fine methodthat is not that difficult to implement, in the case that the pointsare evenly distributed.
>> And not only that once you have a big cluster and you hash into the middle of ityou've got a good chance that, that clusters going to get longer, or worse.
 So, but anyway, starting at point 3,as far as we know, we're going to have tolook at both subtrees.
 Again, we can look at insertionsort in terms of invariants.
 So, we've looked at the quick unionand quick find algorithms.
 We take that command line argument, whichis the minimum length that we care about.
 It's not too difficult to get asimilar lower bound for the model when we know that there are some equal keys.
 So we just search for import and it'lltell us, look in those three files.
 Andthis is an elementary programing exercise that is the, the code at the left has theeffects shown at the right.
 Our compared to is by time.
 So, we had a single temporary four note and we split itup into a two, two note not connected to a four note.
 We're sorting strings but we'reimplementing a different ordering, various different orderings on that same data.
 So it was more complicated and involved a lot more cases and sousually not all the cases were put in the text books.
 The inner class node is the code that was given on the previousslide, and then we'll need implementations of put and get, and we'll also look at animplementation of delete, and an iterator as well.
 They might be short, they might be long.
 Instead, we're going to use a symbol table representation where our keyis the index and the value is the entry.
 So, let's do a demo of constructing the red-black BST from ourstandard set of keys.
 It's larger than the keys in this two children and they're larger than theirs and so forth, so it's the largest key in the data structure.
 Do the sync operation on E which involves promoting the larger of its twochildren, until it gets to the bottom, or a place where it's larger than both itschildren.
About 1.
Every operation is guaranteed to be a constant times log n.
 And soall of this code in red shows a model for what you might do if you're going toimplement your own type of data, equals for your own type of data.
 The implementation could hardly be morestraightforward and it's an excellent way to solve the problem of handling multipletypes of data with one implementation.
 And, andpeople have variants of these algorithms that keep it more, much more than halfempty if that kind of space is a, is a consideration.
 For each site on the top, I'dcheck each site on the bottom.
 We'll view that array as eventually being a maxheap.
 So now we go to 6.
 Watching the [unknown], this is a balanced tree gettingconstructed in the worst case where everything that comes in is in ascendingorder.
 So that's a way to build a binary tree corresponding toa partitioning of the plane.
This looks like a fairly daunting equation, but actually it's not toodifficult to solve.
 And that gives us a temporary four node.
 So the Java language helps us with thisComparable mechanism so that we can sort data of any type.
 The idea of complexity is it's a framework for studying the efficiency of all the algorithms for solving a particularproblem.
 So, that's a, a implementation that, that code isdefinitely tricky and a similar code for ceiling.
 The andthis is the slide that, that gives the math and I won't talk through this math.
 Then test isEmpty() and we also sometimes have extra method that justgives us the value of the largest key and also size which is useful sometimes incollections.
 The first implementation thatwe'll look at uses linked lists.
 Now again, now x ish.
 The client is always going to betesting hasNext() as I showed as I showed and that stub code before and so when itgets to null it will return false in the iterational stop.
 Low.
 And there's a good reason forthat.
 Otherwise, you makea new node and put it at the beginning of the link list with the standard code.
 It's possible soyou have to just take the 31-bits.
 L hashes to six.
This seems to be with a small value, multiple of n times the number of incrementsused which is some multiple maybe of n log n but nobody is been able to find anaccurate model that proves that for any interesting increment sequence forShellsort.
 And this one has many,many applications, and we'll talk about some of them later on.
 And maybe the way the keys are represented.
 So, that's a, asimple simulation to just generate random positions.
 And what was provedby Hopcroft Ulman and Tarjan was that if you have N objects, any sequence of Munion and find operations will touch the array at most a c (N + M lg star N) times.
A connected component is a maximal set of objects that's mutually connected.
 So, and we have to, bear inmind, as we're building our logarithms, that both the number of objects can behuge, but also, the number of operations.
 And that'seasy to do.
Shellsort also has long distance exchange and so it's not stable.
 It grabs an element andbrings it back into position every time.
 Find the key or findan empty table position.
 So let's look at whatthat code looks like.
 So first thing is how do we get an array h-sorted? That's actually prettyeasy.
 So this is a complete linked-listimplementation of all the code to implement a linked-list fora stack of strings in Java.
 This is one of the oldest sortingmethods invented by Shell in 1959.
 And then our method is to move the Ipointer from left to right.
As a final example of a symbol tableclient, we'll take a look at a mathematical application where we want toimplement sparse vectors and matrices.
 We'll assume that is a starting point.
 So they just returned the value.
 Now for a position K, then what we need to worry about is the nodes at 2k and 2k plus one.
 Doing something that, you wouldn't really, necessarilythink that you could do so easily.
 Not only through the useof space-partitioning trees like 2d trees and quadtrees.
 And that's really easy to convince yourself that that's true because the height if we add nodes one at a time going from left to right on the bottom level say, the height only increases when N is the power of 2.
 This is a publishing model that Kevin Wayne and I developed and have beenusing for many years, and we think it's a very effective way to support the, kindsof lectures that we're going to be giving in this course.
 Again, t and I are in the wrong places.
 First thing we do is just multiply by Nand collect terms.
 Now we go totwo.
 The interpretation is the two objects, P and Qare connected if and only if, their entries in the array are the same.
 For Binary Search Trees we're going to talkabout actually explicit tree data structures.
 That's our challenge.
 But if it's goingtowards a wall, then we'll compute the time.
 So we need to fill in this one table, what's the cost of deletion in a binary search tree? How we're going to really do that? Well, let's take a look at a very lazy approach which we setup for in our basic conventions for symbol tables.
 And we just use that for every non-zeroentry in the vector.
 Now we're going to look at an applicationwhere we simulate a phenomenon in nature, and this is, what kind of patternsdo things like starlings and geese or cranes, or fish, or fire flies.
 For search, we have to,since it's unordered, scan through the whole list tofind a match, a key that's there.
 They're not connected, so we'd return false, inthat case, not connected.
 So what we can do is it's pretty easy to find a family of stringsthat have the same hash code for example with just a little fooling around now daysyou can just look it up on the web, you can see that these two character keys,both have the same hash code because when you just do the math in a base 31 hashcode it'll tell you that answer.
 Now in practice, this construction is, is rather high.
 And again, we wind up with a single tree representing all the objects.
 So, in this case, they're all zero, except for 0.
 It, you don't have to assumeanything.
 Where some expert has doneimplementation of the hash code and also your applicationdoes not need ordering.
What's it going to look like? The idea is very simple.
 In this case, best times, worst times, and so forth.
 The findoperation, or connected operation.
 On odd levels we use a horizontal line andthe left sub-tree is all points below and the right sub-tree is all points above.
 Sowhether it's individual atoms and molecules or some bigger kinds ofparticles.
Left parenthesis, we ignore.
 And then if you look at thepolar angle with respect for every other point with the respect to that one, so theangle you get from of the x-axis through p up to the point, then the vertices appear inincreasing order of that angle.
 We took two sorted subarrays and we talkedabout an abstract in place merge but we didn't have anactual in place merge.
 Since it's not there to in sert G, all weneed to do is just put it there and that's how we insert a new node into a binarysearch tree.
 And let's say that key is less than the key at the root.
 So, and let's take a look athow we can possibly make this happen.
 If you need to be able to sort data on two different keys.
And then the right part, that's J + one to high.
left.
 M is large and N is huge, and M<i>N is going to be tooslow.
 So, we have to do collision prediction, which is givenposition, velocity, and radius when's it going to hit with another particle or, orthe wall.
 So, range searching is a veryimportant fundamental operation.
 So, lets see what the code does.
 If the j pointer is exhausted we move over the next ith element.
 We won't give the full proof.
 The idea is to pass through the array from left to right with an index i, as we've been doing.
 But actually when you think about it, why don't we just put allthe items equal to the partitioning item in place.
 So in summary, we took animportant problem.
 And seven and three, three is in the smaller tree so it goesbelow.
 Try to understand, basically, what are the mainelements of the problem that need to be solved.
 And one of the things we'll look at is algorithms thatcome very, very close to achieving that goal.
That's a little implementation detail, but otherwise this is a fine swordimplementation, that actually is very little code, and its got a place in, inthe theory of algorithm, that I will talk about in a second.
 And that's built into java and alsosome classic algorithms depend on that.
 So, even ifit's a huge tree down at the bottom, we just came of a null link.
 But that's a quick and elegant implementation of code to solvethe dynamic connectivity problem called Quick-union.
 And we can't accept quadratic time algorithms for large problems.
 I wanted to findthe top k or the medium or other order statistics so that's what selection is allabout.
 So it's going to be slower.
 We're going to need that becausewe need to change it's reference from null to point to the new node.
 That's array implementations of stack, but it breaks the API by requiringthe client to provide the capacity.
 And the same with the wrapper types like integer and double or color and lots of things.
 You need a quadratic amount ofmemory to avoid collisions.
 With linear probing is called open addressing and isalso around the same time in the 50's the idea is just use an array.
 The way wemaintain, there's a number of ways we can maintain the thing but the one that we'lladopt un iformly because it adapts to more complicated situations is just beforewe're done with the put operation we'll say, okay we've done all our work andbefore we return the pointer to the given subtree we're going to take the size ofwhat's on the left and the size of what's on the right and add one for us and that'sgoing to be our count.
 InQuicksort partitioning, after the random shuffling we have the partitioning elementand then we process everybody to the left independently of everybody to the right.
 So, just, to simplify our code in the slides in it's off, off from thecase for geometric data processing.
 Now, but let's look at what's happened or visualize whathappens when keys come in, in random order.
" and thesewords appear often, "It was the of, it was the of.
 You can actually implementpriority queues this way.
 You may be somewhat familiar with these, but today we're going to takea careful and close look at them.
Split that 4-node, moving L to the parent.
 hasNext() is supposed to if, if we're done is supposed to returnfalse.
text that has thesefour words in it: was, it, the, and of.
 You have to carefully check the code to be sure.
 But weighted quick union withpath compression in practice is, is close enough that it's going to enable thesolution of huge problems.
 So now, we have a bunch of rectangles.
And you might go trough the exercise of trying to implement Quicksort withoutlooking at our code, and you'll find that testing when the pointers cross can be alittle bit tricky, particulary in the presence of duplicate keys.
 And since as with stack and queue operations, theseinsert and deletes might be intermixed in arbitrary ways and there might be hugenumbers of them either one of these is very attractive because they're going totake N times the number of operations.
 it goes to theleft of E, has to be joined with A into a new 3-node.
Which says that, you know, when it's low, it's not going to percolate.
 So, this is just extending our ball data type that we use for thebouncing balls that didn't collide to take in, into account these extra things.
 And it is that, that's a little extra detail.
>> But it wasn't red anymore, it was black.
That's an important step that we'll talk about later, and then partition the array,so that's to divide it so that for sum value j the entry a of j is in place inthe array.
 So idealistically, what we'd likeis to be able to take any key and uniformly scramble it toproduce a table index.
 So actually with a good generic implementation it's not difficultto simply [cough], take every place that we used string and replace it with ageneric type name as in this code here.
 Instead of push we have enqueueinstead of pop we have dequeue.
 Andthe P is larger, the two children promote that and then finally, the E comes down tothe bottom.
 In this case, the size of the array is going to have to be biggerthan the number of keys that we [inaudible] expect.
 So here's the Java library implementationsfor a few standard types and they are what they are andwhat we'll do is we acknowledge that that'swhat the hash code is.
 And then again, we need an, is valid to check aboutintervening collision.
 So now if wehave a sparse matrix times a vector our running time is going to be constant foreach row or proportional to the number of non-zero entries for each row which meansthat the running time is going to be linear for a sparse matrix just by the useof a symbol table.
 That's a temporary 4-node and we split andmove R to the parent, Now that parent's a legal and there'snothing more to be done.
 so let's look at the just the global properties that thesemanipulations preserve.
 That's our context for hashing algorithms.
 And going the other way, it's easy to see that the children of the node at k are 2k and 2k plus 1.
So, in this example the i pointer stops right away because it's pointing to an rwhich is bigger than the partitioning element.
 So at aweek or so ago, we looked at collections in Java and the idea of elementary datastructures where we insert and delete items.
 But we have to look on both sides tolook for more, but if the rectangle lies to the left of the root node, then we onlyhave to look on the left and so forth.
 So, we have a data type called ball that represents justone of the particles and has instance variables that has the position and thevelocity.
 And so the, it's the concept of so called one way hash functions whichmean that we, we, use it for secure to try to be, have some secure fingerprints foruse on the web.
 K is less than M so we go left.
 But with that, we can properly assess the resource usage of this implementationfor different client programs.
 So now,let's look at some applications then of, of stacks.
 If the if we're supposed to associate a value with a key.
 So, let's look at avisualization.
 And sothat's just the symmetric code to the code that we just did.
 So this is precisely the binarysearch code that we looked at before.
 There's one collisionthat's going to happen next.
 Now for standard keys like integers andstrings and doubles and so forth,we can count on the designers and implementors at Java toimplement good hash functions.
 So now, if you want to compare two different dates then the first thing to dois to check if this year is less than that year, over that is the year given, thedate given in the argument.
 10th point is to the right of 1,it's below 2 so we go to the left and it's tothe right of 7, so we go to the right.
 Again, this is a modularprogramming style that's enabled by object oriented programming languages,such as Java.
 Then now that Tis in its final position in the sorted array, we take it off the heap.
 So this code is thebasis for applying the sort, system sort method or any sort method for the Grahamscan for the convex hull that we did at the end of the last lecture.
 So, now does twelve, fourteenintersect fifteen, eighteen it does not so there's no intersection so now what do wedo.
 And then, flip the colorsand that's a legal red-black BST.
 It's actually quite a bit more complicatedthan the one just on for Quick sort.
 So, after the classdeclaration, we write implements Comparable and then we fill in the genericwith the same type because we're only going to compare dates to other dates.
 So again, a very efficient way to get a sorting jobdone.
 We first in order to sort an array of comparables in this implementation we passa link to the auxiliary array, in as well.
 So, that's the ordering of those points.
 And again, it's well known that mostgeometric data has this kind of problem.
1 what happened was that there wasa huge potentail for really bad collision patterns on typical data.
 Theidea is to, allow not just two or three, keys per node, but a large number like thenumber that can fit in a page.
 So, you can put thecolor of a link in the node that it references.
 And then we gothrough the whole array, and looking for the entries whose IDs are equal to the IDof the first argument, and set those to the ID of the second argument.
 So let's look at point 3 now.
 So our insistence in this course is thatstudents should not use the library until we've implemented it in class.
 So we better go to the right.
 So, say we're inserting L in, into thistree.
 We use the same merge code as before and we takea nested for loop.
 So now our representation ofa queue with a length list, we need to maintain two pointers,references.
 If it works properly,putting in the subtree on the right, that's what we want our right link to be.
 And then that means that C-s got tobe less than A if it is in the right, so therefore there can't be any interesectionin the right either.
 And what's more,it expand to more dimensions.
 So in oursort implementations we can change them as shown in this example to supportcomparators.
K is greater than both the keys, so we go right.
 So, so the way the compilers implement functions is using stacks.
 And now we decrement j, as long as it'spointing to something that's bigger than the partitioning element.
 And there's got to be atleast one leaf for each possible ordering.
 So, not very much code but much,much better performance.
 It's exactly the same when N is a power of2 let's, let's look at this one.
 Again, dependent on the random shuffling,is going to be logarithmic.
 Complete binary trees actually happen in nature.
 Here's an application where people want tocompute the convex hull.
 And again, update all the counts after the recursive calls.
 So, as I've mentioned, redblack trees and B-trees are widely used as system symbol tables.
left is going to be x.
 So that means, the objects in the array are going toimplement the Comparable interface or that it will have a compareTo() method.
 So,you can imagine trying to look for a selection algorithm that takes timeproportional to n and also the lower bound is n because you have to look ateverything.
 Youeither have to check whether [cough] the, one of the points is above p and the otherone is below.
 But what we then do is show how to solvethe recurrence when N is a power of 2.
 So now continuing along we put a star on.
 Most interesting thing about the study ofQuicksort is the average case analysis.
 We can do it in six seconds.
 So we have to check each node, to see if 22 isbigger, and, for the three nodes to the left it is bigger than eighteen.
 That's another great algorithm waiting tobe discovered.
 All right, so, and certainly you want tofollow some of these best practices, so fields that are most likely to differ, those are the ones that youmight want to compare first.
 So NCN N times N + one.
 You can think of that as kind of like the well-known Peter Principle where a node gets promoted to a level where it finally can't be better than its boss, the level of its maximum incompetence.
 And that causes us to add a newentry into this internal, node.
 We'll, get the M.
 If there were no timelimit computation at all, then I'll just hash everything to the sameplace and then do sequential search.
 Not constanttime like an array.
 Whenever you're processing geometric data, you're doing some kindof geometric search.
Okay, our basic array implementationof stacks had the defect where we required clients to provide the maximumcapacity of the stack ahead of time.
 For example, the top line,selection sort is in place it always takes about N^2 / two comparisons.
 So the challenge is to do the resizing,but somehow ensure that ithappens infrequently.
 In fact,we couldn't possibly hope to even store them all.
 So, to insert 16/22 in thistree, while we use the, left endpoint as the search key, sixteen is the leftendpoint of our insert interval [cough].
 So it does no exchanges.
 In color flip, wecould guarantee logarithmic performance not just research, insert, in delete code.
 So, first thing we do is take the reference of h.
 So, you could do it but we're not going tobecause there's a much easier way.
 So, it's got position and velocityas I mentioned, and every ball has a, a radius.
 So, a one-dimensional justmeans we have one key, so we'll insert a key value pairs before and what we want todo is to be able to search for a key, and a value associated with it, want to b eable to delete.
 So now instead of points, our data is intervals.
If it's partially sorted it doesn't make much difference - does the higher sorts alittle bit faster.
 This alternative of choosingbetween linked structures and arrays is fundamental, andit's going to come up again and again when we consider more complicateddata structures and algorithms.
 The [cough] number of nodes examined when wedo a search is the length of the search path to low plus the length of the searchpath to high to [cough] find their ranks and that's going to be time proportionalto log N.
 Now we have i pointing to an element that's equal to thepartitioning element.
 So, there's the same number of keys between eand s as there are between e and t five.
 But it doesn't incur any extra cost at allin production code.
 We just go backwards doing a sync starting at K.
 It's recursive so, checks that we havesomething to do first.
 And the real practical challengewith hashing is that developing a hash function is that every typeof key needs a hash function and you need a different approach forevery key type.
 So nowdo the P, exchange that with the A.
 So now we'll search the leftsubtree of 4 first because the query point is to the leftof that splitting line.
 And then we'll pass the s plit up causing asplit up higher so the red keys in the internal nodes are copies of keys downbelow that direct the search.
 Now, we'll look at the implementationof hash functions.
 So that's 2-3 trees,A, a model for implementing balanced trees in guaranteed logarithmic time.
 MOD 32.
 So, since the only thing thatmatters is collisions, we are going to figure the particles move in a straightline, between collisions.
 And that's a key property is this one-to-one correspondence between 2-3trees and left-leaning red-black trees.
 And there's quite a bit known about it.
It's one over X from three to N+1.
 So again, just aswith, line intersection search, using a priority queue or a sort is only N log Nfor processing the X coordinates.
 So we move up the tree exchanging the larger key with its smaller parent until we get to a point where it's larger than both its children.
 We get this most complicated case we did a left rotate onthe bottom node and that, that transformed it to this case where they're both leaningleft.
 Just go ahead and return the link to that child, and that updates the link and everything works fine.
 So now when we associate E with 6, we have to search throughthe list to see if there's an E.
 And then given a key, a string key, wewant it to print out the files that mightcontain that key.
 So first thing is the partition is inplace.
 So it simply takes its two arguments, P and Q, and checks whethertheir ID entries are equal, and returns that value.
 Nine and four, so now, nine is the small one four is thebig one.
 That put a associate a value with a key in thetree.
 And the next time you ask forthe hash code of that string, it will just provide it andthat works because strings are immutable.
 If we have a rightparenthesis, then go ahead and pop the operator.
And that actually, the analysis, is amazing function that goes back to famousRoman Nuygen and other classical results from our commentorial analysis.
 How do they flock together? And we'll look at a simulationthat corresponds to that.
 The only downsize as wouldregular Mergesort is that it uses extra space proportional to the size of thearray.
 We need to adapt to the data.
 J points to the, rightmost element in theleft subfiles, everything that's not greater than K.
 So, you might think, well,we doubled it when it was full, why don't we cut it in halfwhen it gets to be half full? We don't want the array to get too empty.
 And it's going to read a string ofstandard input and then put it in the symbol table associated with the valuei, where it appeared in the input.
 So, whenever we find a right link, we're sitting on aright red link we just rotate it left and return that.
 [COUGH] Let's look at an animation.
 So that's obviously a verydesirable characteristic.
 Thoseare the ones that we care about, that we want to get through.
 Now, this was very easy to implement and, and we could stopbut usually, what happens in the design of algorithms is now that we understand whatit is that gains performance, we take a look and see, well, could we improve iteven further.
 If the types areincompatible or if either one is null compareTo() should throw an exception.
 If you get allthe way through the array without that happening, then you say the array is true.
 You still need that array but you can set up the code in this way which[COUGH] sort, to sort an array, put the result inthe other one.
 And now, the statistical problems are like that or findingduplicates.
 And velocity matching, where you update your velocity tothe average of the k nearest boids.
 Theconcept of an algorithm was formalized actually here at Princeton, by Church andTuring, in the 1930s.
 I'm sorry, v is less than w, w less than equalto x that you don't necessarily know that v is less than or equal to x.
 Let's look atone more example.
 So, the basic s trategy is, with thoseoperations, maintain one-to-one correspondence with 2-3 trees when we doinsertions.
 John Von Norman realized that thedevelopment of the EDVAC, his EDVAC computer, one of thefirst general purpose computers that is going toneed a sorting method and he came up withMergesort.
 And again the default implementation is tocheck whether we refer to the same object and that's rarely what we want,Java system's programs may be want that.
 And you've, you've used programs like this on, on your computer many instances, mostlikely.
 And then looking on the second link cuz E isbetween D and H.
 So those are just a couple of examples, this is a very fundamental andbasic abstraction.
 They'reon the convex hull.
 Because that equation, with C over N plusone equals CN minus one over N, is an equation that telescopes the first term atthe right.
 We'll read a new word, andwe'll ignore the short strings, just trap out if the wordlength is too small.
 So, what we wouldlike to do is just declare a new array using our generic name Item as in thehighlighted line here.
 So, in this case there's fourplaces where these lines intersect.
And the root of tree containing nine is nine.
 To invoke arrays that sort,you have to import the name space from java.
 And that just means that it's well shuffled, that every possible way of shuffling the deck appears with equal probability.
 Well, each one of these operations are fairly straightforward but just to check our ability to manipulate this data structure, we'll takea look at each.
 And even within that bottom line, there's implementations thatmaybe are not stable.
 That's called Computational Complexity.
 First rotate E to make that link point lean to the left, then rotate R tomake the, bring the temporary four node into balance.
 Now, this computation will be pretty easy except for thedegeneracies.
 So you know,typical Java model, what we will do is create a class called UF that contains twomethods, one to implement union, the other one to implement connected, which returnsa boolean.
 And that's a redundant connection.
So, if you know that you have a particle that's at a certain position or x or y andhas got a certain velocity, the x in the x-direction and y in the y-direction, thenyou can from the distance to the pro, vertical wall you can figure out how manyseconds this is going to take until it hits it.
 And then as long as standard input is not empty, it's going to read twointegers from the input.
 If we start witha right-leaning red link.
 So this is a test client.
 And then,we'll do the same thing for all pairs of particles.
This is extending the table we looked at last time, and you can see over in theright column here, Quicksort is quite a bit faster than Mergesort.
 So, we start with a single key.
 And we're at the end of the computation and that's the result.
 So Java has a customized implementationsfor the standard data types that people would use for similar table keysand that's the sweet spot for hashing.
For a million nodes, that's between twelve and twenty.
 So for enqueue, you add a new item a tail.
39 n log n.
 6 is not any closer than 3 was, sothat's not going to update our champion.
We have to save it some of way.
 And it's, quite straightforward, given the demo thatwe talked about.
 Well in the best case Quick Sort willdivide everything exactly in half.
Rotate the top, our temporary four node is balanced, flip colors.
 Take time proportional to N forevery operation, and therefore quadratic time for everything.
 Mathematicians were trying hard tounderstand this problem and were ready to give up and he realized you could useclassical balls and bins type probabilistic analysis.
 So, now we need to rotate left and then once we've done that,now we have a legal left-leaning red-black tree.
 So let's look at the, the cases that could happen.
 So in thiscase, we would change the entry of nine to be six to merge three and five.
 It's called universal hash functions.
 That's quicksort, mergesort, heapsort and radix sorts.
 So, all kinds of information processing that we might needto do for large amounts of data, represented in comma, comma separatedvalue files this one client which is based on a symbol table will provide usefulfunctionality.
 The constructor, takes SR unit, the number of objects, so that it canbuild data structure based on the number of objects.
 Because if K were in the table it would besomewhere between it's hash point five and that empty position nine.
 And so, the key values well, are just specified aspoints on a line.
 We've described the operations we want toimplement all the way down to code and we have client code that we're going to haveto be able to service with our.
 So, in this case, if you go from top to bottom in the tree with threecompares at most you can determine the ordering of the three different items.
Here's a visual trace of 3-way Quicksort for situation with plenty of equal keys.
Simply does the partitioning.
 So again, we take thefirst item and make it a child of the root of the tree containing the second item.
 So without seeing all the details yo can understand that the same basic ideais going to work in this situation where we're dealing with much, much more memory.
 Thereason is they don't scale.
Again, as with Mergesort, studying a recursive trace is instructive.
 And get I'll return zero if the index key is not in the symbol table.
 You don't want to use a.
 Or like the one at the bottom credit cards.
 Thelargest one in there is X.
 Now, and what's mostimportant to recognize about this is that its the algorithm design that enables thesolution to the problem.
 What we can do to remove a node with a given key, is just mark it with a tombstone.
It doesn't use any extra space.
 We have an is empty testwhich returns a boolean.
 And youcan see from this transformation that it's easy to perform this, see thiscorrespondence the middle link between A and B, those are the keys that are lessthan B and larger than A.
 Like these are all the ones associatedwith this, lecture, so we might build an indexfrom that set of files, and then we might wonder well where do we use the importstatements.
 So, when the depth of x increases, the size of its tree at least doubles.
 People might be interested inthis one.
 The only differenceis how efficient is that.
 And also,it doesn't support ordered operations.
 Then there's three cases.
 So, for example, the word freedom appearsin the Magna Ca, Carta and in Moby Dick and ATale of Two Cities [COUGH] in all three of them but not in Tom Sawyer and not in Aesop'sFables.
 The call, or operations have costs that'sproportional to the path link from the, height to the bottom, and every path fromthe root to a null link has the same length.
 So we're gonna go right.
 We want to add something to thecollection, maybe remove something from the collection and iterate throughthe objects in a collection, performing some operation on them,and of course test if it's empty.
 If there's some ordering that is notappear in a tree corresponding the particular algorithm then that algorithmhasn't can't sort, can't, can't tell the difference between two differentorderings.
 So the two operations that we'regoing to perform in symbol tables is the insert operationwhere we're really putting a value, a key value pair into the symbol table,a value with a specified key.
 So ithas to split and we have to create a new route, just in the same way as we've beendoing.
 Not difficult, but a definitely tricky programming exercisethat people are welcome to try.
 So increment the frequencyin the symbol table.
 And that uses apush down stack for the hull, it puts the points on the hull in it goes ahead andfor every point considering I'm in the order of the polar sort it'll comparewhether the top two points on the hull and the new point implement a CCW turn or not.
 You could implement this bybuilding explicit links but the an easier thing to do is to know that every node isreferenced by just one link in a tree the one from it's parent.
 This is our online course Algorithms developed bymyself and Kevin Wayne here at Princeton.
 And really have enabled a new developmentsand new technology in all of these kinds of applications.
 Just take the three nodesand split them into little binary search tree of size two held together by a redlink.
 Sothe real property of external storage that not your local memory, is that the timerequired to get to a page is way larger than the time to access data within apage.
 So that's just, you can think oftwo-dimensional keys as a points in two-dimensional geometric space.
Now we're going to take a look at whathappens when we have significant numbers of duplicate keys which is not at allunusual in practical applications.
 With using weighted quick union and with pathcompression, we can solve problems that could not otherwise be addressed.
 What's the implementation of an exception filters?Here's a simple one using the said API that we just articulated.
 If we've got some points that are on the boundary but aren'treally vertices they shouldn't be included.
 Move all the values associated withthose keys over in one position and put the associated value in.
 So, that's sometime t, we can take twoparticles.
 So that's just a, a way of make suring that the simulation keepsproceeding.
 All those subtrees, those three subtrees areexactly the same relative to the top and bottom of the tree, as they were beforethe rotation.
 We, use the hash function.
 Well, we're gonna go to the right, because, the max endpointin the left subtree is eight, and our interval's 21, so no intersection on theleft.
 I use that same space, and just,allocate an array.
 To findthe key and you stop when you find an empty table position.
 But the key point about it is that designing acomputer became a geometric problem.
 This is the code for Hibbard deletion.
And that's actually not worth the cost for enlarged samples, not usually.
 We have operands andoperators and you want to evaluate it.
 Andagain nobody's claiming that this is easy but this is the Physics part and it'sworked out and it comes from Newton's Second Law.
 And the firstone called by name implements a comparator for students and when you compare twostudents by name, it's going to use the string comparative method.
 And we get M balls.
 We're going to finish up by talkingabout some, practical applications of red black trees.
 Those are the two basic operations.
 And again, if the uniform hashing assumption holds the probability that thenumber of keys within a list is within a constant factor of N over M is extremelyclose to one.
 And so, there is still the goal of a, of afast guaranteed linear time selection algorithm maybe somebody in this classwill invent someday.
And if the program is using primitive types, maybe performance is the mostimportant thing.
 And again, the, heap is stored in the array, with the first key positionone, next to position two and three and like that.
 And to believe this method, you just have to think recursivelyand prove by induction that this in order method puts all the keys in the datastructure on the queue in their natural order.
 So, just adding thisextra loop for h-sorting and this extra loop to compute the increments toInsertion Sort, we get a slightly more complicated piece of code but its much,much more efficient.
 After we do the left rotate, we have a legalleft-leaning red-black tree, and it exactly corresponds to that 2-3 tree, sothe insertion of C gives us exactly what we would want, that correspondence withthe 2-3 tree.
 So, to iterate we're going to maintain a queue of keys.
 So we take the E, replace it with the H, and delete the H, and then everything's fine.
 Theirjust right there, you look at the first or the last.
 When we continue toimplement sorting algorithms, we're actually even in a hide that beneath ourown implementations.
 So in this tree, the color of h.
 We'll take the first one so we move thatone up increment i and k.
 So that's, that's the problem, rectangleintersection search.
 First ofall, you can see we're going to need a computer for this.
 So, for example, 3's parent is four, 4'sparent is nine.
 So now, let's look at the second warm-up.
 And the reason we do this is that it generalizes to giveus more efficient data structures later on.
 And we'll put a new item at theend of the array and remove it from the end of the array.
 We don't haveany, any equal lines that we have to worry about whether we consider rectangles thattouch to be intersecting, and so forth.
 So what we want to do is try to access data that's out, externally, usinga minimum number of probes.
 Now, there's actually some deeper reasonswhy this method is important and one thing to do is to realize that the lower boundthat we talked about before depended on the keys being distinct.
 Where a vacant side is just empty and a block side hasgot some material, and either the water flows through from top to bottom, or not.
 Then the other thing is thatinstead of doing compare to's, we're going to be doing equality tests.
 Maybe later, later on, after an experienced programmer who knows whathe or she is doing could use some of these library collections effectively.
 Where everything to the left of I is lessthan or equal to V.
 It's the number of times you have to takethe log of N to get one.
 Okay, that's a right rotation.
 So, number of pros for search and insert's proportionalto N over M.
 And that just means that our keys must be Comparable and wemust have a compareTo() method that will compare it to another key.
 It'll say that the most frequent word,where there's no word that appears more frequently than it,which appears 10 times.
 So we want to be able to insert anddelete points, you can think of a two-dimensional keyas a point in two-dimensional space.
That's just a few examples of the percolation model.
 We can use resizing array in industrial strength implementation, the same that we did for stacks and other data structures where we use arrays.
 So, that's how to maintain size.
 I won't go through it all in detail just to point out that thisimplements two different comparators as nested classes.
 And simple algorithms like insertions or dump,they've they don't use any extra space at all.
 Two and one means that we connect two and one by changing the 2201.
Now, once we can calculate these roots, then we can implement the find operationjust by checking whether the two items that we're supposed to check with areconnective where they have the same root.
 And again, we keep going until getting to the bottom, or getting to a place where both children are smaller.
 So that's insert for a binarysearch tree in a symbol table.
 It's a little less calculation.
 The word whale is only in, Moby Dick.
 And their in,kept in sorted order.
 That's just another simple example.
 Really, what we're saying is when we go to the left link of H, it says, if G isin the tree, it has to be down this link.
Okay, what are the rules that we're goingto follow? Well, let's start with looking at a typical basic sorting problem.
 Now when we implement objectsthat are to be sorted we'll implement the Comparable method.
 Mergesort and log N guarantee unstable but not inplace, need that auxiliary array.
 And then print out the word that occursthe most often, along with its frequency.
 So how do we model opening a new site? Well to open asite we just connect it to all it's adjacent open sites.
 And this is problematicbecause the union operation is too expensive.
Now we're going to look at k-d trees,which is an extension of BSTs that allow us to do efficientprocessing of sets of points in space.
 We're going to have keys likeour keys in priority queues but the whole idea is that we're going towant to associate values with each key.
 We do the BST insertion, just so we have to do that,update of the maximum in each node on the search path.
 There's other things that we can doalgorithmically to bring down the search time a little bit.
 But what we'll do is invoke a recursive method starting at the root andwhatever link gets returned, we'll set that to root.
 Now, in this case, to implement delete max we save away that value at the root in max, and we eliminate loitering by nulling out that vacated position, then return the max value.
 So we have a, a, a bunch of conventions just toreduce the code.
During and after partitioning.
 So here'san example.
 And actually there's differentassumptions that we'd make in our implementations dependingon the application.
 This, slide summarizes the code for, heap construction.
 The number of possible shuffles is much more and it's 52, it's 52 factorial which is a lot bigger than two to the 32nd, so it's not close to random or uniform.
 It takes linear extra space.
 This array has six inversions.
 So find the H, that's the minimum, hang on to it, and then delete the minimum in T's sub-tree.
 So, what we'll do is use a recursiveimplementation that as it moves down the tree it'll return a link up higher in thetree.
Now, again, many of Java's standard types for numbers and dates and files and soforth implement compareTo() by convention.
 Other, otherwiseit returns the value associated with the index.
 And just the guiding principal ingood modular programming is that we should welcome compile-time errors and avoidrun-time errors because if we can detect an error at compile-time, then we can shipour product or deploy our implementation our implementation of an API and have someconfident that it's going to work for any client whereas, the error is not going toget discovered until run-time it might occur with some client development.
It's a simpler equation already.
 So, that's theskeleton.
 So that's thebasis for the Graham scan method for the convex hull that we used at the last, atthe end of the last lecture.
 We're given an array of n items that areordered and our task is to find the k-th largest.
 These are used for digital photos, where the objectsare pixels they're used for networks, where the objects are computers, socialnetworks, where it's people, or computer chips, where it's circuit elements orabstract things like variable names in a program, or elements in a mathematicalset, or physical things like metallic sites in a composite system.
Find operation requires a little more work.
If you did the random shuffle, it'll be about 1.
 That's another one like merging in place, that you'd think there ought to be an easy way to do it, but in 50 years, no one's really discovered one.
 And again, this is high school Physics.
 The exact analysis is notmuch more detailed than that.
 And again, that's just flipping colors.
 And then we test those models throughexperimentation enabling us to improve algorithms iterating, developing betteralgorithms and more refined models until we get what we need to solve the practicalproblems that we have of interest.
 Well 2N over 2 is N, 4N over 4 is N and wekeep going down, doing that til we get down to D of 2 and we always forthe extra cross for the merge, we have N.
 What about floor and ceiling?Well, those are a little bit more complicated and we'll have to, not quitethe same as in the ordered array for the binary search so we have to do a littlebit more work for that.
So, even with this huge stream of items coming through, we're only keeping trackof the M largest items and that's a fine canonical client for priority queue.
Now, you, you can see this next insertion is going to cause some splitting whereverit is.
 But in many other cases maybe it's not fast enough, or there's notenough memory.
 It's going tobe ten times as slow.
 If it is, then we exchange with the larger of the two children and move down the heap.
 But finding the best incrementsequence is a research problem that has confounded people for quite a long time.
 The quickbottom line is that insertion sort and mergesort are stable but not selectionsort or Shellsort.
 And in this case there is no paren, so wecreate a new one and the height of the tree increases by one.
 Theproblem with this is that the client code has to do this, this casting and it's kindof an insidious bug if it doesn't quite get it.
 And it's enabled by priority queues.
 That's what we're going to be looking atnext when we look at more efficient algorithms.
 And that's just the way it organized.
 So [cough] thisis the get procedure.
 So, what we want to do is increment lt's.
 So we start at point p.
 So, finding, incrementing I, as long asit's less is a simple while loop.
 So first of all, is the, there's a node at the root.
 And that's maybe a little bit what happens when a new boss is hired from the outside and then the two subordinates struggle to take over that position and then the boss would get demoted to it's level of competence.
 That's going to associateintegers with strings.
 Its item is the string that we want toput at the beginning of a list, in this case, not.
 Sothe main part of computation that we haven't really talked about and we'llcover briefly is if we have three points, a, b and c, and you go from a to b to c,are you making a counterclockwise turn or not? So, in the example at the left, a tob to c is counterclockwise.
 The displacement gets up to square root, of pi M over eight.
 Shellsort, we don'tknow it's a running time, it's not stable but it's a fast method for intermediatesize files and not much code.
 If one of the particles is null then we're talking abouta wall, a vertical or horizontal wall.
 The other thingthat is probably more significant on modern machines is.
 But with random, the random shuffle it'smore likely that this lecture will end, because of a lightning strike.
 Now that's a lot of words let's look at a demo.
 So [cough] that's a insertion into athree node at the bottom.
 Part of thearray is the sorted sub array.
 So, if put works properly inserting a new nodeon the left, then that's what we want our left link to be.
 So this array has six inversions, T and R are out of order,because R should go before T.
 It's going thewrong way and essentially what this means is a point 4 is evidence that point,there is no way the point 3 can be on the convex hull.
Our implementation, we stopped the partitioning scans on items equal to thepartitioning item and then in that case, when all the keys are equal, it's going todivide it exactly in the middle.
text has the certain number of three letter words and this client program willresult in those three letter words being rearranged into alphabetical order.
 So in this casewe put on zero and then we put on one and then we put on two.
All of this involves the scientific method.
 Once we have a good algorithm, if we haveanother problem we can say to ourselves, well, we've got a good solution to thisalgorithm, can we use that solution to solve our new problem? Convex hull, whenwe have a good sorting algorithm, it gives us a good convex hull algorithm.
 And in fact, it didn't take that much hacking for someone to realize that after seeing five cards and figuring out what the server clock was doing, you could get all the future cards in real time in a program, and that's a pretty tough thing to have happen if you're implementing online poker.
[COUGH] so the first thing we do is, take the smaller of the two entriespointed to by i and j, and compare those, and take the smallest one, and movethat one to be the next item output.
 And again, we want to try to make useof all the pieces of data that we have.
 It's got what we call nodes which containinformation and every node's got two links to Binary Trees that are disjoint from oneanother, a left tree and right tree associated with each node.
 There was a killer input that will make thething run in quadratic time.
 So Lets suppose that there is no intersect, and that'sequivalent to saying, if there is no intersection in the left then there is nointersection in the right.
If we exchange them, we'll maintain the invariant that everything to the left of Iis less than the partitioning element, or nothing to the left of I is greater thanthe partitioning element, and nothing to the right of j is less than thepartitioning element.
 But the heap conditional will be violated because T is still smaller than S.
 So, in this case, it starts out with the inputexample shown and then the 13-sort - a few items are moved, 4-sort - a fewmore are moved, and then finally, a 1-sort.
 So, with one line of code, we can keep the treesalmost completely flat.
 So the first thing we do is copyeverything over to the auxiliary array.
 It's just that we'reable to do it with way less space.
 What we do is we sayif, if the argument is null, return a reference to a new node that associateskey with value and then that one has null links.
 If our search key is less, we go to the left.
The words cities actually only appears in this one place and this is [COUGH] Contextthat it appears.
 Lots of implementations, data type implementations in Java are immutable.
 And h's color is going to be red.
 Well, it mightbe E but there's no way it's to the left of E because those keys are all smallerthan E and therefore smaller than G.
 It does not, So, now, theleft end point's null.
 Now arereferred to this idea of a good system sort, there was a good system sort that alot of people used for many years.
 So this is just a graphical representationif we want to compute D of N we want to computeD of N over 2 twice.
38 logbase two of N almost the best that you could do.
 Now that's also simple toimplement and it works well as long the size of the array is, significantly biggerthan the number of keys.
 Why are we using the successor, and not the predecessor? No real reason.
 But now, both the union and the connected or find operation takestime proportional to log base two of N.
 If we use a slow Union-find algorithm we won't be able to run it forvery big problems and we won't get a very accurate answer.
 So the client will build a symbol table that makes us associations for everyline in the file and this could be huge file.
 So we're looking for a piece ofinformation somewhere in a computer, and it'll give us the names of the filesthat contain that information.
 On keys with values well the key is the string we type what's the value? Well what we're going to use for value isa set of files, the files that contain thequery string.
The 2-node containing H, Right link is null,So we convert that 2-node into a 3-node and now we have a legal 2-3 tree.
 And one ofthe things to remark about it is that it only uses N exchanges and so forth.
 So in that case now we go to point 3, compute the distance of thatpoint to the query point.
 So even with these simple data structures,we have really important tradeoffs that actually make a differencein lots of practical situations.
 Insert L into that one.
 In mostdatabases, nowadays that, that you might use.
 And somebody's implemented a service in Java that it uses a simp letable that takes string keys, you can cause that to crash in this way.
 So we're going to swim it up, exchange it with its parent as long as it's smaller than its parent.
 So we don't use inheritance that much soI won't talk about that.
This subtree has six nodes in it and so forth.
 And on the other thing is it's not stable,sometimes people choose to use Mergesort in practice because of the stability butHeapsort isnot stable for the usual reason that it does long distance exchanges thatmight bring items that have equal keys back out of order.
 So we increment i and then figure out what to do.
 You don't want to make M too small,it'd be too much time.
 The implementation is simple,except for the comparison.
 Solve a problem by dividing it into two halves, solvingthe two halves, and then putting the solutions together toget the appropriate answer.
" Just like verse, they can be terse, elusive, dense, and evenmysterious.
 So, we createan array of objects and then we cast it down to an array of items.
 Five and four 4's root is eight.
 And then, what the priority queue tells us is - let's organize it in some ways that we are always taking the best one to processnext.
 S that means that, in mathematical terms,equals is called an equivalence relation.
 If you try to do it without it, you're not going to besuccessful.
 You can see in the top the big tree has some trees, some nodes, a fairdistance from the root.
 So that's complete binary trees represented in array with keys in the nodes, satisfying heap order property.
 Seven and two, union seven and two.
 And then adjusting the heap ordering with the sync operation.
 The second improvement that we can makethat'll improve the performance for cases when the array is partly sorted,is to just stop if it's already sorted.
 And also we didn't have the simple left-leaningrepresentation.
 And that's alsoa simple recursive algorithm.
 And six and one,between six and one.
 A binary search tree is abinary tree in symmetric order.
 Sothat's the first piece of code for heap ordering an array with arbitrary valuesand then these diagrams summarize the sync calls that, that we just went through inthe demo starting at five, four, three, two, one.
 So that's what's happening over in theright there.
 The amount of space required is N squared,for the grid plus N.
 And that's a fundamental problemthat we have to deal with in array implementations in all sortsof algorithms data structures.
 There's ways toimplement that don't involve this, but its, the code is so simple and it extendsto more powerful data structures later on that we'll introduce this right now and,and you'll see how it works.
 And we can keep the root page in memory so that it means, for anyconceivable application, you can get to any piece of data.
 So that's called a Kd tree.
 And what we're going to look atas one of the most widely used, which is basically to usea tree to represent a recursive subdivision of the plain,of two-dimensional space.
 What we're going to do is divide an arrayinto two halves.
 Give me the largest keyless than or equal to this key value or the smallest key greater than that keyvalue, give me the number of keys less than that key.
 We wanna be able to insert an interval.
 It gets more complicated ifthere's more forces, like gravity involved.
 And there's been a lot research done to develop functions thattake keys as input, and then produce values that look random.
 And eventually we bring it down to the wholething being sorted.
 They're not as efficient as union findbecause they have more work to do.
36, index five also has 0.
So that's an example of a white list filter.
 Un, so what about in actually in practice?This is our fastest sorting algorithm, and there's a few ways to make it even faster.
 That means it's done.
 And all the points that fallto the right of the first plane are going to be on the right.
 So, what arewe supposed to do when two different keys hash to the same index? The birthdayproblem tells us that we're going to have collisions.
 We're not going to spend a lot oftime on this, in this lecture.
 And it's effective, it means you don'thave to actually move items, and that saves a little bit oftime.
 You can't have M too large, whatwe want to use nowadays is array resizing to make sure that the array is alwaysabout half time, half full.
 You have to have a linked list element orwhatever for each point.
 So, here's an example, say using the data type for vectors, might be a way to implement vectors.
But in same with 3.
 And also we're going to represent it with an array.
 For insert, I would also haveto scan through all keys to find the place to update a value,if it's a value that's already there.
Each one of these union operations just involves changing one entry in the array.
 And so for some clients,maybe that makes a difference.
 If you keep the things in order like in a binary searchsituation then to insert in order to keep it in order in an array, you might need tomove the larger ones over one pos ition and so forth or elementary implementationof binary search when we did symbol tables did this.
 Well, youcan see that this isn't going to be in general an N by N square and about half of theelements in the square are black or about N^2 / 2 and you can see also the exactformula (N - 1) + (N - 2) and so forth is the total number of compares used.
 So, that's a quick demo of Quick-find.
 Unfortunately, it's usually the case in geometric data that the pointsare not evenly distributed.
 8 can'tbe on the convex hull.
 If there is no duplicatekeys Quicksort processes them and referred them out in BSTs and if there's noduplicate keys there's a one-to-one correspondence between what happens withQuicksort and what happens with binary search trees.
 Then we'll consider classic algorithms for sorting, puttingthings in order.
 And if you find that b is lessthan c and a is less than b, then you know that they're in the, any algorithm thatdoes that knows that the items are in the order a, b, c.
 But the space is proportional instead of to N, it's just proportional tothe number of non-zero entries which again, in typical applications, may beway, way less.
 Actually not all sorts preservethat property that is called stability.
 But the other thing is if the increments are small because we'vedone previous h-sorts for bigger values of h, the array is partially sortedand so Insertions Sort is going to be fast.
 So sorting is out ofthe question.
So now let's look at a basic geometricdata processing problem of determining intersections among a set of linesegments.
All the words, pick out our key, s, and again, if, it's not there yet, we create anew set associated with that s, and, then, afterwards, we go ahead and.
 Thetheoretical best that you could possibly do would be R plus log N but in practice Rlog N is quite efficient.
 And again, you can get a feeling for where the proposition comes fromby looking at this N by N trace.
 So all that means is that ourimplementations can use compared to but for the client it means that all theseoperations have meaning.
 And that's very easy to implement.
2 of the book.
 So, if you think of all this is,is, is trivial and easy, go ahead and try to write down a proof that a g-sortedarray remains g-sorted even after it's h-sorted.
 Base M over two M probes and that's going to be a really small number, so sayM is a 1000, log base M over two is, is log base 500.
So, in gray is our, standard insertion code for binary search trees.
 Associate E with 1, that's not there,so we just add it to the beginning of list A with 2 R, with 3C,with 4 H, with 5 and so forth.
 The four to the left and the four to theright.
 If the keys happened to have some order in them, our trees are not going to be balanced at all, and that's going to make the difference between acceptable and not acceptable performance.
 And this is just for random insertions.
 So, amathematical set is just a collection of distinct keys.
 And all the red links lean left.
 But the bottom line is, don't think that it's easy to shuffle a deck of cards.
And these diagrams summarize the sync operations that we showed in the demo.
 You use the same hash function.
 The reason is that you have to createa new array, size one bigger, and copy all the items to that new array.
 Andthen, get the numbers of the fields, so the key and the value.
 Then we create a new node that'sgoing to be the new node that we put at the beginning of the list.
 Andso in this case the longest path is ten and the average path is seven for 255.
Welcome.
 And one way to think about what goes on is to just watchwhat happens when a hash table fills up.
 So, that's our test clientand that's a fine test client to make sure that any implementation does what weexpect that it will.
 So now we invoke the sink where we exchange that node with the larger of its two children until we find a place where it's larger than both of those children.
 Now,when it's returned then that's the point at which we're going to check whether theleft, the links are leaning to the left as they are suppose to and whether or notthere are any double links or not.
 There's the stacks are reallyactually fundamental underlying computation because they implement ,recursion and so, you use stacks often everyday when you wrote, use the Backbutton in the Web browser, the places that you've been are saved on a stack.
 And then there is a constructorand maybe we have a constructor that takes arguments that would initialize theposition and the velocity or maybe initialize them to a random position ifthere's no arguments.
 So, to get started, we'regoing to look at a simple problem called one-dimensional range search.
 So here's the skeleton ofour symbol table implementation.
 Alot of people ask why use the name red-black.
 It's possible to come close to this.
36, index fourteen has 0.
 So, it's a very simple API but of course, we're going to be ableto do these operations efficiently, how we'd we go ahead and implement that.
 And you can test this out for different types of environments easily andit's representative.
 Probably a bad idea to use the first threedigits of the phone number as a hash function because so many phonenumbers will have the same area code.
 So again about 1.
 We want to find just.
 But then the very next one,the 9 has to only go back one position, and the 6 has to go about halfway back.
  Each time we have to scanthrough all the remaining entries in order to find the smallest.
 If you come straight across,there might be a closer point.
 On a personalnote, I wrote a research paper on this topic in 1979 with Leo Givas and wethought we pretty well understood these data structures at that time and peoplearound the world use them in implementing various different systems.
 So this two, complimentary ways to look atthis.
 And it's based on so called in-order traversal.
 So again, a very general capability that'sgot lots and lots of applications and easy to implement withour symbol table api.
 So, if we're looking for H, it's less thanM, so the only place it could be in this 2-3 tree is in the 2-3 tree on the leftlink, So we follow the left link.
 But the other thing is even ifN is small if you do a very small dt, then you're just doing this calculation overand over again and there's just too much computation moving the balls little bit ata time.
 You can [cough] convinceyourself with that quite easily.
 Nowthere's a number of considerations to take into account.
 In fact Quicksort, which we'll consider next time, was honored as one of the top 10 algorithms of the 20th century inscience and engineering.
 So as I've mentioned and this diagramshows, the splitting of 4-node and a 2-3 tree is a local transformation.
 They have every key in the symbol tableand a value associated with that key.
 To check if it's empty we check if N is 0.
 This version keeps it unordered.
 We have this inner class that we use tobuild the items in the linked-list and we make it an inner class so we can directlyrefer to those instance variables.
 In the weighted algorithm, wealways put the smaller tree lower.
 Is empty, it is just checking whether YN is equal to zero.
 So we've drawn the data structure with the links so we have an intuition for what's going on, but all the program sees is the array in gray at the bottom where T is in position one, P and R in position two and three and so forth.
 So an interval is just a leftendpoint, right endpoint of a 1-dimensional data or points on the line.
 So, if we are looking for all the keys between f and t then we haveto look at both the subtrees of the root s.
 And then we're going to create a newsymbol table that associates strings with sets of integers.
 And then we'll go ahead and do thepredictions of each of those particles, A and B, against all other particles.
 So the idea the sign behind bee trees is thatoften, the data that we're, trying to store is, is really huge.
 But as you can see by looking at this table, it gives us a way to implement priority queues where both operations are guaranteed to happen in log N time.
 Or, even nowadays youmight have matrices that are, are even bigger.
 And there will be some code between thecompares but either way then there is going to be a different compare.
 If x.
 To begin, we'll take a look at the API andsome elementary implementations and various operations that peoplewant to perform on symbol tables.
 That's legal.
There are lots and lots of applications of priority queues.
 And it just leads to a lotof interesting questions.
 And this is when this parent is a 3-node,then there's the tree cases, If we split up the last split at themiddle and split at the right, And again, changing the four node to, to a2-nodes and adding links.
So easy to code.
 If N is a power of 2, then N over 2 is also a power of two, so the recurrencemakes sense.
 What about, being able to iterate between, among all the keys between twogiven times? That, certainly is convenient.
Next, we're going to look at a bottom-upversion of Mergesort.
 This one has a constructor, andthe constructor creates the array.
 And it also just supresses a lot of details that are notrelevant to union find.
 No way can you formulate theproblem as so called parking problem.
 As I mentioned, it goes back to the study of physics with [cough] thetrying to understand the pressure and temperature in Einstein's famousexperiment on a pollen grain showing that their motion was brownian and random.
 So, that one goes right in to the value stack.
But what we can do is split that 4-node and pass the middle key up to its parent.
 Ifthat red link were, were way down in the tree and there were another three nodeabout it, we might have to do it again.
 Separate chaining is reallyeasy to implement both insert and delete it performs, it degrades, it does sogracefully and the clustering is, is maybe less of a problem if you have a bad hashfunction.
 On the other hand, in a dynamic situationwhere there are a lot of inserts, this method is going to be problematic,because the cost of its insert is linear.
 But thespace is only proportional to the number of non-zero elements plus N for the extrasymbol table overhead.
x)(c.
 You can think of it intuitivelyas like a dictionary.
 So for this small data from the beginningof Dickens' Tale of Two Cities, if we run a FrequencyCounter,the FrequencyCounter client.
 It'll use less andexchange just like we would in sorting methods.
 And then in both cases, we increment a, not imple, increment k, and thatimplements the merge.
 For, anybody after that time doesn't get aticket.
Another popular closure resolution methodis known as linear probing.
item andsave that in the variable item.
 The proof for this fact is quite beyond thescope of this course but it's still an important fact.
 So, that takes two comparisons to get to them the onesthat are less than A, less than, less than A, that's two comparisons for that and theones that are greater than B are the right link of B.
 The invariants are that the entries on ontothe left of the arrow are never changed and they're in ascending order.
 Now, the color of the root in our code willtemporarily turn red and then we turn it black again.
 Put the value on to the value stack and finally, the lastright parenthesis, take the two operators of the value stack, operators of the valuestack, and operator of the operator stack, perform the operation, put the result backon the value stack.
 Each point has to be inserted, deleted.
 There's trillions of them therecoming through as fast as possible.
 Now, K is inserted into the 2-3 tree andit satisfies all the rules.
 So actually once you 1-sort, that'sInsertion Sort so you're going to always get a sorted result.
 So, TCC is called serine, and so forth.
 So, and I will pick a parameter M and divide space intoan M-by-M grid of squares.
 Sort the second half, and then merge themtogether.
 So.
right is red so that means the rightlink of H is leaning the wrong way.
 Stop at e those two elements are out ofposition so exchange them.
 And then we'll just throw awaythe ones that do not create a counterclockwise turn and you'll see howthat works when we look at the demo.
And now that first subarray is exhausted so reallyall we need to do is take the rest of the elements from the rightpart and move them back in.
 So in the end, the J pointer is pointingto the partitioning element V, which was in position V in the first place.
 Five goes to bea child of zero.
 Two dates should be equal if they havethe same day, month, and year and if any one of those are not the samevalue then just returns false.
 So the, the reason they used that is they thought they gotthem closer to the middle and they also don't like the, some system designersdon't like the idea of using random choices in a system method because of waythat it changes the state of the system.
 [COUGH] here's a trace of what Mergesortdoes and if you haven't studied a recursive program before it's worthwhilestudying this thing in, in some detail.
 So the a quick hack that is widely used is to use casting to implementto reuse the code for different data types.
 It's all about the idea of passing functions asarguments to other functions which is the pair and gets into functional programmingand thinking all the way back to Turing and Church.
 Minimum and maximum well again those are like select.
 And what we want to do is given the set of points,we're going to have a program that can give us the convex hull.
 The operations that thealgorithms are allowed to perform.
 Sothere needs to be a mathematical analysis to, to characterize the running time ofthis program in the fact is that quick select this method takes linear time onthe average.
 So here's the full implementation of stackfor using an array to represent the stack.
That's what the Comparator interface is for.
Now we'll look at the problem that'srelated to sorting called selection that's also well solved by Quicksortpartitioning.
 They're different.
 So now,we've got a heap with nine elements and two of the elements in the array arealready in their final position.
 What we want is sufficient implementationsof both search and insert.
 They could contain millions of keys,But it doesn't matter what they contain.
left after the rotation is going to beh.
 But if they use a stable sort, then it stay sorted by time and lots ofapplications you want stability.
If the key's already in the tree then we're just going to reset the value.
 In this case we're lookingat the b's.
 After that exchange, then S is in position two and it's bigger than both P and H.
 The typical, typical case it'll besort of balanced.
 So westart out with the empty value stack and operator stack and we're going to movefrom left to right.
 And then we have to flip the colors.
 A keyof type key, a value of type value and then references to a left and a rightnode.
 So, those are the three basic operations we're going to use.
 And it's easyto extend that to handle other types of things and so, why does this work? Well,when the algorithm encounters an operator, say, in the inside, we got the parenthesis,operand, operator, operand, parenthesis its easy to see that what its going to doinside there is put the at the top of the stack whatever it is, is to put the twoand three on the top of the value stack and plus on the top of the operating stackand when it hits that right parenthesis, it's going to perform the operation andit's going to proceed then exactly as if the original input where that, where thevalue replaced.
 Then if you have a field that'sit's an array you can go ahead and try applying it to each entry andthere's implementations in Java.
 And move the j pointer from right to leftas long as it points to an item that's greater than the partitioning element.
 And, andthat's going to be important in the use of a matrix.
 And so, it'san annoying surprise for many people and many applications.
 So,we're going to take the next event from the priority queue.
 One thing is the size of the heap is got to go down by one.
 Which isobviously much higher than we want.
 And again N could be huge in applications,as we'll talk about in a second.
 So we get D of N over N equals log N, or Dof N equals N log N.
 That's a demo of search and insertion in a2-3 tree.
Now, hashing also has a extremely important application in today's Internetcommerce.
 The way that we move around the tree is by doing arithmetic on the indices.
right.
 And then,we're going to call this recursive in-order [cough] method.
 So, what are the tradeoffs between usinga resizing array versus a linked list? Those are two differentimplementations of the same API, and the client can usethem interchangeably.
 And [COUGH] for each file we're going tocreate an input stream.
 It's as if you're waitingin line to buy a ticket.
 [cough]and because in this implementation for left-leaning red-black trees we're goingto return the link whenever we're done, and then that will get that link installedup in the node above whether it be left or right.
 So, that'sflipping the colors.
 Again, we take it out by exchanging this time G with a root, and then decrease the size of the heap by one and just take that out.
 So we can have intersection there, so we gonnago right, [inaudible] to twelve and go right.
 So thenumber it compares is going to depend on the order in which the keys come in.
 [cough] or in, in youknow, in the case when we're just inserting a new node and it's turns out tobe the right red link attached to a black one, if that handles that case.
 You might ask for all the peoplewith incomes between 1 million and 10 million who are between 40 and50 years of age.
 So that is the pop operation,what about the push operation? Push operation, we want to add a new nodeat the beginning of the linked list.
 Re-arrange an array of n items into ascending orderaccording to a defined key which is part of the item.
 And every time we pick an integer between zero and i uniformly at random, and swap a of i with that integer.
 So then see how many things happen between nine:15 and nine:25.
 So then if we put withnull as the first argument, then null is the first argument.
 To get started we map a key to a integerbetween zero and m-1 where m is the sides of our array where we are storing thekeys.
Reading all the strings on an input stream, on standard input,and, splitting em by blank space and putting em into array, sonow all the words, are, in the an array.
 The Javaimplementation of tree map and tree set is red black trees, C++, the standardtemplate library uses, red black trees.
 Again, quite useful and familiarfunctionality and very easy to implement with our simul tableclient.
 Bad programmers worryabout the code, good programmers worry about data structures, and theirrelationships.
 And this idea is that, well, when we're tryingto find the root of the tree containing a, a given node.
 And in fact, most of the other operationsthat we implemented on BSTs are also identical.
 So then partitioning.
 And, and this is what they look like and again this is high school Physicsso we're not going to do it in detail other than to point out it's really not ahuge amount of code.
 Andthat's what we're going to look at soon.
 This particular rule is for null,I'll talk about in a second.
The first one is that you have t o check all pairs of balls for overlap so that'squadratic, so it's going to be really, really lot of overall texture you're notgoing to be able to do it for a huge, huge value of N.
 So the mistake happens if we put all the items equal to thepartitioning item on one side which is a natural way to implement it and theconsequence is if you have all the keys equal, then partitioning doesn't really doanything.
 Or if we do the other way around, then wehave to increment the size of i's tree by the size of j's tree.
 That's the basic idea behind the sweep linealgorithm, to find intersections in sets of horizontal and vertical lines.
 With arrays, it doesn't quite work andagain all programming languages and, you know, many programming languages nowadayshave difficulties with this and Java's got a particular difficulty.
 The ideaof selection sort, is start out with a unsorted array and we'll use these playingcards as an example.
 So now our sort methods to referthe data will just use this two static methods.
 It's another variant of linear probing where wehash a key to two positions and insert the key in either one.
 Itjust makes the implementation a little bit easier and that's the way it's usuallydone.
 The efficient solution is to wait until the array getsone-quarter full before you have it.
 And that is an algorithm that scales.
 It's no different than a link list.
It'll compare this object against the object given as argument and depending onsome complicated tests, it'll return -1, meaning less, +1, meaning greater or0, meaning equal.
 We have a lot of one node heaps and thenwe're going to have to perform the sync operation on this one, that node five,that's, in this case just to change it with it's parent.
 Quick Find and Quick Union, and some applications and improvements ofthose algorithms.
 We didn't put in the this is thecheat version where we require the client to provide a capacity but we could easilychange this to a resizing array.
 So,for example this is a rather complicated formula but not too bad but in a sensethat if you know that the i-th key, it occurs xi times you can write down a lowerbound for the number of comparisons that are going to be required in the worstcase.
 You shouldn't use them for the things likechecking if the input is the way you like it.
 So, why we are interested in this algorithm? Well, it's a simple ideathat leads to substantial performance gains.
 Butas soon as we go out to 4 that's not a counterclockwise turn.
 When you create a string that value doesn't change.
 And linear probing isvery attractive in this case.
 So that's the first step.
 Get returns got null if key's not present.
 Doesn'treally matter what they are.
 And then left uswith, applications that, could not be solved without these efficient algorithms.
 After we find it, we mightas well just go back and make every node on that path just point to the root.
 So we search for the key, if it's got no right child we're fine, we just return x.
 And contains a simpler operation than get its convenient for manyclients where it just tells us whether there's some value paired with thatkey in the table is empty in size.
And, we'll, postulate that there's going to be a command that says, connect twoobjects.
 A good algorithm is much more effectivethan spending money or time wasting money or time usinga bad one.
 So, whether or not there was a new node added we don't haveto test for that this recursively takes care of the problem of maintaining thesize in every node when there's a new node inserted.
 And, now we are left with only oneelement in the heap in this in the first position, so there is nothing to do.
 Itmight take, log N, it might be as many as N.
 What do you want to count if they're all on the same line.
 But there's aproblem so you would think that the system sort would be completely solid with allthis resource with all these research and all of the development that's going intoit.
And we do that by using that count field in the particle.
So, say, we're inserting P into this left-leaning red black tree it goes to theright event so we get a temporary four node that's got two red links bothchildren are red in that thing so we want to flip the colors.
 Really, it's a modification of the sweep line algorithmthat we looked at for intersecting lines.
 So,let's look at those now.
 And the otherthing is that, so if we travel from p to point 1 then we make a left turn to goto point 5 or counterclockwise turn and then from there, we go to point 9 and12 and then we eventually get back to the start point.
 So,partially ordered arrays we may not need N log N compares.
 I.
 So again, very little codeto implement search and insert using hashin g and that's why it's so popular.
 So now instead of a rectanglewe have a query point and our goal is to find the closestpoint to that point.
 So if the thing is a linked list we're going tostart out at first.
 Now the firstalgorithm we studied goes back to 300 B.
 Starts looking for a place at a random time.
 And to insert and search, it takesconstant time per point in the range.
 So now when we increment i, well,in this case it's already in order, we don't have anything else to do.
 I didn't know he spend his time doing that But he was veryexcited because he saw this clip.
The j pointer decrements until it gets to the c which it stops there which is lessthan the partitioning element.
 We have to probably to make bullet proof code -throw exceptions if a client tries to call next() with no items there and triesto call remove() at all, we're not going to support remove().
 Now if we get our, our eight and nineconnected, we just checked that they have the same root and they both have the sameroot eight and so they're connected.
 If there's, if there's no node there then, then, then we, we return theroot itself.
 So let's take a look at it.
 Then that modelsthe hash function, then how far do they have to go to look for a place? That'scanoot's parking problem.
 He was quiteexcited because he was watching a re-run on, of an English actually Canadian TVshow on French TV.
 And we use the same idea as for 2d trees,but instead of just cycling through horizontal vertical, we cycle throughhowever many dimensions there are.
 And the way to think, it's called the iterated logfunction.
 So we'll look at hash functions,separate chaining and then two collision resolution methods called separatechaining and linear probing.
 Butthis time, we h ave some guarantee that no item is too far from the root and we'lltalk about that explicitly in a second.
 It expands like binary search to handle all these convenient clientoperations in a very natural manner.
 So the tree grows from the bottomin the little side to side motion it's just accommodating room for each new keyas it's added.
 [cough] So what about search well search for putthere's two cases.
 And that methodis going to add all the keys in the tree to the queue.
 Okay.
 And so,for example, finding the median and if it's already sorted, it's much easy tofind the median.
 And then in that case, we just rotate the top one right andthat brings us to this one.
 And then there are plentyof applications that we'll see later in this course like data compression orcomputer graphics like finding the convex hull, applications in science such ascomputational biology or, or in systems development.
 Now it's partitioning the right.
 The main reason that people study algorithms, is to be able tosolve problems that it could not otherwise be addressed.
Given a, a, given a red-black tree, we just make the red links horizontal, andmerge the nodes together to be three nodes.
 So first thing we do, as before, is buildthe index.
 So first thing we do is save awaythe pointer to the beginning of the list, that's oldfirst = first.
 We went up the path once to find the root.
 And the running time will be proportionalto the number of points returned, plus log N.
 And they're pretty uniformly distributed.
 So let's look at the gap.
 That way, for example, if you were to call Mergesort for an array that's already inorder it would just do this test every time and it wouldbe done in linear time.
 C is five, that's empty and we put it there.
 Everybody in the same connectedcomponent as six.
 Otherwise, x.
 So, in that case, it'll build a symboltable with IP addresses as keys and we can type in an IP address and get theassociated URL.
 So,equal items never move past each other in this code so therefore insertion sort isstable.
 It uses the same datastructure or array ID with size M but now it has a different interpretation.
 If the field is null, return 0.
 And that's, a queue is an iterable data structure, and the clientcan iterate that.
 We have onestudent who was paying attention to what we're saying and uses an array and canpick the indices into that array at random check whether they're open and, andrepeat.
 We don't have to worry about degeneracieswhere lots of things have the same x or y coordinate.
 So they had a hash functionpretty much like the one that we use.
 When we put a key value pairon to the symbol table, think of that as using the key to indexan array and storing the value there.
 And that's just a way to describethat we're going to be manipulating node objects that each consists ofa string and a reference to another node.
 And they might ask you theseon your job interview too.
 So partition usually happens pretty closeto the middle when you do that sample median-of-three and then small subfilescan just be left unsorted to be picked up with insertion sort right at the end.
 With geometric data,the worse case can be bad, so like all the points couldbe arranged in a circle.
 It was actually one of the first non trivial algorithms I implemented on acomputer.
 So we [inaudible] 24 atthe root, and, of course, the right subtree.
 So that's the end of the twosteps in Heapsort.
But really our goal is to have these operations be guaranteed to take timeproportional to log N, Because we don't have control over theorder of operations and they may not be random at all.
 If we're going to the left we find the floor, theone on the left.
 And a programmer might use the same program, to find places where certain,Programming terms are used in a bunch of programs.
 Another issue is, for many clients,if the keys are ordered, it's nice to be able to iteratethrough the symbol table and order.
 The depth of recursion.
 Without priority queues,it would be quite a bit more complicated to figure out how to do this.
>> Now we'll look at an application ofsorting from the field of computational geometry for an interesting computation.
 It's a convexpolygon that encloses the points whose vertices points in the set and those areall equivalent definitions.
 How we, let's see how we implement that.
 We're going to get the situation where twovalues hash to the same array index and we need a collision resolution strategy totry to figure out what to do in that case.
 When we come against the E,we gotta go right because it's bigger than E against the R, we have to go left,because it's less than R.
 Andthen on each of the Ns values of the variable i there's an exchange so that'sthe cost in terms of the number of exchanges.
In a 3-node, we need three links, one for less, one for between and one for greater.
 Two and one, fiveand zero.
 How do we test if two objects are equal? So Java has got requirements as forcomparative and here's the basic requirement about equals.
 So, here's another one that involves, remember, wepassed that red link up.
 Well, first of all,it's easy to see that we can solve selection and in law at end time.
 We put the entry at the table index A for three.
That is the word that we defined, for 2-nodes and 3-nodes, and we also have theperfect balance.
 It seems like it should beeasy to implement equals, basically we're just going to check thatall the significant fields are the same.
 We have to take track, keep track thelinks as we go up and down the tree to take, handle the splitting,And there's, and there's a lot of cases.
 In this example or CSV file relates URLs to IP addresses.
 And decrementing J.
 So I just answered this question, why do we usedifferent algorithms for the two types? And this is, is maybe arguable.
 Nobody to the left is greater.
 And actually, the ideagoes back to Einstein.
 Another example, Social Security numbers.
 So, the lower bound as a proposition, that uses the decision treelike that to prove that any compare base sorting algorithm has to use at least logbase two (N) factorial compares in the worst case.
 It, it doesn't, printnot found.
 And then there's, plus the number ofpoints return.
 We don't always have to go allthe way back to the beginning.
 So the system at the left, you can find a way to get fromthe top to the bottom through white squares, but the system to the right doesnot percolate, there's no way to get from the top to the bottom through whitesquares.
 And if k is to the right of j, we just do the right subfiles that load the j+ one and that's all this code does is that it, we could do a recursive, arecursive call but this just does it by resetting the values of the parameters.
 The idea is just generate a random real number for every array entry, and then sort using those random numbers as the keys.
 And these things are covered on the book site.
 If we want to insert C into this red black treewhich is a representation of this 2-3 tree, then C is going to be less than Egreater than A.
 Since N squared over 4versus N squared over 2, insertion sort's going to be abouttwice as fast as selection sort.
 To merge components containing twodifferent items.
 I just build a binary search tree.
And also, it allows us to develop a math model that we can go ahead and validatewith experimentation.
 And we do a pop operation, we remove the first node fromthe beginning of the linked list.
It's still worth while to look for a practical linear time worst casealgorithm.
That's the only time the height of a 2-3 tree changes, when the roots splits theheight introduces increases by one.
 Now that one becomes overfull.
 So there's threeproperties.
 So how many keysbetween, say e and s? Well one, two, three, four, five.
 Really what we proved is that mergesort is optimal withrespect to number of compares but we already know that it's not optimal withrespect to space usage.
 We saw that we can use binary search to get an efficient symboltable implementation.
 Does itintersect? No, it doesn't intersect.
It's cumbersome to maintain multiple node types.
 The max endpoint is that eighteen so that's what we store for the associated data with thenote to the left of the root and so forth.
 And you're also going to want to makecompareTo consistent with equals.
 Stop at l increment j decrement j as longas it's greater.
, dating at least to Euclid.
 This is with a hundred sites and 88 unionoperations.
 If you're not, you can look at thislittle example and decide what it is.
 So, that's that one for rank.
 Here's the code that you can find on the web for how to shuffle a deck of cards, that's pretty similar to our code but it's actually got more than a few bugs.
 If it's a reference type,use that hashCode and apply recursively.
 That's an extremely importantprinciple in designing good algorithms.
 So that means about half the elementsbelow the diagonal are going to be black on the average.
 So we already looked at some clients.
 And then, the data structuresdiffer on the basis of which item we choose to delete.
 Now, these are the things thathave to be proven and we're not going to get into the details of geometric proofbut they're intuitive and certainly have no trouble accepting that these things aretrue.
 Nearest neighbor couldn't be in there.
 Interesting to think just, justabout this case and to prove to yourself that it's always going to be perfectlybalanced when it's descending.
 [COUGH] And if it's changing the value associated with a key that's alreadythere, then it's just a matter of finding where the key is andchanging the value at that index.
 So to avoid that andreally allow most efficient use of memory, it's best to set thatremoved item entry to null.
 Those 12-14 intersect 16-22.
 So that's just an example of collision, ofcollision prediction, when's it going to hit the wall and resolution what do you dowhen it gets to the wall.
 We were using an extra subarray.
 With the forwards tongues of the twobefore and that were blended in after.
 And what we are going to do is focus only on the timeswhen the collisions are going to occur.
edu hasthis IP and ebay.
 A left-leaning red-black BST hasperfect black balance.
 The point is that the cards to the left of i are uniform randomly shuffled.
 It wasdifficult to create solutions, to be able to test hypotheses against naturalphenomenon.
 Intersection 21231518.
Welcome back to algorithms.
 We've lookedat lot of sorting algorithms and actually, there's hundreds of sorting algorithms outthere and we have chosen the most important and the most interesting for youbut you could literally spend a year reading all the papers on sorting and thenyou still continue to be invented new algorithms are developed and that arefound to have good characteristics all the time.
 Now this isn't legal in Javaif key is not an int and we're going to do this generically,it can be any type of data.
 If we are going to insert Z into thistree, it's greater than N, so we go to the right.
 So if the table has A, E, R, and S,and we have to insert the value C, then we have to move the E, R, andS over one position to put the C.
 But there's plenty of other things that we might want.
 In this care we're kind of hoping forrandomness and maybe that doesn't really always hold.
 In thisexample here, when we get A1, well that's so in this case, the index is just onethat appears in the array, it's just A's and B's.
 Whytwo different well it's just the designer's assessment of the idea that ifa programmer is using object maybe spaces, not a, a critically importantconsideration.
 In this case that brings the X up.
 And we looked at the binary searchalgorithm earlier in the course.
 And in particular, B treeswhich are a general, general version.
 And then these tests are for whether it hits the walls in which case, you haveto flip the x or y velocity.
 That's white in the diagram with probablyP or blocked, that's black of the diagram with probability one - P and we define asystem to, we say that a system is percolated if the top and the bottom areconnected by open sites.
 Which would mean that the find operation would be tooexpensive.
 So if we go left and then left, thatmeans all the points to the left of 1 and above 3, so the square in the upper leftis represented by that node in the tree.
 The implementation is easy.
 Now, and if they're all 3-nodes, it wouldbe log base three of N, which is less, It's about 0.
 Let's look at a demo.
 So,we want to know the number of keys less than K.
 Well, if it goes on the left, then we just make a red link and addit on then we're done.
 Swims up to the top, and if we have a node at index k and we know the heap condition is violated there.
 So that's adding this one line of code toMergesort will make it quite a bit faster.
 And that's a complete implementation of priority queues in Java.
 So the progress of a scientificinvestigation is going to be affected by how quickly you can do this calculationfor a large number of particles.
 And you better use a good shuffling code, that's our topic.
 Or if we did the other way around and proceeded accordingly.
 Six and five six goes belowfive.
 So we don't always godown just one branch.
 So we're going to look at a client program called TopM that takes thecommand-line argument, how many and this case, it's going to say five and thenit's going to take from standard input the transactions and it will print out the topfive.
 So that's anotherreason to think about maybe paying a little extra and using to guarantee thatyou get with red black search trees.
 So, thislink is for all the keys in the B tree that are between this key and the next oneand in every case, it's that way.
 And arbitrarily we choose to change the ones that are thesame as P to the ones that are same as Q.
 And we have a 2d rangeis a rectangle oriented to align with the horizontalvertical axis.
 So, our first one is, the way that random works, it actually never gets to 52, which means that the last card can end up in the last place, so it's definitely not shuffled because of that.
 So whenwe're looking, we're trying to find the root of, of P.
 Let'ssay, there a and b.
 You could use an extra array and thepartitioning code would be a little bit easier.
Here's an increment sequence that I found after maybe a year's work and it workswell but nobody knows if that's the best one.
 We can have more confidence that our priority queue operations are going to work correctly, if we know that the type of data that's on the property queue is immutable.
 Our algorithms willgain efficiency by maintaining connected components and using that knowledge toefficiently answer the query that's, that they're presented with.
 And just note that what'sthe cost of implementing this, well if there's been,if there are N things on the symbol table, you have to for both search andinsert, look all the way through.
 And so people that were usingquadratic algorithms were definitely held back and, it was, Ed, Ed McCreight atXerox Park who, discovered interval search trees and the logarithmic algorithm thatallowed us to sustain Moore's law and keep building bigger and bigger computers.
 Which one is better? In many situations, we're going tohave multiple implementations of APIs, and depending on propertiesof the client program, we're going to have to choose whichone is the better one to use.
 Now,replace STFI with a new node that links to the old STFI.
 But in thiscase we have to put in this one cast and so what we've heard about that is the uglycast it doesn't, it doesn't make you feel good about the code.
Next we'll take a look at comparatorswhich is a Java mechanism that helps us sort.
 So that's[cough] if K is equal to the key at the root, the floor of K is K.
 And then two and three.
Next, we're going to look at an easy application of sorting to a related problem called shuffling.
 Of course,if the last sub-tree's empty, there's no intersection there.
 And then linear probing says, just look at the next position, look at five.
 And that's an interestingresult in itself.
 Because we can't have an array of generics.
 The stack containsthe recursion.
 So there's build apriority queue.
 So we've achieved putting it inorder with less work in this case.
 Okay, so again start out in our normal starting position, whereeverybody's in their own tree.
 So there is the stack there that contains all that informationand whether the function calls itself or not is not relevant.
 Isthere a method that use one-half N log N compares? The lower bound says, no.
 The first term on the right hand side isexactly the same as the left hand side so we can apply thesame formula.
The first line shows the partitioning where k is put into position.
 So, alldifferent types of objects for, but for programming we're going to associate eachobject with a name and we'll just name the objects with a number, integers from zeroto N-1.
 So that's a little survey of some operations on a heap and you can see how every operation is done with just a few exchanges along the path from the bottom to the top, or the top to the bottom.
 So we take the file name as thefirst command line argument, read in array of string from that file separated byblanks, call an Insertion.
 So, the BST contains the y coordinates of all the horizontal linesthat currently might involve an intersection.
 So,that's why we picked the color red to distinguish red links the types of linksin three nodes.
 So we have to greatly expandour, our table.
 Pulling off the largest elementfrom the heap.
 So each of the operations is a one-liner.
Now, we're going to take a look at orderedsymbol table operations using the binary search tree data structure as theunderlying implementation.
Where there's N horizontal vertical line segments.
 That's thecase that we just did.
 Now, we could use a interval bag or some data structure likethat and hide the link list structure underneath and that's a perfectly fine wayto proceed in modern programming.
 And what's worse, if you try to fix it by say, randomly choosing between the left and the right.
 A8, we found A in there andupdate the value 8.
right,and save that in x.
 And now, that you havesome understanding of the classic methods you can have a better idea of whyarrays.
 And also wemaintain perfect black balance because we didn't change the black height, height ofanything by doing this transformation.
 And then with that, simple, relationship wecan use the exactly the code that we developed to go ahead and run a simulationfor this connectivity problem.
 They have the same, entries in the idea array.
 And third onethe other four objects.
 And so, afterthat process, then we know that the entire array is in its final order, all sorted.
 Insert X, It's bigger than R,Goes to the right.
 So now we check if point 6 inthe rectangle, in this case, it's not.
 So that's read this loop,reads in all the data and associates each word withits frequency of occurrence.
 And that's also true of B-trees and both of these methods arevery effective and widely use.
 It's a little mind bending atfirst because of the recursive structure but it won't take you long to convinceyourself that this little bit of extra code completes the implementation ofleft-leaning red-black trees.
 In this case, compares.
 You have a setof rectangles, and we want to know which of these rectangles intersect? Or how manyrectangles intersections are there? These are interesting problems that have lotsand lots of applications, from computerated design, to games and moviesand also in abstractions such as data bases and other situations where you mighthave multiple keys or multiple dimensions.
 Andall the method does is maintain this in variants so let's do an example or two andsee how that works.
 And they're easy to achieve.
 Wehave full code it's the regular BST code with the couple of lines adding the callsand the basic operations.
>> It could be from a binary search tree.
 Then we don't create newarrays all that often.
 So let's just take a look at what we have to do in thetree, the path we have to take in the tree to figure that out.
 Today we're going to look at hashing.
 So if we're looking for E.
 The tree staysvery balanced.
 This is an easy and very efficient algorithm to solve thisinterval search problem and as we'll see this algorithm.
 And in order to get that done, we just need a simplerepresentation for three notes.
 And later on, we'll look at digital propertiesof keys where we can use digital character compares instead of whole key compares andgot a faster sort for certain practical applications.
 One has ID one, six has ID zero.
 Otherwise we return, x.
 Again, modification of binary searchtrees.
 And so now, just we, we know we have a symbol table implementationthat has efficient iterator.
The first elementary sorting method thatwe're going to take a look at is an easy method known as selection sort.
And we'll say that each site is open.
 And you can go ahead and extend thisalgorithm to add functions like logs and sines or other operators and haveprecedence among operators, have them associate and multiple operations, and soforth.
 We should convinceourselves really that it always works and so we'll spend just a moment on a shortproof.
 On the other hand, if you try to improve things by making dt too large youmight completely miss a collision as shown in the example at right.
 And then we flipped colors onthat.
 Increment i, generate a random integer, swap them.
 If the client could change the values, how do we know that the heap order operation is preserved? If we want the client to be able to change the values, we're going to provide methods for that purpose as I just mentioned.
 Here's the code thatimplements Dijkstra's two-stack algorithm.
If you want a full service symbol table which is going to, going to grow fromsmall to huge and then back down to small again then you'd want to use arrayre-sizing to make sure that M is always within a constant factor of N but we willleave that detail out for now.
 We don't want our searches to take that long.
 So let's look at a few properties of binary heaps.
 And with just changing one value in the arraywe get the two large components emerged together.
If the 3-nodes at the right and this one is one higher and those four are one lowerand afterwards it's the same.
 So sometimes we look at both subtrees,but as we get closer and closer, we only look at 1.
 And if I don't need that guarantee, if Ijust care about the total amount of time, I'll probably use the resizing-arraybecause the total will be much less, because individual operations are fast.
 Now, theconnections, well, we need, a few abstract properties that these connections have tosatisfy.
 And people understand properties ofthe universe by doing these kinds of calculations and comparingagainst what's observed in space.
 So now let's look at the running timeestimates about why we care about Quicksort vs Mergesort.
 And so it's pretty clear that if it's.
 >> And then, when the moment is right, they behave in a way thatshould be impossible.
 Right away we have the maximum element in the arrayright at the root, we want that to be at the end so that's what we're going to doand that's what we're going to do is just put it at the end.
 So that's a simple example of a filter usingsets.
 You could do the items between i and minus one, the ones you haven't seen yet, and that would also work.
 We might convert the letters to numbers, or we might, keysmight be numbers.
 And also no object is equal to null, so those are absolute requirements for Java.
 And now H has no right child, just a left child and it's larger than that one so now we're finished with that operation.
 It's a very efficient algorithm.
 If you put at the beginning of the codewhat you expect in the, in the form of an assertion, whichis code itself.
 It just does the compare and increment apointer.
 And then if the K is not less than either one of those, then we're done.
 So it's theoretically possible, but themethods are generally too complex to be useful inpractice and their not used.
 Say well, we'll leave the key in the tree to guide searches, but we won't count it as being in the symbol table.
It only involves changing a constant number of links.
 And what about descending order.
 Now we get theL.
Now, look at an interesting application ofpriority queues that is actually representative of whole family of acritically important applications in applications of computing.
 So again, as always, we'll first writea client and then look at implementations.
 Andthen we'll swap that with the first entry in the array and then we know we've gotone step done.
 And h.
 And then, if the link coming into a node is red we set that to true.
 Which how many balls do you throw beforeyou find two hitting the same bin, when do you get the first collision? And the answer to that is it'sabout square root of pi M over two.
Mergesort doesn't do that.
 So again,typical characteristics we have a huge file but small number of different keyvalues.
 This is simpler than symbol tables because it's got noassociated value.
 Well, Mergesort is easy to understand as a recursive program.
Why is it redundant? Well, the partitioning element is sittingthere and it'll stop when it hits the partitioning element.
 And then wow, what are we getting the sortefficient, done efficiently? Well, we could use Shellsort but actually in thenext couple of lectures and we'll look at classical sorts - Mergesort and Quicksort -that we could use.
 So it just calls our sort() method with a, an array some type ofobject as first argument.
 Again just a few lines of code to eliminate the violation when a key value in a heap decreases.
 4, exchange it with everybodyto its left that's greater, until we find a smaller element,then it's in ascending order.
 Again, the black elementsare the ones that we compare, and actually, they're also the exchanges.
And then this insertion into the parent changed it from a two, a 3-node into a4-node essentially adding a length cuz of the split with the two 2-nodes where therewas only one 3-node before.
 Mergesort uses twice as extra space proportional to thesize of the array it has to sort.
 So, what we have to do isidentify the index or that minimum entry and exchange it.
 Sort the points by polarangle with p so that is if we take a, a vertical line and sweep it in acounterclockwise direction, what order that we hit the points? The first thing wehit is 0, 1, and then we sweep counterclockwise, we get the 2 and then3 and 4 and so forth.
 And at the end, we have the deck shuffled.
 So, we used the same datastructure except, now we need an extra array, that for each item, gives thenumber of objects in the tree routed at that item.
 You'll often see programmers thinking that they're implementing a shuffle and for every entry, they just choose a random place in the array to exchange it with, and that doesn't really work.
left is also red that's this case here where we have twoleft-leaning red links.
 So exchange increment I as long as it'sless.
 And that one we're going to use to implement delete the maximum in a heap.
 So what's aniterator? So, we're going to use an inner class.
 It also intersects the splitting line,so we have to search both the sub-trees.
 And there was a lawsuit and some legal testimony andI am happy to report that, that it was clear that Hibbard deletion was theproblem once the expert analyzed it and the expert witness, who's a colleague ofmine, said if implemented properly, the height of a red-black BST with N keys isat most two log N.
 And that gets us aninsertion into a tree that has from a tree that i s a single three node to a treethat is three two nodes that is containing three keys.
 Either it's yes or it's not yes,let's, let's say, they're distinct.
 So to push,we just add a new item at s of N into pop, we remove the item that's ats of N- 1 in decrement N.
 All right, so what about the analysisof how long is this is going to take? Well, again, a typical case, rectanglesare small that we're only going to examine really the path of the tree maybea couple of other nodes along with path.
 If v less than w, w is less than x, then v must be less thanor equal to x.
 How sixteen is bigger than five so we go right.
 And then the other thing that we dowhen we sort items that are in an array is to, to swap or exchange of the item at agiven index i with the one at a given index j.
 When we find P, we return its index and we use that index to getus the value that we need.
 So here we just as, as it goes up we'reshowing each key getting inserted in the number of probes of the table that areneeded for the insertions are J hash to the same position that A; you had to lookfor a while, and the one thing to notice is as the table gets full, is that firstof all.
 If you'reusing a quadratic algorithm and it takes you n days to check your design rules, andpeople were running these things on the order of days, then for the next computer,it would take 2n days, it would take twice as long.
 Once it computes the hash code,it stores it as an instance variable.
 IfP's connected to Q, and Q's connected to R, then P's connected to R.
 So we're going to take a look todayat how to implement these things.
 My friend Philippe Flajolet who recently diedwas a famous French mathematician send me an e-mail late one night.
Then we're going to change, all entries, whose ID is equal to the first ID to thesecond one.
 So there's a tree so S is at the root everybody to the left of is less thanS over to the right is bigger.
 But we're interested in the biggest ones andso maybe it's the biggest amount of dollars, or the biggest cost, or whateverit might happen to be.
If you have a set of N points in a plane.
 You can merge thingsthat are not equal in size.
 And notice since it's just going from bottom to top in the heap, it takes at most 1 plus log base 2 of N compares.
There's a list of keys at every internal node and that key, tells you that, thenlinks for every key that give you, a place where your key would have to be.
And that's a legal 2-3 tree, so we stop.
 So, the larger of the two nodesin the tree node will always be the root of a little binary search tree of size twofor the three node and the link between the two nodes, the left link that linksthe larger key to the smaller one we'll color red.
 They're not connected.
 They [cough] used what's called a method for choosingpartitioning element called Tukey's ninther.
 But there could be out there some easy wayto doing in place merge.
 But just look at the properties of looking at theproperties over a left leaning red-black BST.
 Either at the book site or in thetext book.
 So, this the is an easy programming exercise given the rightdisplay primitives.
 We're going to stick to thisassociative array abstraction and no duplicate keys in the symbol table, because it both simplifies implementationsand leads to simpler client code.
 And then the client might say, well, what are those keys and you want tobe able to return them.
 How good is that? [MUSIC] >> So, this is a simple model developedby Craig Reynolds a while ago for simulating the situation called the boid.
 So the pop operation forlinked lists is very easy to implement.
 And as you watch it go for a while, you can see that this thing about going to the right and taking the successor all the time, the trees becoming much less balanced that it was.
 And how do we resize to a new capacity? We create a new array of that capacity andjust go ahead and copy our current stack into the firsthalf of that and then return it.
That's a bad case.
 But the fact is that in manypractical applications, the matrices are what's called sparse.
 So, as I mentioned, the symmetric order ispart of the definition of a 2-3 tree.
 But still, it's easy to implement, so that'll be our startingpoint.
 And this is a fine example anduseful example, of amortized analysis to getefficiency in a stack implementation.
 It's not relevant to the client.
 From the internet to biology to,commercial computing, computer graphics, security, multimedia, social networks, andscientific applications, algorithms are all around us.
 And that'll give a total cost of about 3N.
 Andwe'll consider classic methods for searching.
Rotate left, rotate right and flip colors.
 And we know how to delete the minimum.
 Sothe sort does huge files with huge numbers of duplicate keys.
 And, what's interesting about three way partitioning is that the number ofcompares that it uses is equal to this lower bound within a constant factor.
Today, what we're going to talk about is called the priority queue and for that, weinsert items, but when it's time to remove, we consider the items to have atotal order and we want to remove the largest or the smallest item.
 Now, first thing to mention is that oftenthe kinds of data types and data structures that we implement or found in aJava library.
 So, each entry in the array is going to contain areference to its parent in the tree.
 And that had to be added.
 If you think what we've been studying so far is trivial, go ahead andfind a better increment sequence.
 And then merge the result.
 And it'llwork well if the file is small or partially ordered.
 So let's look at how thatlooks in the animation.
 That's a very convenient initial starting point for our programs because wecan use integers as an index into an array then, and then quickly access informationrelevant to each object.
 The terminology that we use ispushed to in certain items and pop to remove the itemmost recently added.
 Any possibleintersection would have to be in the right, And then the other point is that ifyou go left, then either there's an intersection there, or there's nointersections at all.
 Sothere is another thing about the uniform hashing assumption is that it is anassumption and if you are writing code where we have to have guaranteedperformance like when your aircraft is landing or you are controlling a nuclearreactor or somebody's pa cemaker.
 So that's a straightforward and simple scheme for implementing symboltables with hashing.
 So this is 4 interleave sequences, that'sa 4-sorted array.
 And for strings, it kind of createsthe string as a huge number and then,really computes the value of that number.
 So 16 bushes at the end there.
 Now when we search, we're going to have to do thesame thing.
 So, for a particular insertion, we can take advantage of this reduce one caseto another by, in, in the way that we're moving in the tree, not to get everythinghappen with just a, a few extra lines of code in our standard binary search tree.
 So, we go through.
 The second part of the course isfor more advanced algorithms including graph algorithms, classic graph searchingalgorithms, minimum spanning tree and shortest path algorithms, algorithms forprocessing strings including regular expressions and data compression.
 Now, we're ready to look at theimplementation for, of the code for inserting into a left-leaning red-blacktree.
 So, we type in somebody's loginname we get their first name.
If our symbol table is really going to be dynamic, we need to be able to delete key value pairs from the table.
 So that's John Bentley who discoveredthis while an undergraduate at Stanford.
 So now welook at seven L not there, we look at eight L is there, that's a search hit.
 String is immutable.
 Thecomponents containing three and five.
 This is just do mod M andif M is a prime then from that modular arithmetic we know that we're using allthe bits in the number in that point to.
 Whateveralgorithm we have is going to, first, do a comparison between two of the items.
36.
 And typically, indesign rule checking, you wouldn't expect too many intersections.
 The, the dynamic connectivity problem.
 And if that distance is lessthan the best found so far, then we'll keep that as the champion.
 This isthe example of the client program that sorts the files in a given directory byfile name.
 Wemight consider keeping the things in an unordered array.
 If it's a primitive type,use the wrapper hashCode.
 And then we just keep going.
 Infact, there's an argument for just using this implementation of Quicksort andforgetting about horse because it performs so well in so many practical situations.
 So, for example, you could sort them.
So we start at the root, Compare the search key against the key orkeys in the node.
This sum, minus the same sum for N - one, just leaves the 2CN - one.
 Otherwise wehave a constructor and actually for some applications, it's convenient to have aconstructor that takes an array of keys as argument.
 And for many, many clients,that's an effective tradeoff to make.
 And those simulations are only enable by fast union findalgorithms, that's our motivating example for why we might need fast union findalgorithms, so let's look at that.
 In a few applications, this might be fine, but in many many applications,that's too onerous of requirement.
left equals null return x.
 And so that'sdefinitely going to be costly eh, if you're doing this operation a, a lot.
 I wouldlike to, to store the, the thousand biggest ones.
 Even though they came in, in ascending order, the treewinds up being perfectly balanced.
 And that's a left link, and so forth.
 And we keep going till we find an emptyplace, and then we put H there.
 The zero keys are going to be zero on the dot product sowhat we're going to do is take the item key of the vector and multiply it bywhatever value we get for the non-zero entries.
 So now we'll look at adata structure called an interval search tree that helps to solve this problem.
 Should we go left no the max in point on left is ten so we shouldn't go left.
 But the bottom line is that now we havetwo methods that under the uniform hashing assumption can give us constant time,search, search it insert and delete.
 And in the real world, it's best to think of that as a number less thanfive because lg two^ 65536 is five.
 Okay? So now, what about six and five? So again, we change thefirst one to match the second one.
 So, firstwe'll talk about the dynamic connectivity problem, the model of the problem forunion find.
And that's what we have for our binary search implementation.
 So now let's look at the code forimplementing a stack.
 It's better not to assume that, it's better to arrange for that or implementations by using keys that are immutable, whose values don't change.
 That's an easy one.
 As long as what we have is less than thepartitioning element.
 So analysis of 2d trees isa bit beyond our scope.
So, our code has to check for these three cases.
 Now, the key point is that sorting algorithms rhythms are essentialin a very broad variety of applications and, and all of us use sorting algorithmspretty much every day.
 So let's, let's see what we have to do.
 Alright [cough].
 All of that leads up to, in a programmingworld to specifying, a data type which is simply specification of the methods thatwe are want to going to implement in order to solve this problem.
 So here's our summary of applications ofbinary search trees for geometric problems.
 They're not in the same connectedcomponent.
 And there, we find first the ID corresponding with the firstargument, and then the ID corresponding to the second argument.
 Maybe 20% faster.
 Essentially, we're finding a node that has only one link leading that node, and then replacing the node that we need to delete with that one.
 Let's say, the new key is smaller than both ofthe keys in our three node.
 A set of algorithms for solvingthe so-called dynamic connectivity problem.
 We've removed the maximum and we still have our data structure heap order and our N keys stored in the first N positions in the array.
 Unfortunately, Java does not allowgeneric array creation.
 So what about memory usage? Well, this is the analysisof memory usage for stacks, and it's actuallyless memory than for strings.
 And we'll see later on, there's times when we want to expand the API and provide other operations like removing an arbitrary item from the priority queue, or give the client in the API the capability of changing the priority of an item.
 Bychanging this quadratic algorithm to a linear logarithmic algorithm, and let'ssee how it works.
 And allow us to take a problem that wastaking us quadratic time with methods like insertion and selection sort, and getit done in, in log N time with Mergesort.
 Andthat's a key feature of binary search trees that we'll come back to again whenwe look at more sophisticated data structures.
 We don't want to just be able to sort things,we don't want to just be able to sort them by defining and compared to.
 And the problem is and this was quite a surprise when it was first discovered, actually many years after Hibbard proposed the algorithm is this lack of symmetry tends to lead to difficulties and here we're just inserting the leading alternating, in certain delete a random key, so that maybe well models a situation or practical situation.
 And then after changing the id link, we alsochange the size array.
 Sonow three, four, and eight are in the same component.
 And just leaving empty positions around, in a hash table, orusing links in a link list, did not seem like an appropriate use of space.
 So, left endpointinsert the y coordinate into a BST, right endpoint remove that ycoordinate from theBST.
 Then when it comes to this hyphen, it'll pop the most recently inserteditem which is 'to' in this case.
 So one scenario shown here is, if for whatever reason a child's key becomes larger than its parents key.
 And then we do the same thing for the nextfour in the array.
 And our basic search tree mentality and APIs, and binary searchtree data structure give us efficient solutions to these important practicalproblems.
 So now the best way having looked at those small examples, thebest way to understand this code is recursively.
So, find all the keys that are between two given keys, or give how many keys arethere between two given keys.
 So if we have astack we can say - (for String s : stack).
Next we're going to look at the use of thebinary heap data structure to implement a clever sorting algorithm known asHeapsort.
 And that algorithm works like this.
 It's greater than R, so we go tothe right.
 And that makes it kind of like Merge Sort.
 That's the, our basicimplementation is providing rank.
 Let's say, we ha ve three different items, a, b and c.
 Entries in gray are not touched, they're in their final position.
 And what we're going to do is implement a sorting method thath-sort for decreasing sequences of values of h.
 Now but one problem is if the keys come in and, and reallyunfortunately, if they come in, in a natural order.
 And then thelast thing we do is flip the colors and now that's the result of that insertion.
 The idea is that we're gonna be talking aboutgeometric objects, not simple keys like strings and numbers.
 Then from standard input we take queries, just reada string, check if the symbol table contains the string.
Now, we compare H with E and J, and in this case it's between, so now we aregoing to take the middle link, that's the only place that H possibly could be.
 And what we want todo is split that four node and in this case, since we are at the root that's allso that just flips the colors.
 That's an upper bound and how difficult it is tosolve the problem.
 They have some exposure toobject oriented programming and recursion.
 And then, it's up to the client when it pops something off theapple stacks to cast at the apple to keep the type checking system happy.
 In fact,a pr ogrammer might ask, why study anything else? Well, there's plenty ofgood reasons to study other things, but I'll submit there's no good reason not tostudy algorithims.
 And the heap condition is only violated again where H is sitting.
 There's is one little detail when you are sorting an array of course positionzero comes into account and we've been building our heaps from position one.
 I referred to delete the minimum just to avoid confusion, we have theimplementation separate implementation usually MinPQ, where we delete theminimum.
 So the idea of Mergesort is, is based onthe idea of merging.
 So, the point with thelowest y coordinates on the convex hull and shows the one that is the smallestpolar angle that creates with the x-axis.
 And so we'regoing to mai ntain the connected components.
 So, as that example shows,2D trees are extremely effective in quickly processing hugeamounts of geometric data.
 And that's right parenthesis.
 Again, another common function that'seasily handled by symbol tables.
 Each node has aleft tree and a right tree.
 Exchanging it with the.
 That allows us to, build balance trees that, are very, veryshallow.
 For example, in the firstlecture, we're going to talk about the network connectivity problem, where theproblem is, given a large set of items that are connected together pairwise isthere a way to get from one to another with a path through the connections.
 And then push is the four lines of codethat I gave on the previous line and pop is the three lines of code thatI gave on the slide before that.
And you can see that we're going to need efficient algorithms for this.
 It's not really satisfactory because of that, and we'll come back to this, but it works.
 And the semantics is different, forenqueue we add an item say at the end of the queue, and for dequeue weremove an item from the beginning.
 So for example, in this set of ten objects, weperformed already, a bunch of union commands, connecting four and three, threeand eight, six and five, nine and four, two and one.
 So now, when we compile this program we get a, a warning message fromJava.
 So, that's adding a new node with a red linkat the bottom inserting that into whatever the two or three node it's attached to.
 So what's put going to return?Well, that left link is null, so what's going to happen is, in that call x isnull.
 We're taking advantage of the factthat the keys are comparable to give us an efficient search.
 And that works,again, recursively say we have one node in the tree, and we have a new key toassociate.
 So, the typicalapplication that I just used as an example is say the set of student records.
 So here's the implementation in Javaof Shellsort for Knuth's 3x + 1 increment sequence.
 We're goingto do the same thing, exchange it with the last element in the heap.
 So, another undergraduate in an algorithmsclass discovered this idea for N-body simulation and that's Andrew Appel.
 He was reallyinterested in analyzing correctness of programs and showing that this how youcould convince yourself that this program was operating as expected.
 Here's ananimation.
 Now the node at the root violates the heap orders, so we have to exchange it with the largest of its two children, in this case that's R.
So we can apply the same equation so its two over n + one.
 But it's a good way to think about it and then to retrieve it you just give thatsame key and it'll return the value.
 And then the onlyto move [cough] operation does is to update the position of the ball by thevelocity, which is just another number and then it does the bouncing off the walls.
 The idea behind symbol tables is toimplement the following abstraction.
 Well, you still have to insert.
 Put a key value pair into the table so that is associate the value with key andthen get the value paired with the key.
 Is are those precisely the same objects ornot? Now usually in applications where wewant to have something more general than that, we have a concept of a value orlike a key in our case.
 If there was perfect balance beforethere's perfect balance afterwards, because we didn't change the height of anynodes.
Now you have to be a little bit careful with terminating the loop.
 Andhow many calls were there before nine:10:25? So you can see that there's,all of these operations are quite natural when we have the, table in sorted order.
 Alternate between horizontal andvertical partitioning of the plane.
 Probably finding duplicates by itself is not quite obvious what to do butthe easy way to solve it is to just go ahead and sort.
 Even if it's trillionsof, of pieces of data in this huge, huge file.
If we split the root, then, that's the, what happens at the root, and if there wasperfect balance before, there's perfect balance after, with the height one bigger.
 Again, it's similar to the other one, we're creating a symbol table thatassociates strings with integers.
 So, we get to use the faster and bigger computer to build faster and biggercircuits but that doesn't help if you're using a quadratic algorithm.
 First, we are going to need toreturn the first item on the list, so we save that away.
 So if you have a quadratic time algorithmfor implementing symbol tables or linear time for each operation,you're not going to be able to run this client in a reasonableamount of time for a big amount of data.
 So, one idea is the so-called time drivensimulation.
So the random shuffle is a key for good performance in Quicksort.
And then that gives us an easy sum that we can approximate by an integral.
 In this case, we'll call itListIterator that implements Iterator and it's generic.
 It's a little more than half empty usually now, as this shows.
 But it might also bein the right so we move to the right in this case.
 Numbers of only 3-house for a hit, and only 5-housefor a miss.
 It still takes quadratic time in the worse case but Heapsort does both.
 So now, we have a fully dynamic symbol table where we can insert and delete the number of nodes that we have in the tree is always proportional to the number of key value pairs in the symbol table.
 When we get to the pointers cross we breakout of the loop and exchange the partitioning element into position.
 And again, y is bigger, so exchange it,decrement gt.
 So, here's a much bigger example.
That's a kind of a magic step, but we will see that it makes possible to solve theequation easily.
 As you can see, only one, two,three, four, five exchanges are needed to bring this into heap order.
>> I thought the red door was the storage container.
 Well, that one doesn't exactly workbecause of a phenomenon called thrashing.
 The otherthing we h ave to do is iteration.
 And another pointabout this is it< /i> seems that this is</i> so close to being linear that is t imeproportional to N instead of time proportional to N times the slowly growingfunction in N.
 Okay and now we have one connected component with all theitems together.
 And wekeep going until we get to a point where the system percolates.
 In this case the answer is that there is such a path.
Let's look how it works in the demo.
 Into two so a nodeis always between half full and full.
Always, in this class, we have an exercise or exam question is this version of thissort stable or not? So, students learn to recognize whether the code is stable.
So that's a quick implementation of the Quicksort partitioning method.
 But again it's a simple one andwidely used.
 It's proportional to N over 2.
 Between f and t, there's only f our.
 >> It was the red door again.
 So starting at any node, you justfollow ID equals ID of I until they're equal and then you're at a root and that'sa private method that we can use to implement the find operation or theconnected operation.
 And number two, that every time youresize, you've already paid for it in an amortized sense by inserting,pushing or popping.
 So that's theexception filter, and that's useful in lots of applications such as the oneslisted here.
y - a.
 Make sure they're the sametype can do the casting, and then compare all the similar andsignificant fields.
 Supply that operator to those values and put theresulting value that you get back on to the operation stack.
 And, again these formulas are nice approximate formulas, but Knuth, oncehe figured this out, in 1963, tells stories, that time, he decided to writehis famous series of books on algorithms.
 It was in one, each one cango to two.
 So,but we can take care of that in the less and exchange methods by just decrementingthe indices in those methods to have it work as if the array were zero through n.
 That essentially splits the four node.
 On this lecture we're going to look inMergesort, which is the basic sort in plenty of differentprogramming systems including Java.
 Although it's aninteresting programming exercise that a lot of us would get wrong the first time.
 One, two, and seven allhave entry one.
 And if you have an array,you have to apply it to each entry.
 Doe it contain point 4? No.
 If there's only one thing, we're not doing any compares at all.
 So this is a indexing clientwhere we associate each string with its most recentposition in the input.
 Maybe the keys are small andthe items are large or maybe the keys are really huge.
 We think of storing the value inthe array position given by that index.
 So thatrepresentation is, shows that they're connected.
 There's alot of attributes, the different applications have.
 So let's accept that as what computers are like.
 There's another facility that Javaprovides that leads to very elegant compact client code that's definitelyworthwhile to add to our basic data types and that's iteration, that's what we'regoing to talk about now.
 Again it has to be a total order and thisis very familiar for example with strings.
 And that's a pretty close approximation,in this case.
 And that takes us to 5,and 5's our new champion.
 Now, the analysis of Shellsort is still open.
It's a bunch of transformations but they're all simple using our flip colorsor left or right rotation.
 The client programs usually havecustomized implementations that are based on comparing some sort of value.
 In this case, sign are the same, there is no swap.
 So like if we wanted to find the minimum item that's k =zero or the maximum item that's k = n - one or the medium that's k = n/2.
 You have, these clusters or these chains building.
 In this case, it's the C, which is the smallestone in this new page.
 The first will be a file name, a so-called common separated value fileand the next two arguments are integers which will tell us what to treat as keysand values in the file.
Here's another simple client program forsymbol tables related to indexing.
 Given two objects, provide a connection between them.
 And then, so, so that's going totake N log N for every one of the lines to process them all either N to build thepriorit y queue and then log N to take the smallest off each time, or N log N for thesort.
 But with the basic interval search tree algorithmand the sweep line process that we've talked about, you can get the orthogonal,orthogonal rectangle intersection search problem solved in time proportional toanalog N log N + R log N, where R is the number of intersections.
 In fact, to make this mapping from an object name to theinteger zero through N - one is to find application of a symbol table or asearching algorithm, which is one of the things that we'll be studying later inthis course algorithms and data structures for solving that problem.
 And when we've done that, we've thrown outlg N 1s.
 The other thing that's possible to do andit's a little mind bending so recommended only for experts.
 There might, if that gets passed up to a three node, thenwe have to continue moving up the tree and just treat it in the same way as we justtreated inserting at the bottom.
And that was one of the main uses of hashing, was just to be able to dosearching with string keys.
 We have data that we are processing we can't process it all at once.
 And we have to use ugly cast, 'cause we can't have a race ofgenerics.
 And then after it gets to that worse case it also winds up beingcompletely balanced when we have a power of two.
So, the idea is first randomly shuffle the array.
 And that's just checker if anything happenedwith those two particles.
 And also one point to make forthis class is that this algorithm was discovered by an undergraduatein an algorithm school.
 And that's where we get the result that, by runningenough simulations for a big-enough n, that this, percolation threshold is about.
 But now, when we have eight to merge with fourand three, we put the eight as the child, no matter which order their argumentscame, because it's the smaller tree.
 This is a, one of the easiest ways toimplement the merge.
 And its example of, of Moore's law.
 Operator, put on theoperating stack.
 Last lecture, we looked at Mergesort,another classic sorting algorithm, that's used in many systems, and today we arelooking at Quicksort which is used in many others.
 Now, our goal is to be ableto sort any type of data so let's look at a couple of client programs.
 To insert we put the key value pair.
 So now wehave to do a sync operation on, on the E.
 >> Oh yeah, got you.
" another, A complementary approachis to think of these words as words that we don't want to ever see.
 With the natural order, we had to put the definitioncompared to within the data type.
 Now there's four volumes out and moreplanned, and this is where, all computer scientists go.
 Well, one thing we could dois maintain a linked list.
 Here's a war story fromstudents Programming assignments not that long ago.
 A lot of times, we're sorting everythingwe have.
 So that's the symbol table API.
 We could also keep thesethings in a bag and do a client that gives allthe positions that appear.
Here's another client that we could use our sort program for, if we achieved thegoal of sorting any type of data.
 And what we want to do is create an index,so that we can efficiently find all the files that contain a givenquery.
 It makes n squared over 2 compares andn squared over 2 exchanges.
 So our, eh,our node stored intervals, but we only use our left end point as the key.
 So when we decrement that value N, there's still a pointer to the thing thatwe took off the stack in that array.
And continue that way throwing out two over decreasing numbers all the way downuntil we get down to two elements, c1 which is zero.
 That's fine, but it requires a sort, sort seems like a lot of work for this problem.
 We just want tocreate a new node with our new key and return a link to that node, that's all wewant to do.
 And because the interval search trees take logN for every operation, the insert and delete intervals is N log N totaled andthe searches is N log N + R log N.
 Insertion Sort.
 To implement a comparator you can use thiscode as a model.
 To delete the minimum in a binary search tree again, we just go to the left until we get a null left link.
 Quadratic time to insertN items into a stack, that kind of performanceis unacceptable for large problems, as we've seen,as we will see many times.
 We have to change all the entries, whose ID is equal to one ofthem to the other one.
 So we are going to use a min-oriented priority queue sothat's going to keep, it'll [cough] it'll be one where we can delete the minimumand, and it'll be generic so we'll have a transaction type that holds thisinformation including natural ordering where it's ordered by dollars that lastcolumn.
 So, just as we do forsymbol tables where we take keys, now we're going to take points.
 But in the1990s we figured out that really this was going to be an effective way to sort.
We wanna be able to Insert an interval search for an interval, delete an intervalbut the main thing is we want the interval intersection query.
 If you want to review the material that we think isprerequisite for the material in this course, you can do a quick review bylooking at sections 1.
 And the keys less than E and so forth.
So can implement it to cut off to insertion sort for small arrays.
 If you have a sort method that can store anyvalues in an array, it could, for example, store zeros in every array entry thatmethod would pass this test, but it didn't really correctly sort the array becauseoverwrote all the values.
 So,we don't have to have to look there.
 So now we have, just five elements left.
 Sothe Comparable API then, by convention in Java we always need to implement compareTo()such that v that compared to w is a total order.
 And thenexchange of course rather doing comparable has to use object.
 As computers get faster and bigger, quadraticalgorithms actually get slower.
 So we add that in.
 So, say, we havejust two nodes in the tree, so it's we have two nodes and that means it's asingle three node.
 In fact,is simpler in many ways than these standard implementation of Quicksort.
 Thisis an external five node.
 It's alittle better feeling for what's going on.
 And that's the above.
 Maybe the third line there is the final grade.
 Flip thecolors, now we h ave a temporary four node that's out of balance so we need a doublerotation.
right after the rotation.
 So now, we have one over to the right thatwe know is greater than the partitioning element.
 Right parenthesis, you pop the operator and twovalues and push the result.
 It's the next thing that has to go in theoutput.
 So to connect six and five, we change the six toa five.
 Now, what we need is if wehave a table of size M, an array of size M that weare going to use to store the keys, we need an int value between zero andM minus one.
Next we'll look at some elementarysymbol table implementations.
 So N place is important.
 So let's go left, in this case.
 So that's asearch hit.
 It is possible to concoct cases, where you're going to haveto examine all the points.
 We're having a efficient sortas absolutely crucial.
 If P's connected to Q, then Q's connected to P, and it's transitive.
 So it depends on how the keyscome in.
 Well, sorry, you have to take the absolutevalue because otherwise it'd be negative and you can't have it negative.
 So that's an example of a binary tree.
 So, Adobe.
 And so the array is N by N, it's N^2 things and it takes about N^2 time,which is actually a linear time for this application.
 So, now we're going to extend the APIto talk about two-dimensional keys.
 But in practice this is something thatstill we have to worry about somewhat.
 When you're enqueue you go at the end, and when the one that's been in therethe longest is the one that comes off.
 So, that's a fine implementation of QuickFind so the nextthing to decide is how effective or efficient that algorithm is going to beand we'll talk in some detail about how to do that but for this it's sufficient tojust think about the number of times the code has to access the array.
 P is bigger than L, sowe look to the right.
 The other thing is that the lower bound isfor the particular model of computation being studied.
 A famous quote and there's many similar quotes, 'The generation of random numbers is too important to be left to chance'.
 2 has to go all the wayback to the beginning.
 I, I think maybe they might have added to this warning statement "We apologize for making you do this".
 We could keep it in order orkeep it unordered.
 And that link is null, so that's a searchmiss.
 So if the whole table is empty,return null.
 And also access is not bad.
 Sonow we have one that's definitely less than the partitioning element and lt is,is pointing at the partitioning element.
 One might want to use the URL as key, given the URL,give us the corresponding IP address.
So if you go right, there's no intersection in the left.
 Howwould we do that? Well, we just sort the array and then if we want to find thesmallest, we'll look at the first position or the largest, we'll look in the lastposition or the medium, we'll look in the middle.
Now there are some things that you have to watch out for with Quicksort because theimplementation is a bit fragile and it's easy to make mistakes.
 And then, M9 and P10, L11 are all notthere and they go at the beginning.
 So, even if there's a lot of zeros we, we still have to take the space to storethem all.
 For now, what we need to do is put a cast in to make this work.
 So forexample in this example with our ten objects the idea array that describes thesituation after seven connections is illustrated in the middle of the slide.
 The implementation is amazingly simple.
 First thing is that Mergesort is toocomplicated to use for tiny arrays.
 We scan through and the smallest one is the two, three entriesfrom the right so we swap that.
 We build a data structure containingpoints that can efficiently support range searching and range counting.
And the way we do it is, first make a temporary 4-node that replaces that3-node.
 If it's equal, if it is, go ahead and return the associated value and if youget to an empty position, then return null.
 Like theintegers or natural numbers or real numbers or alphabetical order for strings,chronological order for dates or times and so forth.
 Then, an insert() that putssomething in like push in a stack or enqueue in a queue.
 With the clever data structure and interesting implementationwe can actually achieve that goal.
 It would take quite,quite some time for a human to figure out whether there's a connection.
 But the delete operation for Binary Search Trees shows us the kind of complexity that we can encounter with working with these kinds of data structures.
 Now, a card could be involved in more than one swap, but that's not an issue.
 People have beentrying to do that for 50 years without a whole lot of success.
 So the first thing is what we're going to do isuse the left end point of each interval as the binary search tree key.
 And so nowwe'll just consider those points in order and then take them for the convex hull.
 And if there is, then we couldroll back time just a little bit and I'll try to figure out exactly, the moment ofwhich they collided and then figure out how the position and velocity shouldchange accordingly and then continue the simulation.
 And if, in theclassic algorithm or computer science problems for people to think about is whatdo we do to delete in these two situations and exactly how do we resize.
 And then putting the y coordinates into, into a binary search tree is, again,N log N.
 So, the first thing iswe're going to for every particle we're going to compute the next time that itmight hit every horizontal and vertical wall.
 In fact,almost any computer application system is going to have a symbol table ormultiple symbol tables at its core all the way down to the basicmemory system of the computer or the networking system that your computeraccess to information depends on.
 You just peels off one key to do file size n then you get a sub file size n- one and then n - two and so forth and the result is a quadratic tim e algorithm.
 So now, five and zero five is in the bigger tree so zero goes below.
It gives us the guarantee that the worst case is not gonna happen.
 A complete binary tree is one that's perfectly balanced, except possibly for the bottom level.
 They're used for movies andvideo games, for particle collision simulation, they're used to study thegenome, and all manner of other applications.
 So the standardrepresentation that we use for vector is to simply use a one dimensional array.
Insertion sort best case linear, quadratic, and place unstable.
 If our splitting line hits our rectangle,we have to go down both branches.
 And just to add the point to the list forcorresponding square.
 We have a binary search tree algorithm which is fine, in that it gives us log n performance for search and insert in a situation where we can think that these things are happening randomly.
Now, inserting E into that well, it's going to B if it's in the tree left of S,that's a null lin.
 And now, what we are going to do is take a look at just a couple of different scenarios that we violate that invariant temporarily, and then fix it.
 We, have a legal three tree,2-3 tree.
 21, 23.
 The Graham Scanuses a sort where we give two different ways to sort the points.
 So with that note please don't think there's something wrong with yourcode if you follow our prescriptive and, and get this warning message.
 And so it's a simple idea butexpert scientists were struggling with dealing with hugeamounts of geometric data.
 So, that's the largest key in the data structure that is less than G.
 But the point is, the tree shape depends onthe order of insertion.
 Six and one they're inequal size trees.
 Andwe'll see example in a second.
 This points out examples of howdifficult computational geometry can sometimes be because degenerate caseslike these are difficult to deal with in code.
 And dates, when is a date so we addthat hash code, multiplied by 31 and add that hash code in.
 Nobody to the left is larger, nobody to the right is bigger.
 And we also have a problem with the worst case.
 Again G is not larger than its two children so we have to exchange it with the larger of the two, that's O, and now we're done, we've removed the largest again.
 Out of all the orderings the one that's further stand in the tree that'sthe worst case and so the algorithm, no matter what the input is, the tree tellsus a bound, the number of compares taken by the algorithm.
 And we use the emptyslots in the array.
 So, with one client we can handle lookups of all kinds in CSV files.
So what is the Quicksort method? It's also a recursive method, but thebasic idea behind Quicksort is that it does the recursion after it does the work,whereas Mergesort did it before it did the work.
 And there's aprocess called auto-boxing which automatically cast between primitive typesand wrappers so all of that handles of the, the problem of dealing with primitivetypes, kind of behind the scenes.
 And if we didn't have that we would now, if we're usingiterators, we could go ahead and write this longhand code but nobody would everdo that cuz it's equivalent to the shorthand or we might have to write clientcode that does a lot of unnecessary pushes and pops just to do this iteration.
 So, we make our implementation with typeObject so everything in Java is a sub type of Object and then the client, when theclient comes to use it, will simply cast the result to the corresponding type.
 And then inthe middle are all the equal keys and that's what we'd like to arrange.
 Otherwise, we call rank and that gives us a number of keysless than the current key.
 So in this case, we have a table of size five.
 But usually, we're just going to worry aboutthe keys and we'll keep the values, in the nodes along with them [cough] so that'sbinary search trees.
 So we exchange itwill lt and increment both i and lt and now where the point, where the pointershave crossed i and gt across there's nothing that we haven't examined yet.
 And then that's not a 2-3 tree cuz it'sgot that one 4-node with three keys and four links.
 So then that's the client thatwe're going to use for analysis.
 And we use parallel arrays forthe value in the keys.
It's the root of the tree, containing two, four and three.
 We're touching all the nodeson the path from that node to the root.
In the way that, that happens is a mechanism known as a callback.
 The more complicated operationimplement is a union.
 That associates string keys with sets offiles.
 Or in other cases, if you onlyhave a few entries out of place, the array's going to be partially sorted.
 And anyway for Java 1.
 This implementation by itself is extremely significant because it's really very simple.
Sort the first half.
 And we're going to build a datastructure based on these points.
 A faster computer wouldn't help much.
 And it's, and a couple of waysto implement it, one thing is you could sort according to the x coordinates, oryou could just put them all on a priority queue.
 And then, we want to insert theE into its parent.
 And so what they decided in the first implementationwas let's just look at every eighth or ninth character, and that way, we don'thave to spend a lot of time computing the hash function.
 We don't get any benefit from having it in a treeshape.
This seems like an artificial kind of input but actually we'll look at anapplication even in this lecture.
 If you want to find the pairof points that are the farthest apart in the set of points in the plane, this issometimes important in statistical calculation or other applications.
When we give you working code it's not hard to see why it works.
 We go backwards through the heap.
 You need to keep that rank tree as a field, or keep a field which has thesize of the tree and it's easy to complete the rank from that.
 And for search, we're going to haveto go to, if we're going to look at is C in this table say, we're going to find thehash value for C and we'll look down the list to see if we can find C.
 So, a sort, it'sworthwhile to take a careful look at what the implication of that is.
So, for every value of k, if you add those up the probability that the partitioningelement is k, plus the cost for the two subfiles, we get this equation.
 Inthis case, the answer is E.
 As we'll see, all symbol table implementations lead to complications when we try to do this operation.
 In totality, is that either v is less than or equal to w or w is lessthan equal to v or both they are equal.
 Or using either one of those techniquesyou could just get the idea that D of N is close to Log N or you can write a programto expand the recurrence and find that.
 There's a hugenumber of applications of Union-find.
 Well, let'slook at the other two cases and these understanding needs is crucial tounderstanding the whole algorithm.
 Well what that means is that actually, just likeworking in binary you got, you can combine those things.
 And if we this the, the thing called event which involves it saysbetween two particles, something is going to happen at a certain time and we'regoing to adopt the conventions that, if, neither particle is null then we'retalking about two particles.
 So that's a fine implementation ifthe priority queue was going to be tiny all the time.
 And the list of applications is huge.
 And then that might involve somework with the, it's like insertion sort, you find a place to put the new item andthen put it in the right place.
Now, let's look at a dictionary client,another very useful and common application of symbol tables.
 The dt speed, speed variable that's given as argumentdt.
 But anyway, that's a basic operation that we sometimes need.
 We have atwo-dimensional matrix one-dimensional column vector for the multiplicand and theresult.
That's corresponds precisely to our temporary four node when we're doing 2-3trees.
 It says that we're using unchecked or unsafe operations and we shouldrecompile with a minus -Xlint equals unchecked for details.
 And then, [COUGH] to computethe total force traversing the tree of all the information that you need,to complete the N-body calculation.
 The other thing is as I just mentioned, you can use the array indices to move through the tree.
 Nowwe look at e, hash of e is ten, we look at ten, it's empty so we put e there.
 Andthe idea is to cut down on that cost by taking advantage of idea that there's alot of zeros.
 In this diagram, the entries in black, are theones that are examined in order to find the minimum each time with the minimum inred.
 Well, there used to be box andpeople would open up those box to look for a word to find the definition.
 So, we have to do a left rotation, legal-red black BST.
 And then this isanother famous physics experiment showing diffusion.
 [cough] so, in this case, we have the right link of E points to S and Sis red so that's a right-leaning red link and so now that's the before and what wewant to do is reorient things so that it leans to the left.
 That's the over-view of Mergesort.
And those observations give us the lower bound.
 First, an integer which is the number of objects that are going to beprocessed.
 This is a, a.
So you can imagine the implementations of priority queues using these two basicstrategies.
So now, if we insert R into this one then it goes on a red link to the left of X, Sand that's fine, it's a red-black BST.
 Now in my view,a good code has zero cast.
 Now, the keys and the values caninterchange roles that's why we have the abstruction to separate them.
 And these components have the property that if anytwo objects in them are connected and there is no object outside that isconnected to those objects, that's connected components.
If the in-, the file is, the array is randomly ordered, then the two sub-arraysafter partitioning will also be randomly ordered.
 And they're soconvenient for clients.
 And its next the oldfirstitem on the list, which is now the second item on the list.
 In here two properties.
 Let's look at an animation of Quicksort inoperation.
 It goes to the right of H,leading the wrong way rotate left.
 In this wecompare twelve fourteen to five eight, so now we apply the same rules.
 Now, you might say, well, what we want to do is, connect,check whether any site in the bottom row is connected to any site in the top row,and use union find for that.
 Now the invariant's brokenbecause the element on the pointer is not in sorted order.
 We just takeaway the one at the end.
 And then when you get to anexternal node you just look for and so that's a, that's the all searchesterminated in external node, in other words that's just a generalization of whatwe just did.
 If we start in the second place at E and lookat every fourth element, it's sorted.
 Andalso nobody racks up a, a set of billiard balls such that all fifteen are touchingin all places.
 And then when a node gets filled it splits.
 So, we have thissummary which is looking pretty good, because we have the average case for bothoperations, the search and insert, to be 1.
 So what'san Iterable? Well, in Java lingo what an Iterable is, it's, it's a class that has amethod that returns an iterator.
 So this is a simpler, narrowerAPI but still it expresses an important little collection of operations and, andwe'll use this one and we've already seen the implementations.
 But you could see that even for this case which is hundreds of keys,the length of the path from top to bottom is not so much.
 We'll do some extra work totry to get this extra property that every table position shouldseem to be equally likely.
 So what are the things left to bedone? Let's just check.
 One thing thatis very common is the idea of an exception filter.
 In this one, we're going to sort file, file's namein a given directory.
 Now eachentry in the array has associated with it a root.
 In, in that case, thenthe expected length of the longest chain will be lg, lg N which is quite animprovement.
 So, we do have a quadraticinitialization phase that we perform just once to get the priority queue filled up.
 This is a different ordering than we have to heap ifwe have a node larger than both its children, this one, every node is betweenthe values, the value of every node is between the values of the nodes in its twosubtrees.
 And actually, the threshold between when itpercolates and when it doesn't percolate is very sharp.
 So, again, this analysis is just forthe stack itself, not for the strings, which the client owns.
 And these things are not difficult but they're all worth articulating asseparate issues that we have to deal with in order to get an effectivesingle table implementation.
 So we use the merge procedure we justshowed, and then our sort procedure.
And, if, if it's a billion nodes, that's between eighteen and 30.
 That's a searchmiss, and we return all.
 So both of those are 10 over 2, 11 over 2 integer divide is 5.
 So, one is that the new one islarger than both of the keys.
 The only solution we have comes from acomputational model, where we run simulations to try and determine the valueof that probability.
 It's either redraw, bounce, B of A or, or bounce off avertical wall or, or a horizontal wall.
 Andjust looking at this trace of selection sort and operation really is a proof,visual proof of this proposition.
 As usual, we start at the root.
 And the question is,can we do better than that? Is logarithmic performancethe best we can do? And the answer is that, actually, we can.
 So the percolation model onthe left corresponds to the, connection model on the right, according to whatwe've been doing.
 Now, it's going to be much fasterbecause of better balance in the tree, but in terms of the code, we don't have tochange the code at all.
 Andthere's many kinds of applications from people processing data.
 In this case, 2325 doesnot intersect, 1719.
 Be is gone, to is gone sothe next is not, and so forth.
 So, six and five doesn't matter, whichever onegoes down doesn't matter.
 Butthat's it.
 Itmight not hold if the algorithm has more information about the keys, for example,if it's known that the input is almost ordered, we saw that insertion sort can belinear time for files that are almost ordered.
 So it's a little more work to makeQuicksort stable, maybe using extra space.
 Well, it's easy to fix this one.
 And we've got a reasonable hash function.
 And that'ssomething that's not allowed.
 And we came up with thatbefore when we're talking about using a sort for the Graham scan.
 So now, every time the line sweep hits arectangle, that corresponds to an interval.
 And also whatever color h was, well, it looks like it should be black.
 Now, we flip colors and thatgives us a, a good red-black tree, except that, that one red link that we just isleaning the wrong way.
 So, we'll have a table that's smaller than thenumber of keys that we have, the hash function will map each key to someinteger.
 And to prove that, we just need to showthat each transformation maintains symmetric order and perfect balance, andthese are all the possible transformations that we could do.
 And each particle is a disc that's got known position, velocity, mass,and radius.
 In order to do that, we're going tomaintain three indices.
 So we have to makethem objects then when we get things off, we're going to have cast.
 There's a geometric object calledthe Convex Hull which is the smallest polygon that encloses all the points.
 Now if we're inserting into a 3-node atthe bottom, we have to do more work.
 This is a simple indexing clientthat we use for our traces.
 And a supercomputer can do it in aninstant.
 That's the first goal of algorithm design is to try and findoptimal algorithms for the problems that we need to solve.
 So, that's our summary for algorithms for solving thedynamic connectivity problem.
 And so then at that point,it's half full, and it can either grow by adding stuff orshrink by subtracting stuff.
 In fact, you can always use an explicit stack to make a recursiveprogram non-recursive.
 We identify the, the length of the array that's n.
We can iterate through the elements in, in constant time, and with a hash table, wecan get at them in near constant time and then constant time in the average.
 And well, we'vegotta have at least, two, keys at the root.
 That's the heap of size three.
 So we need a data-structurethat more gracefully adapts to the distribution of the data.
 So we take that element and replace the root with it.
util.
 So, more and more and more now a days people are developing computationalmodels, where they attempt to simulate what might be happening in nature in orderto try to better understand it.
And we have three arguments lo, mid, and hi.
 There's no larger entry to the left of jand no smaller entry to the right of j.
 Now, what we get back from a hash code is a int value that is between minus2 to the 31st and 231st- 1.
 One, having to deal with compiling from aprogramming language or interpreting into an actual computation and then the otherone is the PostScript language which is widely used for, for printing andpublishing.
 Another problem is in this implementation, the random uses just a 32-bit seed, if you do that, there's not enough possible shuffles.
 Sothat's in, you know what the position is.
Welcome back, today we're going to talkabout balance search trees, Which will lead us to an ultimate symboltable implementation that can provide fast performance for all the simulative optionswe've looked at, guaranteed.
 So, the key is the string in the key fieldentry of the array, and the value is the string in the value field entry in thearray, and we simpl y put that into symbol table.
 Then to properly maintain a symboltable in a dynamic situation, in many clients you want tosupport a delete operation.
 Insert x into that one that goes to the right of S, it'sleaning the wrong way, rotate left.
 We just have a for loop starting at hash ofkey and going until we get to a position that's null.
 Maybe, you runa credit card company and you want to check for stolen cards then your keyswould be numbers.
 The problem is, what happens when there's two children? So say, we want to delete node E in this tree.
 There would be lots of ways to get from the topto the bottom.
 So one remark before we do theanalysis is that actually binary search trees correspond exactly to Quicksortpartitioning.
 The idea is when a decouple, thedefinition of the data type from the definition of what it means to compare toitems of that type.
 You can build a heap from N values in linear time.
 Now, what we seek ideallyis what's called an optimal algorithm where we prove that the upper bound andthe lower bound are the same.
 Then we'll create a new node forthe end of the list.
 Whenit fills up, it's red, and that splits into two half pages and then keys getadded on one side or the other so each.
 It's not somethingthat you will come up with on your own and that's, and that's an undesirable feature,I think for codes so simple as this.
 And union, six and oneso there is three entries that have to get changed.
 And the trick is that onceyou get past the capacity, you have to reset back to zero.
 So that brings us to this summary where red-blacktrees, we were happy with a log based two of N for search and insert with separatechaining, you can really get it down to a constant number of operations for searchand insert.
 The diagram at the right gives another simple way to look at itpictorially.
 And so, the extra space used by merge sort maybe is not a problem.
 And this point by itself is verysignificant.
 The first case for Hibbard deletion is what we want to do to delete a node with key case.
So, if we call this client with second argument zero and third argument one, thatmeans we want to use the URL field zero on the CSV file as the key, no one use the IPaddress that's field one in the CSV as the value, you want to associate keys withvalues.
 A second improvement is to, try toestimate the partitioning element to be near the middle.
 So we weren't able to show thatthere was no intersection, on the left.
 So, you have to just be aware that these situations have to bedealt with.
And its running time will be proportional to n log n, and it'll be a fast sort.
 So here's our simple client for traces, so if we associate S with zero,we just had it.
 You have a better chanceusing the last three digits.
 And so, for example, if theseare the keys in our symbol table and we're doing a search for the index whereP is stored, we look at the middle.
 So now, what about operationslike rank and select? How many keys are there less than a given key? And, give usthe seventh largest key to facilitate implementing those operations and alsosize all we do is keep an extra field in each node, which is the number of thenodes in the subtree rooted at that node.
 If it's not there, then we return null,saying the key's not there.
 We just go down a path in the tree.
 If j = k, we're done, we've found the k is the largest.
 If we had no limitation on space at all,then we can have a very huge array with space for every possible key andjust use the key itself as an index.
 We talked about dynamic connectivity innetworks there's many other examples in our computational infrastructure.
text, then what the client will do is pushto be or not to all on the stack.
 So we're going to need something better to provide the guaranteethan just randomly ordering the keys.
1.
 So,each line has a URL and IP address and are separated by commas.
 So for example, in tail of two cities.
040.
 And for dequeue you remove an item fora head.
 And that's a good optimization forlots of situations, why go through all that rest of that codeif you know right away they are equal.
 So then this is D of N over N equals D ofN over 2 over N over 2 plus 1.
Now, we'll look at red black BSTs which isa simple data structure that allows us to implement 2-3 tree with very little extracode beyond the basic binary search tree code.
 Now, let's saywe add a union five, zero.
 That's apretty straightforward implementation.
 So that's J now is after this statement, is the larger of the two children.
 And so now in, increment both lt and i sothat's the first case there.
 So, forexample, if we have these components, and we get the command to union connect, twoand five.
 And you'll sometimes see Mergesortperforming poorly because of that bug.
 It takes this linear time toinitialize the data structure.
 Similar, if our third point comeson the left, again, we'll partition according to the horizontal linethrough that point on the left.
 Points are defined data type for geometric objects and so what weneed is code that will compute the polar angle and use that as the basis forcomparison.
 Then, to get rid of the first node,we just advance our pointer to the first item on the listto point to the next item.
Now, what's the cost? Well, we went down a path in the tree so it's one plus thedepth of the node in the tree.
 Two items that are in different components.
 And this first argument is just ignorewords fewer than this many letters.
To get started, we'll look at the API and some elementary implementations.
 So to hash again we do the same thing, we just map the keyto a index.
 But Mergesort you can only sort reallyhalf of what you can fit in memory, because you need thatauxiliary array for the other half.
 So, nine is going to be the one that goes down below.
 If you seea value, you put it, you maintain two stacks and if you see a value, you put iton the value stack and if you see an operator, you put on the operator stack.
 Then, we test whether that event has been invalidated.
 So if it's an integer the hashcodes suppose to be 32-bits, integer supposed to be 32-bits.
 So from that trace, it's pretty easy to seewhat's involved for the code.
 So say the subarrays are only of two, orthree, or four there's too much overhead with the recursive calls andso forth to get that done efficiently.
 Now we have three pages andwe keep going eventually one of them fills up and splits.
 But nowadays that's restricted to justa few implementations like stack and queue anda few other fundamental data structures.
 If b less than c goes theother way, then it takes another comparison to determine the order.
 But first we're going to lookat the implementation of order and operations with the binary search treestructure.
 It's a very efficient andsimple data structure for processing k dimensional datathat's very widely used and the whole idea is that data clusters,particularly in high dimensions.
 Becausethe main, the most work in convex hull is the sort.
 And then h's coloris going to be black afterwards.
 As long as it's not null, westay in the loop and increment I mod m.
 So what we want to do is get the array into threeparts so then now we have two pointers into the middle.
 And again, in practice, the running time of this algorithmis going to be close to logarithmic.
 Ittakes quadratic time in a worse case even though we make that unlikely by randomshuffling.
 So this is a bad case that we wouldn'tlike to see in a practical application.
 So now, we are sitting at E.
 This is a simulation that shows a, agrowing B-tree so when a page, at the top, there's just one page that fills up.
 But there's a different interface called theComparator Interface which is a way to help a sort, using some alternate order ormany different orders on the same data.
Today we're going to look at Quicksort.
 Rightnow we will look at two examples.
 Swap that one withi, increment i.
 So the bottom line isseparate chaining versus linear probin collision resolution message methods.
 And in 1991, there were some scientists that,that Bell Labs that were using qsort for a scientific problem and they were used totaking just a few minutes and then they realized that it was taking hours of CPUtime.
 When you makean assumption you better be sure and you're depending on that assumption, youbetter be sure that it holds somehow.
 So, for this example, we've got a client that, Will read information fromstandard input.
 And for overflow, what happenswhen the client does too much? We're going to talk aboutan approach called resizing that will allow us to avoid overflow forclients.
How long can those paths be? Well, it's not hard to see that the, inthe worst case, if they're all 2-nodes, that's the longest they can be is log basetwo of N.
 Now what we can do is get rid of that sumby subtracting the same equation for N minus one.
 And context just means a few words beforeand a few words after.
 So to delete the node that has no children, just return null and then go back up to update the counts as usual, that's the easy case.
 That selection sort, our first elementary sorting method.
 So this is a [COUGH] a, a java construct for.
 [cough] There's a lot ofequivalent definitions of this.
 And then just look at the M atthe end but by sending up the problem, I already kind of ruled that one out becausewe don't have the space to sort them all, to store them all.
 Now, that meansis that, with that huge memory, we can address huge problems.
 So here's the, this is very concise recursive codebut its tricky because of that last point so its worth reading carefully.
 So, that's a rotate leftoperation.
 So our operations maintain symmetric orderand perfect balance in a 2-3 tree.
 And in manyother applications in Computer Science and in scientific computing.
 I just use, the leftend point, as the search key.
 So implementing this is a simple example of linked list processing, a slightmodification of our stack and queue code.
 What kindof efficiency might we expect in a selection algorithm.
 This is just anothertrace without the data-structure shown, to just show in our standard way, theelements in black and red are the ones that are touched and the elements in greyare the ones that are not touched at all.
 And this kind of algorithm, a data structure would be useful forthat kind of situation too.
 Trying to take all the bits andscramble all the bits and use them.
 Essentially, we need to merge the connected components containing theone containing two or the one containing five to get a big connected components andnow we have only two connected components.
 If it's not in theexceptional list, then we print it out.
 We have instructions on the web on how to do that.
 We have an algorithm that can solve it it's the least thateasy.
 Here's a trace of Dijkstra 3-way partitioning forhis problem which is when there's just three different values in the file.
 [cough] now we're going to use these to implement symbol tables andthere's values associated with each key when appropriate, we'll write the valuesin smaller numbers next to the keys.
 And to implement black list wejust this call to contains, we just change that to a, a not.
 There's no reason not to.
 So again we, we start out the same way butnow the idea array entry really means that every one of these things is a little treewhere the one node each everyone pointing to itself.
 And that's a very longstanding open problem to find a natural simple efficient delete for binary search trees.
 But youreally know that your data structure and algorithm is used by a lot of people whenit appears in the popular culture.
 Oneconsisting of just object zero, second one objects one, four and five.
 Starting at Nover two because the, N over, half of the, right most half of the array is justlittle heaps of size one.
 And how many stages do we have here? Well, it's the number of times you divideN by 2 to get down to 2.
 And for primitive types takethe wrapper type and use the hash code.
 But we did decrement gt so we made progress.
 Now in practice Heapsort isactually not used that much for a couple of reasons.
 That's the same data using different sort keys.
 So now our second point in the tree, the left sub-tree corresponds toeverybody below that horizontal line and the right sub-tree correspondsto everybody above it.
 Everything tothe left of lt is known to be less and between lt and i is known to be equal.
 If it's greater we exchange i and gt anddecrement that.
 That's equivalent to saying, are they inthe same connective component? So that's some work, going to find the roots of eachitem but the union operation is very easy.
 One that is the boundarybetween the keys that are less than the partitioning element and those that areequal of the partitioning element.
 That's a complete implementationof selection sort.
 Here's the code forthat frequency counter client.
 Where, it's since there are so manypossible values for a typical data type.
 What would what we we'll look at is</i> very simple and practical implementationusing a data structure called the binary heap that gets the job done in timeproportional to N log M and only M space.
 The average distance to the root is much, muchlower.
39 N log N.
And to perform an insertion all we need to do is replace that 2-node with a 3-nodecontaining K.
 Itdoesn't have a local reference, like Quicksort does.
 If we have plus or times, push it.
 Then we'll find some algorithm tosolve the problem.
 Now the eight is the smallest and we swap.
 So now what about this one - 2? Is that onthe convex hull? Well, as far as we know at this point, it could be, it could bethat the thing is a triangle and 0 is the last point in which case it would be.
 This is oneof those mathematical facts that seems obvious but then if you try to prove thatmaybe it's a little more subtle than you think.
 The first thing is we need to beable to compute the hash function.
 We'r e going to have to look at all those positions to look at H.
And then the sum collapses just leaving the last term.
 Now a specific example that really shows this off and also will illustratethe utility of being able to process multiple types of data with the same codeis this example is Dijkstra's two-stack algorithm for arithmetic expressionevaluation.
 10,000 by 10,000 if, if there was,if it was full, that would be a billi on or 100 million entries.
 That one's generally too complicated to use in practice.
 So the idea of a binary heap is based on the idea of a complete binary tree.
 Certainly, plenty of clients might want, want that.
 And now one more time and now it'spointing to one that's greater so we exchange that with gt and decrement gt andi is pointing to the one that was there and that ones smaller.
 That's an abstract in-place merge fortaking the two sorted sub-halves of an array using an auxiliary array, movethem out, and then put them back in in sorted order.
 Now there's a fundamentaldefect in using an array and that is that you have to declarethe size of the array ahead of time and then so the stack has a certain capacity.
 And to compute that wholenumber you multiply 31 times what you have so far andadd the next digit.
 Thing to be researchers in the 1950's who cared so much about memoryand nowadays a little extra memory is not something that people care about so muchand most people just go with the easy algorithm except for really performancecritical applications.
 That's an effective way to get things shuffled.
 We know the two three node heapsthat are the children are heap ordered but we may have to correct the heap orderingat the root so we do a sync on two.
 So, it's hasNext() and next() and so to make the data structureiterable, we're going to implement those things.
 Now there's a, a number of practicalimprovements that we can use to make Mergesort even more efficientthan the simple one that we've looked at and we'll take a lookof those because they're examples of techniquesthat we can use for other algorithms.
 So let's think of an n by n grid of squares that we call sites.
 That is a complete implementation forlinked-list that would work with as a fine push down stackimplementation for any client.
 Even on a super computer, if you're usinginsertion sort nowadays it'd maybe take a week ormore.
 And clearly, it's worthwhile to thinkabout for your application whether you want or need a stable sort.
 So our best practice that we recommend is so few thatthese basic data structures that we use and there's so simple is to go ahead anduse the implementations that we've just discussed for these fundamental datastructures.
 But if you have a good algorithm like Mergesort, and you're trying to do abillion items, you can do it in just less than half anhour on your PC.
So it's a [cough] there's a direct correspondence.
 We save away the item, we delete the firstnode by advancing the reference and then we return the item, so identical.
 So on average, it's like addinga cost of one to each operation.
 The designers found that the cost of computing the hashfunction for strings seemed to be excessive, particularly for long strings.
Or your computer will be struck by a lightning bolt.
 And what we'lllook at now is the lower bound.
 So move the H up, and actually put the root value there, just exchange them but it's no longer in the heap.
 Don Knuth who wrote several books on, on algorithmsand was a pioneer in the field said that, "An algorithm must be seen to bebelieved.
 Let's look at another using 2dtrees to solve another problem, the so-called nearest neighbor search.
 So, for binary search, [COUGH] what we're going to do is usean ordered array and actually use parallel arrays, one forthe keys and one for the values.
 If the root node lies inthe rectangle then we're done, [COUGH]we can return that point.
So, here's the operation summary for ordered symbol table.
 So maybe a node got deleted down there, but always the invariant is, that the count of the node is one plus size the left and right, and then return x and fix the links from the counts on the way up.
 So if you, without evenimplementing it, you can understand this table that if we use an unordered arrayimplementation we can get insertion done in constant time but we haveto look at everything to delete the maximum or even find the maximum.
 [BLANK AUDIO].
 So to look for a, to do a search for the keyH in this tree, we start at the root and we compare our key against the key at theroot.
 Just a new symbol table that associates integer indices with doublevalues.
 It'll add that file name to thecorresponding set for that word.
 That's the basic API and some elementaryimplementations for priority queues.
 But, forany interval, in the right subtree, its got to appear after.
 If the current space istaken, you try the next space and the one after and so forth.
 And we'll only worry about the possibilityof finding something closer than that.
 So, this is a standard matrix vectormultiplication that you learn in Math where we have a square matrix and a columnvector and we want to do a dot product of, of first row with the column vector to getthe first entry in the result.
 And one of Mergesort's characteristics isthat in practical applications, it uses extraspace proportional to N.
 So, any 2-3 treecorresponds to a left leaning red-black BST in this way.
 So this is just an example showingall the words in a Tale of Two Cities using the modular hashing function forstrings like the one that Java uses.
 Thisis a very general tool.
 That's easy to code up, but not worth it, because it'smuch too expensive to do that.
 So it's recursive argument switchery toget the job done.
 And we just do that by changing its link to be red.
 Take first.
 [COUGH] And sothat's what we'll continue to do.
 There's another issue about whether clients can insert nullitems into the data structure.
 The, inner class that we used to implement nodes has,one, two, three, four instance variables.
 So, now the main loop iswhile the priority queue is not empty we're going to pull off an event.
 And we get the same kind of partitioningfor three dimensional data, so we could do Boyd's in three dimensions.
 And a lot of clients only want todo is just iterate through the stuff in the collection.
 They donot intersect, so now, what are we gonna do next? Well we're gonna compare the leftsub-tree, and it's Not, 22 falls within our interval so it's not less than'r' sothere might be an intersection there so we better go to the left, so we do go to theleft.
 To talk about this in a quantitative way,we define what's called an inversion.
 So, notice, we're in this case we do this rotationfirst, we're on this node and then , that returns and we come up to deal with thesituation on this node after the return, and then we do that rotation.
 To make sure that if the queueis empty after we move an item we gotta set last to null.
 Today, we'regoing to talk about the union find problem.
 So it's in 1000, it splits in two.
 And basically, these ruleshad to do with doing this ortho, orthogonal rectangle intersection search.
 So this allows us to create modular, reusable libraries of algorithms anddata structures that we can use to build more complicated algorithms anddata structures.
 Firstargument null is horizontal.
 So, that's the fullcode in white for implementing quick union.
 Here's a little bit more mathematical one:we write the recurrence down, and then we divide both sides by N.
 Now we get to the beginning of the array,and once we've done that or we've hit a smaller element, then we haveeverybody to the left of i in order.
 From zero to one.
 But that's simple to implement and very efficient sortingalgorithm.
 And again, that level of flexibility, here's the implementation of it.
 Andso forth.
So this is a mathematical formula that we derive by examining the code but itcompletely describes mathematically what we an upper bound on the number ofcompares that are going to be needed.
 It's going to beat even theclassical sophisticated methods for medium sized arrays.
 The other things that we didn't talk about, the implementation should throw an exception if the client tries to delete from an empty priority queue, and we should have a no-argument constructor and use a resizing array to account for a gradual growth and shrinkage in a industrial strength implementation.
 So you can spend a lot of money or a lotof time, or you can use a good algorithm.
 Or you really want to be certain that itin some performance critical situation.
 Floor and ceiling that's again is an outgrowthof the rank operation.
 And they had a complex error recovery process that,that got triggered if the height limit got too big.
 Then x is going to have that colorcuz the link coming into h is going to be the link coming into x.
 In this case that involvesregarding the S and the R.
 It could beas many as N in the tree for each one.
 And really, the key idea is reallyimportant to think about cuz it applies to all sorts of algorithmic problems.
 In this case, that's H.
 And that's something that's very, very common in, inscientific inquiry nowadays.
 So in this case words, wordsthree.
You can even get a Quicksort t-shirt nowadays.
 So let's see.
 So here's just an overview of twoelementary implementations for priority queues using the example operations that Igave before.
 Now, that compareTo() method is really all that the sortimplementation needs.
 Because a union operation only involves changing one entry in the array.
 And the move method again,most of the times, just takes the x and y coordinates and adds the current velocitytimes the speed constant.
 And what we want to have is the abilityto save away a collection of strings and remove and return the most recentlyadded string periodically, and also test if it's empty.
And, it's a extremely, simple algorithim, but surprisingly, complicated tounderstand, so we'll go slowly.
 And thenafter that rotation, or if there were no rotations at all, if the insertionhappened over here then we'd test and flip the colors.
 Obviously, not practical toaddress such a problem on today's computer.
 And then for the merge, we need at least,at most N compares.
 And this is a fine implementation forsome clients.
 We come against the H, we have to go left.
 So here's still another example where we might use for aclass list, which has the person's year of graduation, last name, first name preceptname and login name.
 So what we want to do is run this experiment millions of times,which we can do in a computer, as long as we can, efficiently do the calculation ofdoes it percolate or not.
 Okay, with this concrete demo in mind then moving tocoding up this algorithim is pretty straight forward.
 So how are we going to solve this problem,implement this API.
 Whereas, Mergesort has to move the itemsinto and out of the auxiliary array, which is more expensive.
 That's the easy one .
 Find the smallest, it's five, swap that with i, increment i.
 The mistake we might make is to put ID of P here rather than first pickingout, that value.
And that definitely enabled new progress in technology and it's a fine example ofthe importance of algorithmic technology.
39 n log n compares.
 So lo is the first part of the array to besorted.
 And if both particles are null we're saying wejust want to redraw things.
 That's our one node linked listthat's got that information.
 And if you do themath, that works out to 30 some years of computer time.
 And just to simplify the codeand to get it the main principles of the algorithms, we're going to assume that allthe coordinates that we have are distinct that we've preprocessed in some way toremove the ones that touch without intersecting.
 This is a little bit about Einstein's experiment.
 And, and in the real world you cannowadays find on the web particular sequences of keys that will causeparticular services to crash.
 So the advantages of immutability and again, maybe this isn't the place to really solve those advantages, it's more for a programming language course, is that it really simplifies debugging.
 So it's a regular binary search tree butit's got this interpretation based on the geometric data,where we switch which key we use for the comparison, the x coordinate orthe y coordinate at each level.
 Go to 9.
 Another way to use two hash functions is just to hash the twopositions and put the key in the shorter of the two chains.
 And now, from standard input we read words, as long as our setcontains the word, we print it out.
 Including binary search trees,red-black binary search trees and hash tables.
 So now, we go on to 5 - turning the wrong way.
 And then we'll just returnthat queue.
 Actually that one doesn'twork at all, very well at all because it winds up not comparing elements in evenpositions with elements in the odd positions until the 1-sort which meansperformance can be bad.
 Thistechnology is, is useful for storing passwords and digital fingerprints andthings.
 So now we look at four, and that's occupied, so we can't put the Hthere.
 And so what's an Iterator? Well an Iterator issomething, a class that has methods hasNext() and next().
 So that's 2d tree implementation.
 That's a trace.
 So that's called amortized analysis, where we consider the total costaveraged over all operations.
 Then there there's a while loopwhere we just read a new line in that read line, read line and then split accordingto comma into tokens in an array.
 And this clearly can make the difference between being able toaddress a huge problem.
Swap the elements of I and j.
 This is for two reasons, one is we canget more efficient implementations if we can use the ordering of the keys to helpus find our way around the data structure.
 So,that's an easy recursive algorithm for finding out the rank.
 Let's remove the maximum again.
 So what we want to do is exchange those.
 So let's look at the, at the three cases.
 So, what we really want is to have timeproportional to log in.
 And then it turns out that it holds forall N, which we can prove by induction fromthe recurrence.
 We want to put it at the end, sothat will be the last one returned.
Sort the left part, sort the right part.
 So, we've got an array A and its firsthalf is sorted and its second half is sorted and the computation we need toperform is to replace that with the sorted array where those two sub-halves aremerged together.
 And if there's no match,we could add it to the front.
 That's straight forward.
 That's the root of its tree.
 But it's something always to be aware of whentrying to [cough] apply simple algorithms in situations like these that turn out tobe maybe more sophisticated than we might think.
 But for user defined types,you're on your own and we'll talk a little bit abouthow to implement hash codes.
 Now what we want to do is read text, andwe want to build an index for each word.
 So seven's root is one, three's root is eight, onebecomes a child of eight.
 Now in theory, it's possible to dosomething that has the property that all positions are equally likely.
Maybe four, 4k or bigger, or maybe even a whole file.
 In those operations to distinguish them, we call NQ to insert an item andDQ to remove an item.
 And now we might have aconnected query that says, is zero connect ed to seven? Well, in this case, there isno connection, so we say no.
 Now, you have to takethese results in context.
 Do heapordering on the, heap of four and that only involves one exchange.
 They're all on the same connectedcomponent.
 [cough] So, asa wa rm-up, here's code to implement bouncing balls without the collisions.
 It's got, room for one moretemporary one, And then what will happen is, when you insert into a full node,it'll split in the same as before.
 And this is a fine data structure forsymbol tables where there is, [COUGH] that are relatively static, where the values don't change much,and most of the operations are search.
 A very rough standard, say for now, is that people have computers that can runbillions of operations per second, and they have billions of entries in mainmemory.
 Now, every time it gets a new item, it has to exchange it allthe way back to the beginning.
 But then, once wefound it, we only have to swap two cards those are both key properties of selectionsort.
 Move the pointer to the right,it's incremented again.
 Algorithms arealso interesting to study, because they, they have ancient roots.
 There's another family of methodswhere there's no ordering, and there's a special methodcalled hashCode that helps us inject randomness into the process.
 You wanted be able to go aroundthe obstacle and it turns out that the shortest path, either it's a straight linefrom s to t or it's part of the convex hull and is not hard to see why that mightbe true.
 What about an unsuccessful search? Well the same rules follow.
 So, and that gives usthis and reduce it to the other situation that we had before.
 Now, if we want to insert E,if it goes to the left, that's fine.
 We're going to start outwith the comparable mostly.
 And for every value of k what we're most often doing is comparing whether aux of jis less than aux of i.
 These are so simple that wewon't go in too much detail, but still it's worthwhile to takea look at them to set the stage for the more advanced implementationswe'll consider next.
 And, so that's an example of inserting, keys into a hash table.
 And not do the individual forcecalculation between our particle and every one of those in the aggregate.
 And that's going to give us the flexibility that we need to implement priority queue operations.
 And those six subtrees drawn could behuge.
 The bitswere really expensive, and people wanted to make sure, that they were making bestuse of the memory.
 But we'll go towards the query point andsee if we can find something closer.
 For range search, ofcourse, we, we have to touch every key that we return, so the running time isgoing to be proportional to the number of keys that match.
 Now we compare the minimum again, again,the one pointed group by j is smaller, so we move that one to k.
 So therefore, the answer is E.
As long as it's pointing to a bigger element that's similarly just a wide loopwe put in to test to make sure we don't run off the left end of the array.
 So, that's inserting into atree that's a single three node a node that's larger than both of them, a keythat is larger than both of them and we get wind up with a four node.
 And now, wehave a legal red-block BST.
 And the [cough] Naive Brute-Force Algorithminvolves checking each pair of rectangles for intersection.
 So anyway,that code down at the bottom is you can use that as a template forwhat you might want to do.
 And the idea is,even if there's K dimension, what we'll do is recursivelypartition one dimension at a time.
 So you can imagine keeping the item, say, in a linked list or ina doubling array and just keeping just an order just as we would in the, in thestack just keeping in the way that they come in.
 In this case it's three nodes that's oriented the wrongway so we need to do a left rotate.
 So here's what it looks like for link list.
 And the algorithm maintains those invariants by finding thesmallest entry to the right and exchange it with the next one.
 So that's our API.
 It doesn'tchange any links so it still, of course, maintains symmetric order and perfectblack balance.
 So again, just a few lines of code, [COUGH] that's basiclinked-list processing.
 So, thatcompletes our summary for a symbol table implementations with red-black BSTs.
 Now we have an instance variablewhich is an array of strings, and our variable N which isboth the size of the stack and the index of the next openposition on the stack.
 Selection sort is based on iterating that idea.
So every time we're moving a new element into k and that's the codethat impelements the abstract in place merge.
 And, and the only other restrictionis that, we don't want the nodes to get too empty.
 And so just using that distance,we recursively search any part of the tree thatcould contain a closer point.
 So, taking a look at equal keys is carefully is something thatcan lead us to very efficient Quicksort.
 You processes through the expression from left to right.
 What's that node? Well, it's the minimum in T's right sub-tree.
 So now we haveour i pointer which is right to the left of stuff we haven't seen ye t and then, wehave two other pointers that maintain, maintain these boundaries everything tothe right of gt is known to be greater than partitioning element.
 And then we, what we have to do is for those two particles is gothrough and predict the future collisions with any walls and collisions with anyother particles.
 That's also called the LIFO discipline,last in, first out.
 We're going to concentrate onprogramming and problem solving in the context of real applications, and ourfocus is going to be on two things, Algorithms which are methods for solvingproblems and data structures which store the information associated in problem,with a problem and go hand in hand with algorithms.
 And we'd throw them universallyat random into M bins.
So, this one, for each word in the file.
 So, that's a demo of insertion into a3-node at the bottom, in a 2-3 tree that percolates all the way to the top.
 So it's a very fundamental concept andwe'll look at plenty of applications.
 It's got a little extra [COUGH] dynamics in the animation because of the auxiliaryarray.
 There's some extra overhead, 8 bytes,because it's an inner class.
 So, six and one havedifferent IDs.
 So life can be complicating when you try to simulate the naturalworld.
 So, we'll build a new priority queue, min priority queue or we'll havethe capability to delete the minimum.
 And it's a simple generalization ofour line intersection problem.
 Recursively, recursively sort each of thehalves.
 We'll consider a number of data structures and algorithmsthat are basic to all the methods we consider including stacks, queues, bagsand priority queues.
 It's the root of it's own treeso now if we have to put four and three in the same component, then all we do is wetake the root, of the component containing the first item and make that a child ofthe root of the component, component containing the second item.
 You have centering, where you try to point near the centerof mass of the k nearest boids.
 A red black tree tracks everysimple path from a node to a descendant leaf with the same number of black nodesthey got that rig ht.
Again, that's a legal 2-3 tree and we stop.
 All right, so we're going to try to findall the points that are contained in that green query rectangle.
 So how do we fix that violation? Well, that one's also easy.
 Web search is something that weall do multiple times everyday and the key is a keyword ora list of key words and the value is a list of placeswhere that key word is found.
 If our keys are 32 bit integer keys and we've got a table of size 2 to32 second then we're just fine.
 Now,what's missing in this is what happens when the balls collide with each other.
 So if we, we aretalking abouta randomized model where the sites are vacant with the givenprobability.
 But now we have to go back and we haveto search the other sub-tree of point 3.
 Unfortunately thatsituation at the beginning of Java where we stuck with that and there are plenty ofprogramming languages where basically we're stuck with that so what we want tolook at is a modern approach to avoiding having multiple implementations for eachtype of data.
 And those counts are going to notonly enable us to immediately implement the size function, just return the countat the root but also, they'll give us good implementations of rank and select.
 Now typically, what we'd what a programmer would do is try to figure onmaking M about equal to the number of keys divided by five say.
 And we haven't looked at things inbetween.
 The shape of the, of the tree could be well in the best case so it wouldbe perfectly balanced.
 So how are wegoing to support that? So this is the API in Java code [cough], so We, have,intervals, so instead of one key we have two, which is left and right end points ofthe interval for input.
 And it's easy to tell whether anyof them could fall in the range by just checking whether they're range overlapsthe root or not.
 So you have two end rectangles to check now, and your computer's twice asfast.
 So, we're movingthe smaller ones than the partitioning element to the left of lt and keeping ltpointing on a partitioning element.
 And that's going to involve, exchanging withthe T, because T is larger than O.
 On this case, it's only the A that goes back two.
 Now, sinse the hash code can be negative,this doesn't quite work the way this arithmetic implement and Java,because it's one in a billion times.
 Today we are going to lookat some symbol table applications, give you some idea of how symbol tables mightbe used, by client program for practical problems.
 And this is a very natural idea.
 Exchange that with the E.
 [cough] method to implement comparators.
 Or if keys are strings or numbers oraccount numbers or many other situations.
 So, let's, look in a little bit moredetail of how we're going to use our dynam-, dynamic connectivity model to dothis.
 So first thing is ifthe search goes right.
 And these are just pieces of literature.
 But there won't be anotherresizing array operation until it either gets totally full orhalf again full.
 So,we're going to have moving particles that either collide with each other and withthe walls.
Okay.
 And again, the cost of this is the number of comparesis equal to one plus the depth of the node.
 Okay, what about arrays? Well, we won't do the details, but it's not difficult to implementqueues with resizing arrays as well.
 Insert M into this one, goes to the right of h,leaning the wrong way, rotate left.
 And that's going to be a discipline thatwe're going to follow carefully throughout this course.
 And then there's the problemof collision resolution.
Okay next we're gonna look at anotherextension of geometric algorithms to process slightly more complicated objectsand then we'll see an important application.
Left parenthesis you ignore.
Then there's a test to see if the pointers cross.
 We start at the root then we set variable x to be the root and that's goingto be the pointer to the current node as we move down the tree.
 Next time we'll look at Quicksort which is also used in Java for differentapplications.
 But generally if we have comparable types,we'll use compareTo, and if we don't have comparable types,we'll use equals.
 So very inexpensive and they had macros to do this so and use not too muchcost to find a partitioning element that's much closer to the middle than, and if youuse a, a random one.
 That checks if those arrays are the sameobjects, and that's not what you want, you want to check that allthe values are the same.
 But this has a huge problem.
 [inaudible] it'seasy to see, well, if that's the case, then we're not gonna find an intersection.
 It's simply which coordinate we use forthe comparison that's the only difference.
 In this case, the 4 subfiles stretched out at seven each onlyhave two elements in them.
 So, during this course you'll be referring tothe book site frequently while working online.
 That following off that nulllink and again, we'll just, for G, travel down the tree until we come to the, nulllink.
 We refer to every node in the tree as the root of a sub-treeand [cough] referred to, the nodes below.
 The client might have a lot of stacks thatneed to be maintained simultaneously and maybe they reached their maximumcapacities at different times and various other things.
 So, Insertion.
 And so we'll needwhat's called a left rotation, and the job of that operation is to take a, a rightleaning red link that is there for whatever reason and reorient it to lean tothe left.
 So this code implements deleteMin, not too bad at all.
 And for search you do thesame thing you hash to the table position and you look there into the right.
 And the number of leaves has to be greater orequal to N factorial so that implies the height of the tree has to be greater thanor equal to log base two(N) factorial which is proportional to N log N byStirling's formula.
 Now we have the c, that one smaller so that's the first case.
Now there is more complicated versions of Mergesort and Quicksort that can do thisin theory but Heapsort is pretty simple algorithm that gets both done, so in a jobinterview somebody asks you what's an in-place sorting algorithm that'sguaranteed N lg n? Your answer's going to be Heapsort.
 There's an advanced data structure called a Fibonacci heap, where inserts are done in constant time and delete max done in log N time, on average over all the operations.
 So in this case, the query point isto the left of the splitting line.
 All the algorithm says is that, if you didn't goright, go left.
 We don't touch them at all,Nor do we touch anything above this node in the tree until the split happens.
 First of all no node has two red links connected to it cuz theonly red links are internal to three nodes.
 And so on average, you examined Nover M squared points per square.
 We're going to take advantage of thisa little bit later in this lecture.
 If it's the left part of arectangle, then we put that interval into our interval search tree.
 We find a node T that contains our key.
 Anywhere between ten and twenty willimprove the running time by maybe twenty%.
 In this case we didn't find any intersections.
 We going to have to, that's data thatwe're going to have to maintain when we do an insert and it's data that we'll usewhen we're doing an interval-intersection search.
 Even if you are familiar with linkedlists, it's worth taking a look at this code because it's the style of codingthat we'll use throughout the course for much more complicated data structures.
 Nowadays you more likelyto do that online or when you're trying to find the song todownload, you provide the name of the song and then the value will tell youwhat computer got her to get that.
Consider some of the details in implementation of partitioning with quicksort.
 Now, suppose the next operation is remove the maximum.
 Let's look at the best case and the worstcase, which are certainly outliers.
 It might moveitems past some equal item and leave a result where items that are equal or indifferent order than they were originally in the file.
 And the key to understanding this code is to realize that the same code,code handles all of the cases.
 There's many reason that immutable keys are that programming languages provide the capability to build immutable keys and this is a fine example of one.
 So we start with anempty table, insert s, it's hash value is six, six is empty so we put it there.
So, all the paths in a 2-3 tree with N nodes have to have length between thosetwo bounds and those are pretty small numbers.
 N times, we're doing a sink operation, andthe size of the heap is at most lg N so it's N lg N.
 Algorithms are interesting for intellectual stimulation.
 We just add it to the end of thearray.
 Or count the number of keys thatlie in a two-dimensional range.
 And now j's E is smaller than g.
 Alright, so first, warm up, insert into a tree withexactly one node.
 So that's kind of like when you create a literal value to be assigned to an integer, it has that value.
 In all that saying is reallythat it must be possible to put items in order in a sort.
 So now we increment that again,and we come to the 3.
 For example, if you have a large arraywith just a few, that's sorted except for just a few unsorted elementsappended at the end, it's going to be partially sorted.
Now we insert H, that kind of goes to the right of E.
 It's applicable to animportant application that we'll see in a.
 It's for comparable keys associated with values andthose are both generic types.
 On the left is our implementation of a stackof strings using link list.
But for three it's worthwhile.
 Well, we're going to use the 2dtree represents our points and we're going to use the structure anddefinition of that tree to go ahead and help us find the pointsthat are in the rectangle.
 So S hashis to position two, it'll be on the link list that is first link is at positiontwo.
 So we look at six.
 And we need to compute a hash code soreturn a 32-bit value.
 [sound].
 And the semantics justclear from the names.
 But it's too expensive for use, in a symbol table.
 Something goes wrong somebody analyzing the situation canenable insertions and they often will help find out where, what theproblem is.
 So, that are sorting algorithms actually their actual code canbe used to implement sorting in many other languages.
 So,if we're looking for the rank of E say, how many keys are there less than Ethere's exactly two, that's by definition in the data structure that's the number ofkeys that are less than E.
 So it's more flexible and more broadly useful.
 Read a new string.
 So, here's the summary of some of the thingsthat we've talked about.
 So, abinary tree is an explicit data structure.
 But if we're going to be implementingsymbol with our own types of data we're going to have to worry about thesethings in order to get a hash function that's effective, that leads toan effective symbol table implementation.
 And have S well, that key isdefinitely going to be in the left subtree.
 So, thoseelementary implementations are no acceptable for a large numbers of keys cuzthey have the linear time operation.
 And you could havesome hybrid struc ture where you use something different for the internalmodel.
 Inthis case that's E.
 So what we're going to run is called a so calledMonte Carlo simulation.
 And then add the hash code for that field.
 Most of thetime, the link that we get back will be same as the link that we put in but forthe bottom node it will be different.
 And then, we return x to link further up the treewhich happens during our standard recursive insert.
 Again, when we look at moresophisticated values we'll be returning something else.
 In fact, if k is small, therunning time is going to be proportional to n.
 A regular binary search tree will just be all strung out in a single lineand wouldn't have quadratic time for this input but a left-leaning red-black treeactually when, whenever it becomes a power of two is completely balanced as you cansee from this example.
" You can't just think about an algorithm you have to work with it.
So it's got to implement Iterable so what does that mean implement Iterable? It'sgot to have a, a method iterator() that returns an iterator.
 Today, we're goingto talk about event-driven simulation which is an interesting idea that is basedon priority queues but it's also used in numerical computation and we'll see inalgorithms for data compression and graph searching that it's useful.
 So, that's our basic setup.
 So the constructor is going to create in this [cough] symboltable.
We convert that 3-node into a temporary 4-node, but then we need to split that4-node moving E to the parent and that creates a new, root node and increases thesize of the tree by one, But now that's a legal 2-3 tree so we stop.
 We'll insert P, L, and E and then, after a while, weremove max P.
 B-trees, there's many different variants that, givedifferent characteristics of, space usage and other characteristics.
 So,that's the key because that means that the size of the tree containing x can doubleat most log N times because if you start with one and double log N times, you get Nand there's only N nodes in the tree.
 And in this small example say we are goingto have five text files.
 So just make it so that every key is larger than it's two children.
 Okay, so let's look at a couple ofapplications where this set API might be useful in client programs.
 If it's not greater or lesser it has to be equal, thanwe return the value right at that node.
 And that's a fine implementationof an elementary sorting method.
 This is a simpler problem.
 We haven't examined yet,it's children are heap ordered so it's a small heap of size three that may not beheap ordered.
 So, that's going to give us, a very easyway to describe a performance.
 Well, first of all, a binary tree is either empty or it's a node with links to left and right binary trees.
 So, we can go aheadand do that and it says that you have put in, in your code an unchecked cast andwe're warning you about that cuz you shouldn't be putting in unchecked cast.
 All of these keys, which are totallydifferent, would wind up having the same collision.
 What if we want to havequeues and stacks of other types of data? And that brings us to the topic ofgenerics.
 We use the notation Lg always for logarithm to the base two.
 Now as alpha gets close toone, you can see these things are going to grow, and particularly the search miss isgrowing to grow quite, quite a bit.
 And it's generic andwill be compared to against a certain type of item.
 [MUSIC] And it happens everyday,right through the winter, just a couple of miles from my doorstep.
 It's kind ofhalf empty.
 Now, for a practical situation we picked some kind of, some value of M.
 And what we do is use a function known asa hash function that takes the key that our symbol table key andreduces it to an integer, an array index, and we use that array index to storethe key and the value in an array.
 Now we're going touse a sparse matrix representation, where each row of the matrix is a sparse vector.
 So it'snot null so we'll compare our key against the key in that node.
 I mentioned the two probe, or double hashingversion.
 So, here's what the main loop is.
 So, that's asummary of linear probing or second hash, collision avoidance strategy.
 But it has two red links in a row.
 And asyou can see, it's a one liner.
 And we'll be very disciplinedin our use of this style.
 So now we can analyze the performance ofthat so that we can provide clients with information on how well the algorithmdata structure will perform.
 So, there's thatcase and then if we're going to the right, then we have to add one for the root andone for the left subtree of the root and then find the rank of us on the right.
 So, that's adding it at the end, violates the heap order, exchange it with the parent through smaller and keep doing until we get to a place where it's larger than it's two children, in this case S goes all the way up to the root, and then the I is all heap ordered again.
 So the clientmethod put of course, just is supposed to do the association so it has a voidreturn.
 And so, you can just run that program and if thesort doesn't use randomness then it's vulnerable to this attack.
 The keys between E and S are still there.
 So here's the implementation of dequeue.
Very close to log based two of N.
 Actually years ago when we taught coursesin algorithms and data structures, much of the course would be aboutthis kind of pointer manipulation.
 That is a fullycomplete industrial strength code for sorting.
 Knuth when he wrote his books in the 60s proposed the incrementsequence 3x + 1.
And you can see on the right that the numbers are printed out in sorted order.
 So but for now the main idea is that it's like a 233 except that we allow waymore keys per node.
 And then the interval search tree to solve the one dimensional N over searchproblem and then how that corresponds to the basic algorithm that you get to if youuse the sweep line algorithm to solve rectangle intersection.
 So that's our assumption thateach key is equally likely to hash an integer between zero andM minus one.
 So, that'sour basic question, how can sort, now, how to compare data of all those differenttypes without being given any information about the type of an item's key? And theanswer is that what is we set up a mechanism known as a callback or referenceto executable code where the client, by passing an array of objects to the sortfunction.
 And basically, the computation is based on computing the interacting force foreach pair of particles.
 So those that's onekind of event that can happen as we sweep from left to right.
 Well, there'sactually a way to compute the convex hull just mechanically if you put the nailsaround the points and put a rubber band around it, that gives you the convex hull.
 So that's going to help us get a handle on the performance of hashing algorithmswhen we get to the implementations.
 You could spendmillions on a super computer, and maybe you could get it done in six years insteadof 30, or in two months but with a fast logarithm, you can do it in seconds, inseconds on your own PC.
 And then since it has to go down by one, the place to remove the element from the heap is at the end of the array because it's now going to have to not occupy that position.
 So, S is the larger of the two children R and S, and now H is still smaller than both its children, so we promote the larger which is P.
 Now, here's the third elementary operationthat we're going to perform.
 Lots of the xs and the ys and the vs but really not a hugeamount of code.
 That's a model for many physical systemsI'll give an abstract model and then just talk briefly about how it applies tophysical systems.
 So for example when we come to this A in theInsertion Sort, then it's, we look at the array before that and then there was M andE in the positions three back so we exchange the A with the larger one to itsleft, that's M and then the other larger one to its left, that's E and then put itinto position.
 W is a bigger one, let usto go over to the right.
 And what we want is amore efficient algorithm than that as usual.
 And the question is.
 Now there's two E's, equal we always takethe first.
 As long as our, ourcurrent node x is not null what we'll want to do is a comparison between the key atnode x and our search key.
 So first thing is the representation is going to be a symboltable.
 In this case, this insertion just says wewant to be sure that a of lo to mid assorted andthat mid plus one to high is sorted before our code andthen we want to check that, the whole thing issorted after our code.
 [cough] So, for this course we have two resources that I wantto talk about and make sure that people are familiar with before entering into thecontent.
 That's the data structure that's going to support thisimplementation.
 And next,we'll take a look at implementations.
 So we won't talk to much about that.
 So 6 isnot there.
 So the nodes to the left of e are smaller and nodes to the right of eare larger.
 For insert and, and for counting.
 Or sink and swim methods are good for making this happen, but we'll delay these implementations until we need them in a more complicated algorithm.
 And in this case, there is.
 [COUGH] concordance client that that doesthe job.
 So both of those entries have tochange to eight.
 We just check the array entriesto see if they're equal.
 One is so-called White Listing where we want to take the words in that fileand, and then we have some other much bigger file.
 Because since y had to be an objectnow we have to cast it to a date, and that better be in the right class or it's just not going to have thesefields that we can test for.
 To use an array, we just keep the nitems on the stack in the array and the array locationwith index N is the place, the top of the stack,where the next item is going to go.
 So, get the next one just like if we want to removethe first.
 Now there's a few rules and there's naturalrules but they're worth talking about and paying attention to that the compareTo()method has to implement in the so called a total order.
 Justdraw the ball.
 But let'ssay, we want to keep track of the top five [cough] values using the third column asthe value.
 [cough] Youcan see our pointer moving from right to left every time it finds the smallestelement to the right, it exchanges it into position.
 Now the intuition behind Shellsort and actuallythe mathematical fact is that if you've got an array that's h-sorted and then youk-sort it for another value k different from h, it's still h-sorted.
 As far as we know, it could be, butas soon as we hit 7, we know that it can't be cuz that's a right turn.
y)(c.
 It's, the idea is to start with point p, theone with the smallest y coordinate.
 So for example,a domain name server might have a lookup where you've got a tablethat's got an IP address and URL associated with that IP address.
 So, here's an example.
 And it's really the sameas a binary search tree, it's just that we alternate whichcoordinate we use as the key.
 In continuing on the right perhaps the nextcompare is a less than c and maybe if c is less than a, then another compare, b lessthan c.
 We have a new red link appearing into some threenode.
 And then the proof is generalizes what I talked about on thedecision tree on the last side, slide.
Six and one.
 So now, thesmallest is the three.
 So, might be, M = 1000 or M = 4000.
 In a new method called, relativelynew method called Cuckoo Hashing.
 In this case it's a bit trickier to affix thesituation, what we do is we rotate the bottom link left.
 And in this case, H is less so all that says to us is that if H is in thetree, it has to be to the left cuz everybody to the right is greater than S.
 It's calledevent driven simulation.
 And that corresponds to thispartitioning of the plane.
 And now we're back at 4, do we haveto search the right subtree of 4? No, because there can't be a closerpoint than 5 in the right subtree of 4.
 And the most important thing is that if we want to do a dotproduct with a vector, say, then the time that it takes is only proportional to thenumber of non-zero keys.
 And we exchange that one with the one that's violating the condition.
Rather than just arbitrarily using the first element.
 And when we remove the minimum element from the priorityqueue, that's the next collision that we have to deal with.
 Now, ifh.
 And so the external nodes have no links, they just have keys.
 So arbitrarily our first point,we're going to divide the plane into two parts basedon a vertical line through that point.
 That's the kind of situation we're going to try to avoid bydeveloping more efficient algorithms for solving problems like this.
y)minus (b.
 And the key thing about this standard implementation thatit's two nested four loops that each run up to N.
 Okay, so that's the procedures that weneed and then they're similar ones for the horizontal and vertical walls.
 That's, that's why Dijkstra's algorithm works.
 So you have collision avoidance, where you always try to pointaway from the k nearest boids.
 In this casethere is a connection.
 Now, here's another war story about red-black BSTs.
If the partitioning element is K.
 And basically what thisthing has to do is implement these methods hasNext() and next().
 Tosearch for E, E's hash value is ten so we look in ten and there it is.
 In particular,it's known that after you've thrown M balls into the M bins then the most loadedbin has about log M over log M balls.
 So first thing is to check if ourrectangle contains a node of the root, in this case it doesn't.
 It's got two nested for loops,selection sort had two nested for loops, a test, a comparison, andan exchange inside the for loop.
 Well, the first thing is that a of 1 is the largest key.
You might need, a multiple compares to move down the tree.
 And we can showthat the vacancy percentage at the time that it percolates is an estimate of thisthreshold value.
 And to just show that this thing gets thesort done with touching relatively few elements.
 So again, our symbol table API gives a very easy wayto implement this file indexing function,which is very widely useful.
 And the Comparator interface again justsays that it's going to implement a method compare() that compares two different keysof the given type, of the generic type.
 We just use Insertion Sort but instead of going one back every time wecome with a new item, we go h back.
 So that's when I gets to the end it gets tothe end, it's in the position m minus one and it goes.
 Find a, a position, if it's, that's equal, And then, reset the key, inthe value.
 But the thing is, there is way morepossible combinations of attributes than there are algorithms.
 Its not going to be bigger than Sbecause S is bigger than G so we go to the left.
 Would be quadratic, right on the face of it.
If every car.
 So here's an example.
 But a sequential search can beslow if we have lots of keys.
 So we put the word final to means that instance methods can't be overridden, and not only that, instance variables are private, they can't be seen from the outside and they don't change.
But Quicksort is much faster, because it doesn't do much corresponding to eachcompare.
 So, the bottom line is that the sweep linealgorithm takes this rectangle intersection problem and reduces it to 1Dinterval search and we have an efficient algorithm for that problem and thatenables us to solve the problem in linear rhythmic time instead of quadratic time.
In the left.
 And Tukey's ninther is justpick nine items out of the array and take the median of the mediums and that's theninther.
 Put everybodyto the left on the queue then put the root on the queue, then put everybody to theright on the queue.
 All right, so, the, insertionalgorithm is pretty simple.
 So, here's an example of an implementation for online poker.
 For a double value, this is the code.
 So, the third attempt that we'regoing to talk about uses generics.
 Well one easy way to doit is to just think about dividing space into a grid of squares.
 There's nobody greater than K.
 And, it also handles moregeneral situations, as we'll see later on.
 In this you know many different versions of hashingthat are based on this idea.
 In this case, we're using that method issorted that we were before.
So what we're going to talk about to do it, is an algorithm, that actually prettyold algorithm called 2-3 trees, and a particular implementation that requiresvery little code, called left leaning red black BSTs and then we'll talk about ageneralization called B-trees.
 And we merge those together to get one ofsize eight.
 If the i pointer is exhausted, then wejust move over the j, next jth element.
 As soon as we hit 12 we seethat 11 can't be on the convex hull and 10 can't be on the convex hull andthat completes the computation of the convex hull with the Graham Scan.
left and that the handles both cases zero and one.
 In the twentieth century, math, scientistsdeveloped mathematical models to try to understand natural phenomenon.
 In this and the next few lectures,we're going to look at symbol tables.
 You type in a word, and then you get places that, where that word appears incontext.
 So what about the mathematical analysis? Well the mathematical analysis,for the Heapsort part is pretty easy.
 There's some other applications that are not so obvious wherewe use sorting as a to make a problem easy once you know that they're sorted.
 And now, it's got two redchildren.
 Increment i, generate a random r, swap them.
 To remove the Q - we know it's at the end to removethe max.
 And if it's equal we don't even have to test that,that's why it's in grey.
 Otherwise this is a very straight forwardimplementation.
So if we start by just inserting a key, well, that just creates a 2-nodecontaining that key, and that's legal 2-3 tree, so we're fine.
 So it's worthwhile youknow, checking that you believe that this code implements the simple binary searchtree algorithm that we demoed where when we fall off a null link we created a newnode and replaced that null link with the new node .
So, let's see an example.
 So what hashing is kind of inthe real word where we're trying to tradeoff this idea that wedon't have unlimited space and we also don't unlimited time sowe're trying to find something in-between.
We might have violated the heap order condtion at the heap right now.
 So the method that we'regoing to look at is a so called Sweep Line algorithm and the idea is to think ofvertical line that sweeps left to right through the data.
 So , what we want to take from thesetheoretical results is, is a guide when we're looking at implementations andtrying to solve practical problems.
 You can figure out the returnvalue which is the number of keys that are less than it.
And the key thing, one key thing is that the way that these implementations work.
 It's to the left, so we only have tosearch the left sub-tree of point 4.
 Strings were defined and as part of the Javasystem but we can define our own ordering on strings with the comparator.
 And now it's greater than x, and that's a null link to the right of x,so the search ends there and are, what we want to do is insert Z into that 3-node.
 There's the partition.
 After that point, no element to the leftof the pointer is going to change and all the element, there's no smaller element tothe right.
 What is it that we care about in asort? It's a little bit more complicated than just put stuff in order.
 And the defect for Quick-union is that thetrees can get too tall.
 And that leads todifferent types of clients, different types of implementations.
 So, just go in from the inside out for every operation enclosedwithin parenthesis like that it's just repeat the argument that's exactly as ifthe original expression were (one + five) twenty and then again, replacing that one,one + 100, 101.
 If that, that happens in their natural order, then the nextthing that has to appear is the key at the root.
 But at this point, thequestion is, is there a linear time algorithm that works for every k? Orpossibly selection is as hard as sorting.
In this case, that node, one node 2-3 tree contains H, so that's a search hit.
 It also allows us to focus onperformance when appropriate.
 And I didn't really thinkabout that at the beginning but it can make a huge difference.
 That's pretty helpful although not, nottotally helpful but there's a lot of situations wherethat's helpful.
 And so to understand how merging workswe'll think about the idea of an abstract inplace merge.
 So should we go left.
 We're going to look at something pretty close in the next lecture.
 Uh-huh, we just want to get at the, allthe non-zero entries.
 And actually the Javasystem and other systems include both so that programmers can make use of eitherone in diff erent situations.
 The month, theday and the year and the constructor fills those from the arguments as you cansee.
 But, doing the whole array doesn't give you a uniformly random result.
Let's take another example for unsuccessful search, a key that's not inthe tree.
If not try I+1 I+2 until getting to a empty position.
 So it goes in the, 3-node containing H andP and we convert that into a temporary 4-node.
 There's actually a very easy way to rearrange an array so that the result is a uniformly random permutation, and only require linear time to get the job done.
 And then we have helper functions less and exchange that access the array directly so that the code doesn't have to access it directly.
 So let's say, N over five and then you get constant time searches and notmuch extra space.
 The subtext of today's lecture really is to go through the stepsthat we'll follow over and over again to develop a useful algorithm.
 So since its to the left ofthe splitting line of the root, we only have to searchin the left sub-tree.
So that'll also improve the running time by maybe ten%.
 But for our iteration,we just have to worry about implementing next() and hasNext() and perhaps using a localinstance variable to get it done.
 So, in this example we have two types with two stacks one of apples andone of oranges.
 And again, it's an E and they're equal.
 It's a simplified version of the Date class that's implemented withinJava just to show the idea of implementing Comparable.
 You got two particles, change your velocities figure out the futurecollision of those particles with the wall and update the priority queue and then themain loop is take the next thing off the priority queue and keep going.
So we can discount that.
 There's versions ofmerge sort that come close but they are too complex for practitioners to haveadopted them.
 Linus Torvalds, who created lin, Linux, saysthat the difference between a bad programmer and a good one is whether heconsiders his code or his data structures more important.
 As I mentioned, it's verywidely used.
 So, as webuilt a faster computer say, in 1970X, we needed to check in rectangles.
 In ancient times, memory was, at quite apremium and so people were very concerned in m-m-making sure that the hash tablenever, got too empty.
 So, we do the standard BST insert color the new link red and then if that[cough] new three node happens to lean right, rotated to the left.
 And again simplify the code, we are going to make the non degeneracyassumption that no two intervals have the same left end point.
 Sowe're going to go right.
 Now, we can assume that put is going to return a link to a sub-tree thatcontains our new key and if our new key is smaller than the key at the node that,that we're processing now, then [cough] we want to insert the new key value there andthe new node on the left otherwise, we want to insert on the right.
 So, the best practice is to use insertionsjust as we did in that example with merge and to assume that they're not going to be there inproduction codes.
 And these are not critical,but they make it a bit more convenient for several implementations.
sort is the way that it is.
 We save a[i] in a variable swap,put a[j] in a[i], and then put swap back in a[j].
 It's very little code beyond the basic heap code that we'velooked at can get this implemented.
 And, surprisingly binary search trees and these associatedalgorithms that we've looked at are going to provide very efficient solutions to anumber of important problems in this area.
 And then we put a test to make sure wedon't run off the right end of the array.
 So in order to handle generic types wehave to use Java's wrapper object types.
 Well, firstthing that we might that we might consider and actually we're forced to consider thisone in lots of programming environment, is to implement a separate stack class foreach type of data that we're using.
 You'll have to do the samething in the vals array.
 So it's the first little chunck and thenthe next little chunk and then merges those together, andso forth and so on.
 And all the res t of'em take timeproportional to the height of the tree.
 So, so now we doput in it's actually a link to that one node that's got two null links.
 So we're going to take, this time we'regoing to take the list of file names from the commandline.
 So first we put the root, then we put the two nodes on the first level going left from right, and then all the nodes on the third level going from left to right and so forth.
So, that connected query, that find says, true, they're already connected.
 [COUGH] And so,we'll search 6 is left subtree, which is empty, andthen its right subtree.
 Now, there's a few thingsthat we can say.
 Alright, and in fact, it leads usto actually for a lot of clients it doesn't really matter what order we getthe items.
 The implementation, on the other hand, can't knowthe details of the client needs.
 So, we add account field to every node and then toimplement the size function well, if it's null, we return zero.
 So, that would be in thiscase here, we'd rotate it left and reduce it to that one.
 Costing involving in the ray axises justto do the find operation and that's going to be too slow if you have a lot ofoperations.
 Find Operation is quick, it'sjust to a constant number of times check array entries.
 And notice it's an associativearray implementation, so for example, we have two Es.
 Again, our symbol table API provides foran easy way to implement this.
 So, we number them zero,one, and so forth starting from the left.
 What about hash tables versus balance search trees? Wellhash tables are really simple to code usually if you don't have to do the hashfunction.
left equals deleteMin x.
So this aspect of red-black BSTs is an extremely nice one because of theoperations that we implemented for regular BSTs that involves some complicated codefor floor and ceiling and rank and so forth, and we don't have to change thatcode at all.
 When we reach the right thenwe remove intervals and so forth.
 Now that's the root of a seven node heap.
 And smaller problems only take an instanteven on your PC.
 What we do is we add a new node at the end of the heap, so that's one position over.
 Algorithms are veryinteresting objects to study.
 And these are just conventions and some are details but it's importantto appoint them all at front.
 So in both cases we just went along one path in the tree todetermine whether or not there was an interval or intersection.
 So given the sink implementation, we had donea one liner for the first pass and a three liner for the second pass so that gives acomplete implementation of heap sort with the code that we have given so for, sofar.
 That's Shellsort or first non-trivial sorting method.
 So that's the basic setup or the invariant that we want to maintain in this data structure.
 To insert or delete howevertakes linear time.
 Youwant to return how many taxpayers have salaries between one million and tenmillion and then which ones are they and so forth.
 To start, we'll talk about 2-3 searchtrees, which is a model that underlies the concise and efficient implementation thatwe're going to look at.
 So [cough] we're going to have arecursive algorithm for our given key.
 For returns null, it's not.
 If we find one that's less weexchange i and lt and increment them both.
 After that exchange, then that would have T up here and P down here.
 Those are some of the situations that we encounter whendeveloping a system sort.
 It's just going to be able toanswer the question, is there a path? In part two of the course, we'll consideralgorithms that explicitly find paths.
 So for example,if you've played the game Doom or used a flight simulator that these types of graphical simulations andanimations are made possible.
 This plot is another way of looking at it, which is the number of array accessestaken as you implement push operations.
 An inversion is just a pair of keysthat are out of order in the array.
 And youwant to insert h that goes to the left of R, two reds in a row, rotate the top.
 And that's every programmer'sfirst introduction to assignment statements.
equalsb.
 And exchanging with the P because P is largerthan O.
 Sowith a series of in exchange and then sync operations, we pull the sorted array outof the heap.
 And as I mentioned, there's been many, many improved versions ofhashing that have been studied.
 Butthat's going to be too slow.
 So what are we going to do with those two links? Well, the Hibbard deletion mechanism which is pretty old, 50 years ago it was proposed, says go ahead and find the next smallest node in the right sub-tree of that tree.
 Instead of hashing.
 Let's believe that it worksfor small cases which we have just done.
 So anyway, we're required to makesure that X is always equal to X, and that X equals Y is the same as Y equals X,and if X equals Y and Y equals Z, then X equals Z.
 This is interesting because we can draw the tree to get more intuition about what's happening, but in the actual data structure representation, we don't need any links at all, it's just an array.
 And then we have the entire array sorted.
 And so this, this traceillustrates how we always make some progress and eventually we get the filesorted.
 But intuitively, we can see kind of whathappens each partitionings that maybe splits the array approximately in half.
 Selection Sort is not stable.
 On ourway, we've been talking about rules of the game.
 Theidea of Shellsort is that Insertion Sort is inefficient because elements reallymove only one position at the time even when we're kind of know that they have along way to go.
 Doone partition then check whether you to your k-th element is going to be on theleft part or the right part and reset lower high accordingly.
 And I, actually, in our implementation thetest of the J pointer running off the left end is redundant.
edu is not in the file.
 If you're not familiar with linked lists, you'll need to review that insection 1.
 If 12 weren't there, they would be.
 It'll get the valueassociated with each key, and if that's bigger than the maximumfound so far, we'll save that away.
 Again, wejust had a red link and now we have a BST with two red links along the pathconnected to A and that's not allowed.
 And the idea of immutable data type is you can't change the value once it's created.
 And then, so that's the casewhen it's smaller.
 This isreally one of the rules of the game but it's much easier to talk about in thecontext of the real algorithms that we've seen so far.
 Nowusually we argue against why the interface is just adding operations to an interface,usually our reason for doing so is that we can't guarantee that all the operationscan be performing efficiently.
 But then we get to the next point,we'll switch and we'll partition on a horizontal line.
 Or in commercial computing the keymight be an account number and the value might be the transactiondetails for that account.
But then we saw how to improve them to get efficient algorithms.
 And that's null, so that's where we insert ournew, interval.
 And, and in our code, if the two keys areequal, it takes from the left subarray so that means that, it will always take the,if there's a two sets of equal keys, it will preserve the relative order andthat's enough to show that the merge operation is stable and then thereforeMergesort is stable.
While the first thing is if the increments are big then the size of the sub arraysthat we're sorting are pretty small so any sorting method including Insertion Sort isgoing to work well.
 The problem is that when we do that, it messes up the sort by name andthat's annoying.
 Princeton.
 Well all thenodes with no children are heap order, they are only a size one, the first one wehave to worry about is this one here the root, the root.
 Nowuntil the 1990s, conventional wisdom among people implementing system was, wasn'tworth doing this.
 And then we do the same thing for the nexttwo elements.
 And in this case, we might as well use a hash table because the order inwhich we process things is not important.
 And it'sactually a very simple algorithm, and it's very easy to see that the running time isgoing to be proportional to N log N plus the number of intersections returned.
And these, we looked at some similar things with for the Word, Mergesort.
 The problem is nobody knows an accurate model for describingthe number of compares taken by Shellsort for any interesting increment sequence.
 And we'll want this client towork well for huge data sets, so leipzig is a data set fromthe web of 20 million orders.
 Okay, so that's a standard, this isjust in words the standard recipe for user type optimize forreference equality check against null.
 So now, we have the two andthree in order, continuing that way.
 And so that's the prediction.
 Now we compare against 5-8, and there's no intersection.
 What's worse.
 That's a linear time shuffling algorithm making use of randomness.
 Now this part I'm not goingto talk about in that much detail right now because it's high school Physics.
 One, to the first item in the list andthe other to the last item in the list.
 This is the scientific approach to designing and analyzing algorithms,where we build mathematical models to try and understand what's going on, and thenwe do experiments to validate those models and help us improve things.
 And again, for successful,you can use that rank to return the value.
 So we have iteratethrough all the keys, and iterate through all the keys in a given range, and countthe number of keys in a given range.
 But it's just a little bit of arithmetic with thevelocities and positions to deal with what happens when, when how to predict when agiven particle is going to collide with another given particle knowing theirvelocity and position.
 Five and zero.
 So the well-known technique fordoing that, called repeated doubling,is to, when the array fills up, create a new array of twice the size andcopy all the items over.
 And so, what's clearabout that is that, it means that, the new hash is likely to hash into a big cluster.
 But then the time, though,gets divided by M squared, your number of points, M, are spread outover the M squared different squares.
 Well, at thatpoint we said we only do that if the size of T2 was bigger than the or equal to sizeof T1.
 And then similarly, dot product of this with that column is 0.
 It's a mutable type and every dayit's got a month, a day, and a year.
 Next, we'll look at more advanced ones.
 At level i, we put on the left the pointswhose ith coordinates are less than p.
 It's actually just thedifference between the ranks plus one if the high [cough] entry in the range queryis in the table and not +one over.
 Notmuch code at all.
 And the fact was that all the qsort implementations at that time in Unix hadthis flaw well, there are two flaws and one of them is a little complicated aboutthe way they are raised order and the other one was for a raise that had lots ofequal keys and this is Wilks and Becker problem and have lot of equal keys, it wasquadratic time.
 We'll assume that the keys have valuesthat come from a total order and we can use compare to compare whetherone key is less than another or not.
 That's up in the topclass file, implements comparable file.
 And what we need to do is find all theintersections in that set of rectangles.
 So that youcan use the natural order or you can provide a compare order and provide yourown order for any type of data.
 In particular, just as another example,consider the idea of N-body simulation, which isa classic problem in physics where you've got N particlesmutually affected by gravity.
 If it's 9/10's full one over one minus alphasquared is 100 one over 100, so it means it's going to be 50 p robes for a searchmiss if it's 9/10's full, and that's independent of N and M, whereas if it'shalf full then we get the nice.
 And then,it'll also put an event for the vertical wall and the horizontal wall, again, usingthis null convention to say that the event second argument null is vertical.
 So we want to do betterthan this.
 And with a quadratic algorithm when you do that.
 But by the time that it doubles, you'veinserted that many items into the stack.
 Linear probing tends to make better use of space.
 It's really an astounding example ofalgorithmic technology.
 I'm not going tosell tickets to anyone that came after that time.
 And we want to be able to find all keysthat lie within a two-dimensional range, that's a rectangle,as I mentioned at the beginning.
 Actually it's the same API as forstacks, just the names are different.
 So, and those are the a top is summarize the four type of thingsthat we could wind up with and what to do so the left parenthesis we've ignored, avalue we put on to the value stack.
 A is four, empty, put it there.
 And again, that has tobe a local operation that only changes a few links and just from the diagram it'snot difficult to see that this little bit of code will do the job.
 And insertion, works the same way, where we get to the bottom, and then,and then we split.
 And now, we know they're in orderbut the program doesn't so we have to look and decide that i and n are the same andthen it swaps it with itself and does the same thing for the last.
 Now we have a private method that implements thisprocess of finding the root by chasing parent pointers until we get to the pointwhere I is equal to ID of I, and if it's not equal, we just move I up one level inthe tree, set I equals ID of I and return it.
 Andthat's the idea of path compression.
 So for every i, we do exactly one swap.
 And so, that takes us to 4,and that one is not closer, so we still have 3 as our current champion.
 There's akiller input for the system sort and, and it can be disastrous in various systemsand the reason is, they didn't do the random shuffling.
 That's extremely significant, and much better than a binary search trees.
 And so we make nine a child ofeight.
 Of course, we cannot get down to having constant time for all operations.
 And again, every insertion involves making a new position by moving allthe larger keys over one position.
 So, we're starting at some point where we have these 10 keys in a heap and its heap order.
 Everything to the right of J is greaterthan or equal to V.
 And then that first node is ready tobe reclaimed by the garbage collector.
 And it's less than both keys,So, if it's in the tree, it would have to be in the left link and it's between thosetwo keys.
 Of each object just pointingto next and then to do a find operation for object at the bottom would involvegoing all the way through the tree.
 That's insertion sort,our second elementary sorting method.
 And this is the specific math that gets that implemented.
 And if doesn't contain it, we don't print it out.
 So, Java has a method called arrays.
 So that's the proposition Mergesort usesat most N lg N compares and 6 N lg N array accesses tosort any array of size N.
 We aregoing to think of that array as representing a set of trees that's calleda forest as depicted at right.
 So the code is the same as insertion, as for Insertion Sort, exceptthat when we go backwards through the array we skip by h instead of just by one.
 So these are mathematical formulas andthere's techniques for solving them and we won't go intothat.
 So[cough] here is just an example of what happens if would those implementedcomparators for that class student using the Java system sort, if you call arraythat sort with your a rray of students and you give it this by name comparator, itwill put them in order alphabetical order by the name field.
 In thiscase nothing is required because it's larger than its children, so we have athree node heap.
 So, in Java, in inner class there is, for every object there's 16 bytes of overhead.
 So, one improvement that we can make is touse insertion sort, and just cut off and use insertion sort which issimple and efficient for small subarrays.
 And [cough] that one happened to be at the root.
 You look at the current node and you look at the rightsubtree, if any of them could fall in the range.
 So Mergesort, it doesn'tmatter that much what the key values are like and it's actually, we can show thatMergesort always uses between one-half, N log N and N log N compares.
 WhatCanute's theorem says is that under the uniform hashing assumption, the number ofprobes in the linear hash table size M, that is alpha percent full, so the numberof keys is a fraction of M, is for a search miss half one plus one over alpha,and a search miss one plus one over one minus alpha squared.
 They might unlockthe secrets of life in the universe, and they're good for fun and profit.
 So, worst casefor lower bounds is when the keys are all distinct.
First thing is small sub-arrays.
So zero children no problem, one child no problem.
So tha, that's.
That's pretty simple code, the question is, if you have a sorting algorithm thatpasses that test, are you sure that it correctly sorted the array? Well theanswer to that question is, yes if, yes if you used only the less() and exchange()methods to implement, to refer the data because then you know because you used theexchange() method that the data in the array after the sort is the same data as was inthe array before the sort, sort.
 And iteration is a fundamental operation ontree structure.
63 log base two of N.
 I want, what's the, given a particle what's the time tillwe hit that particle? What's the time till we hit vertical horizontal wall? And thesame thing is if we're at the point where we're hitting a particle, what would wedo, the, the same way with the vertical and horizontal wall.
 So to look for a key in the hash table we compute the hashvalue.
But that's not really necessary nowadays, as long as you've done the, random shuffleOh, and by the way, Quicksort is not stable cuz partitioning does one of thoselong range exchanges that might put a, a key with equal value over a key anotherkey with the same value.
 When we have an equivalence relationa set of objects and connections divide into subsets called connected components.
